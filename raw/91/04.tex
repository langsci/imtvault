\chapter{Origins} \label{ch:4}\is{language!origins of|(}

Ever since it has been anything you could even remotely call a science, linguistics has been set in a mold of static formalism. I do not make this remark in a spirit of reproach, as do so many who offer in exchange some form of quantitative, communication-oriented, or functionalist approach, equally static but a whole lot less rigorous. There are many points in the history of a science when developments that may not seem desirable from an ideal viewpoint may be strategically necessary if the discipline is to advance; such I believe were the idealizations\is{idealization} initiated by de Saussure and refined by Chomsky. I would not even go so far as to say that such idealizations had outlived their usefulness. In particular, work by Chomsky and his associates over the last decade -- which I understand is aimed principally at establishing, as it were, the outer limits of language -- is I think extremely important and complementary, rather than opposed, to the present approach, as I shall try to show in the final chapter.

The only problem from my point of view with the generativist approach is that it tends to create a mind-set rather difficult to adapt to the kinds of problems we have to address in the present study. In acute cases, the mind-set may be so rigid that when problems can no 
%\originalpage{215}
longer be ignored, they are verbalized away, rather than grappled with; I am thinking, for instance, of Chomsky's response to a perfectly legitimate question by Harnad (\citealt[57]{HarnadEtAl1976}).%FN1 begins 
\footnote{\label{Fn3.1}The exchange, which took place at the New York Academy of Sciences Conference on Language Origins in 1975, should be quoted at length; it demonstrates the orthogonal approaches and seemingly invincible mutual incomprehensibility that have bedeviled glottogenetic studies better than could countless pages of exegesis:
	
\begin{quotation}
		\textit{Harnad}: Let me just ask a question which everyone else who has been faithfully attending these sessions is surely burning to ask. If some rules you have described constitute universal constraints on all languages, yet they are not learned, nor are they somehow logically necessary \textit{a} \textit{priori,} how did language get that way?
		
		\noindent\textit{Chomsky}: Well, it seems to me that would be like asking the question how does the heart get that way? I mean, we don't learn to have a heart, we don't learn to have arms rather than wings. What is interesting to me is that the question should be asked. It seems to be a natural question; everyone asks it. And I think we should ask why people ask it.
\end{quotation}
	
The question ``Why do you ask that question?'' is of course a stalling ploy familiar to psychoanalysts; indeed, it was programmed into the ``robot psychiatrist'' with which some ingenious psychologists were able to simulate, with surprising plausibility, a therapeutic session. The present writer believes, as firmly as Chomsky, that we get language like we get a heart and arms, yet I entirely fail to see why Harnad's question was an illegitimate one or why it does not deserve, or rather demand, an answer. How we first got arms or a heart are questions so phylo\-genetically remote and so unrelated to the mental life of our species that Chomsky is right to dismiss them as not worth asking (except, presumably, for those whose professional specialism they are). But the evolution of language is so recent that we may reasonably suppose that its present nature is still conditioned by those origins, and its crucial role in distinguishing between us and other species (while any number of other species have arms and hearts) is such that it must strongly influence, even if it does not wholly determine, all that we think and do. Thus, to put the determination of its origins on a par with the determination of the origins of physical organs seems to me a piece of evasive perversity.} %FN1 ends
Of course, if you believe that human language is always and everywhere the same, that all languages are equal in expressive power, and that how human language developed can have no conceivable relevance to what language is like today, if indeed it developed at all, if indeed it did not spring in its entirety from Jove's brow by some beneficent and unprecedented mutation -- if you believe all of this, then you are ill-adapted to understand the dynamic processes which, as every man of sense since Heraclitus has realized, govern all that takes place in our universe. Those in whom the malady is less advanced are hereby requested to retune their receivers to a processual wavelength, if they wish to get the most out of the present chapter.

The fact that static formalism has prevented linguists from grappling with the origins of language has not, of course, prevented persons from other disciplines -- with, unfortunately but inevitably, rather less understanding of all that language entails -- from trying their hands at it. Their efforts -- and those of earlier generations of linguists -- have yielded a host of purely speculative theories which I shall not attempt to review here.\footnote{\citet{Hewes1975} provides a fairly exhaustive account of these theories.} Suffice it to say that all of them suffer from the same defect: they concentrate, exclusively or almost so, on the moment when recognizable speech first emerged, when Ug first said to Og, ``\ldots\ldots'' (``\ldots\ldots'' being some kind of meaningful, even if only monolexical, proposition, delivered in the vocal mode). This, which one can only characterize as the Flintstones approach\is{Flintstones approach@``Flintstones approach''} to lan\-guage origins, totally ignores the vast amount of preadaptation that was necessary before you could even get to that point, and equally ignores the vast amount of postadaptation that was necessary in order to get from that point to fully developed human language.

That the Flintstones approach\is{Flintstones approach@``Flintstones approach''} lives is shown by the current hottest number in origins studies -- the ``gestural-origin'' theory (\citealt{Hewes1973,Hewes1976}, etc.). Whether or not the theory that a gestural language\is{language!gestural origins theory of} preceded spoken language is a violation of parsimony (as suggested by
%\originalpage{216}
\citet{Hill1978}) is really beside the point. Either this gestural\is{language!gestural origins theory of} language was of a structure as complex and noniconic as modern sign -- in which case the real question would be, how did this gestural language develop? -- or it was some much simpler and more iconic system -- in which case the real question would be, how did it get to be more abstract and complex? In fact, the ``gestural-origins'' theory is just as much focused on the supposed ``critical point'' of language development, and just as indifferent to any of the substantive questions about language origins as any of the other ``Flintstone'' theories.\is{Flintstones approach@``Flintstones approach''}\is{language!gestural origins theory of}

The trouble with almost all previous attempts to look at origins is that they do not go back far enough. If we were to understand thoroughly all that language involved, we would probably have to go back to the birth of the lowliest animate creatures, for language depends crucially on a matrix of volition and primitive consciousness which must have begun to be laid down hundreds of millions of years ago. Such an approach lies far beyond the scope of the present volume, and will be addressed in a subsequent work, \textit{Language and Species} \citep{Bickerton1990}. Here, I shall go back no further than, say, \textit{Dryopithecus}, although a brief glance at the frog will not hurt us.

Again, as in previous chapters, a certain amount of ground-clearing work must be done if we are to avoid irrelevant distractions. At the very least, we will have to dispose of what I shall call the Paradox of Continuity.\is{continuity, paradox of}

The Paradox of Continuity is\is{continuity, paradox of}, at the present moment, perhaps the greatest obstacle to a proper understanding of language origins, as well as a powerful factor in keeping linguistics isolated from other human studies. It may be expressed as follows. On the one hand, all the species-specific adaptive developments that we know of have come about through regular evolutionary processes\is{evolution}, and language, remarkable though it may be, is only one such development; therefore, language must have evolved out of prior \isi{mammalian communication systems}. On the other hand, if one has anything like a complete understanding of what language is and does, one realizes that there is not simply a quantitative, but a qualitative and indeed unbridgeable, gulf between
%ORIGINS 217
the abstractions and complexities of language and the most abstract and complex of known mammalian systems (which, indeed, seem pretty direct and simple); therefore, language cannot have evolved out of prior mammalian communication systems. Thus, there must have been evolutionary continuity in the development of language, yet there cannot have been evolutionary continuity\is{evolution} in the development of language. This is the Paradox of Continuity\is{continuity, paradox of}, and debate on it has followed the approved political model of both sides hurling slogans at one another from their different and,\enlargethispage{1\baselineskip} as we shall see, mutually irrele\-vant positions.%\\\\

All paradoxes that are resolvable are resolved by showing that one or more of the presuppositions on which they are based is incorrect or at best misleadingly stated. In the present case, both sides of the paradox have weak legs. The weak leg of the discontinuity side is a belief in the unitary nature of language; the weak leg of the continuity side is the belief that if language evolved out of anything, it must have evolved out of another communication system. Let us examine each of these in turn.

The belief that language is one and indissoluble has also taken its toll on the primate-experiment debate. In both areas, the central point of debate has been ``When can X be said to have language?'' -- ``language'' being defined, by the discontinuity side, as something virtually indistinguishable from Modern English or Ancient (ancient!) Greek. Although the continuity side may have protested the definition, few have protested the gambit; instead of pointing out that the question ``Has X got language or hasn't he?'' is an intrinsically stupid, irrelevant, and actively misleading question, they have mostly contented themselves with trying to get linguists to lower the target (for a generally bracing and insightful, if overly soft on the continuity side, account of the ape debate, see \citealt{Linden1974}).

In fact, we will get nowhere until we appreciate that anything as complex as language cannot possibly be an internally undifferentiated object, but rather must consist of a number of interacting systems,
%\originalpage{218}
some of which may originally have developed for other purposes and many, perhaps all, of which must have developed at different times and under different circumstances. Once we accept this, we can per\-ceive the development of language as a succession of stages and there\-fore amenable to reconstruction and study, rather than as a quantum leap, which then imposes on us, whether we will or not, some kind of catastrophe theory as the only possible origins story. It then becomes possible to replace ``Has X got language or hasn't he?'' with the more interesting, and more answerable question, ``How far has X come along the road to language -- specifically, which of the necessary pre\-requisites does he have, and which does he still lack?''

In the opposite camp, the belief that language must have evolved from some prior communicative\is{language!as communication} system if it evolved at all is clearly connected with the belief that language is only, or originally, or pri\-marily, a communicative system. Any doubt cast on this is enough to send the continuity side into a flurry of pooh-poohing. Typical is the attitude of \citet[175]{Young1978}, who finds it ``a further \textit{problem}'' that ``a major use of language in each of us is internal -- for thinking, that is \textit{for speaking to ourselves}'', but nevertheless concludes that it is ``\textit{rather perverse} not to consider human spoken or written language as primarily a functional system evolved for communication'' (emphasis added). Perhaps a biologist may be forgiven for not realizing that language is not just ``for communication'' but is also that which is communicated. But in fact the belief is widespread that all language in\-volved was giving labels to things and stringing the labels together. It is assumed as self-evident that when we were ready to talk, all the things in the universe stood there waiting -- rock and river, dodo and elephant, storm and sunrise, thirst and evil, love and dishonor -- all waiting patiently for their labels. That the world had to be recreated in the image of language before anyone could communicate about anything at all is an idea that seems simply not to have occurred on the continuity side. How that recreation was carried out will form an essential part of the analysis that follows.

Crucial to extant continuity models, even the most recent, is
%ORIGINS 219
the belief, whether implicit or explicit, that you could get from a call system\is{call systems} to modern language (with or without an intermediate stop at a gestural system) by a series of imperceptible stages. Thus, \citet{Stephenson1979} proposes a ``dialectical'' evolutionary process by which, when our ancestors were more preyed upon than preying, they learned to control involuntary vocalizations and replace them with manual signs (how a four-foot hominid in five-foot grass informs his cohorts of the imminent approach of a sabertooth by gesture is left unclear); then when they got to be better predators and were less concerned with unobtrusiveness, they were able to return to voice, which was now under cortical control. ``The dialectic consists in \textit{an increase in the level of complexity of messages} coincident with a decrease in the limbic content of messages as one proceeds through calls, through gesture, to spoken language and into written language'' (emphasis added). \citet{SteklisEtAl1979} dismiss the gestural\is{language!gestural origins theory of} phase on principles of parsimony, but maintain call-language continuity by accepting the claim by \citet{HockettEtAl1964} that progressive blending and differentiation of primate calls could have mediated the transition.\footnote{In the Hockett and Ascher  ``Flintstone''\is{Flintstones approach@``Flintstones approach''}, the key development is a hominid who, in encountering food and danger at the same time, gives half the call for food and half the call for danger. Not one shred of even the most oblique evidence from ethological or other studies, or even the authors' own ratiocinations, is adduced in support of this inherently unlikely development, beyond their admission that they can't think of any other way language could have begun.}

All these views share the assumption that the only significant difference between call systems and language lies in ``an increase in the level of complexity of messages''. In fact, complexity is not the issue. A given alarm call could well receive the reading, ``Look out, you guys, a large predator is already near and rapidly approaching, so get up the nearest tree as quick as you can'', which is surely at least as complex as ``the boy ran'' or ``John kicked Bill''. Language depends crucially not on complexification but on the power to abstract, \textit{as units}, classes of objects, classes of actions, classes of events, and classes of yet more abstract kinds (think, for example, for a moment of all the different kinds of relationships that can be conveyed by so simple a predication as \textit{X has Y}). It is these classes, not the particular objects, actions, etc., of which they are composed, that constitute the units that language must represent; but in order to represent them it must first abstract them from the constant sensory bombardment to which all creatures are subject (we will see how in a moment). An alarm call
%\originalpage{220}
abstracts nothing from that bombardment, but merely selects from it a set of stimuli (smells, colors, physical movement, etc.) to which some kind of immediate reaction is the only appropriate response. A call and a sentence may both constitute communication, but in the ways in which they work they are more at odds than chalk and cheese; for some chalks and some cheeses at least have the same color and texture, whereas language and call systems do not even have this superficial resemblance.

However, once we are prepared to consider the possibility that language could have developed in a regular evolutionary\is{evolution} fashion without having sprung from some primitive repertoire of grunts, groans, and grimaces, all the objections to a continuity approach melt like snow in August. Once we have gotten over the ``communicative'' hang-up, we can see that where we must look for the distinctiveness of human language is not in what it shares with call systems -- both communicate -- but in how it differs from call systems -- language communicates concepts, call systems communicate stimuli. If we don't understand \isi{conceptualization}, we don't understand language, period.

However, if we are to write an evolutionary\is{evolution} history of \isi{conceptualization}, there is one more ghost to be exorcised -- the ghost of Descartes. This particular specter is still haunting the behavioral sciences even though the naturalistic observations on which its man-animal dichotomy was based are now over three hundred years out of date. If you believe, as Descartes believed, that animal behavior can be explained by principles as simple as (and similar to) those hydraulic forces which activated the ``living statuary'' of 17th-century French gardens, then it does not seem so unreasonable to suppose that animals are automata but that we (with souls stashed in our pineal glands) are not. In light of all that has been learned about both the structure of the nervous system and the behavior of species since Descartes' day, it is merely absurd -- possible to salvage only with the logical, if counter-factual, strategy of the hardcore behaviorist who would claim that animals are automata but that so too are we.
%\originalpage{221}

There are four possible answers to the question, ``Who has consciousness, volition, etc.?'' (all the so-called ``nonphysical'' attributes summed up under the illegitimate label \textit{mind}): animals do, but we don't; animals don't, but we do; animals don't, and we don't; animals do, and we do. In all the history of human folly, I know of no one who has seriously asserted the first. The second is Descartes' answer. The third is the hardcore behaviorist's answer. The fourth, curiously enough, has seldom been made and has been scorned almost as often as it has been made, although in light of what we know now it would seem the most logical. Since it now appears that \isi{evolution} has advanced not by leaps and bounds but by infinitesimal gradations, we either have to claim that with respect to a particular set of attributes (volition, consciousness, thought, language), \isi{evolution} behaved in quite a different -- and, incidentally, completely mysterious -- way from that in which it behaved with regard to all other attributes, or we have to accept that at least some of, or some ingredients critical to, these attributes were and presumably still are shared by species other than our own. I know of no logical argument against the second move although the emotional arguments against it seem as numerous as they are strong. Let us therefore see how \isi{conceptualization} -- without which language would have been impossible -- could have evolved.

Conceptualization\is{conceptualization} is intimately linked to perception, if only in the sense that if there were no perception, conceptualization could not take place. But there is, I think, a great deal of difference between a concept and a percept\is{percepts|(}, which tends to be obscured by loose ways of talking and thinking. We use ``concept'' for any kind of mental image. In fact, there are mental images of percepts and of concepts. We might say, loosely, that I have a concept of the glass that is presently standing on my table, meaning, I can close my eyes and present myself with a mental image of my glass. That is a mental image of a percept, i.e., my glass as I perceived it now -- empty, but for a small slice of lemon. Of course, I could imagine it completely empty -- which is a percept of how it was at another time; or full -- which is the same. However, I can also have a mental image of the category \textit{glass}, which embraces
%\originalpage{222}
my glass and all other glasses, and which is not a percept, but a true concept.

In some species, percept and concept may not be so far apart. Consider the frog\is{frogs|(}. The frog can discriminate ``fly'' and ``not fly'', at least as long as the fly is moving. It is unlikely that a frog can tell one fly from another or would preserve \isi{memory} images of individual flies, even if it had a memory to preserve them in. In a sense, perception and \isi{conceptualization} in the frog are one. Only in a sense, of course; for true conceptualization, you have to have volitional control of concepts, and the frog is as far from that as from flying. But in the sense that perception in the frog is generalized, it is like \isi{conceptualization}.

Now, the fibers which connect a frog's retina with its brain are capable of passing only about four kinds of information, of which only two are relevant to the perception of flies. The first of these two kinds is supplied by a set of neurons specialized\is{neural infrastructure|(} to detect small moving objects with curving edges; the second is another set specialized to detect sharp boundaries of light and shade \citep{Burton1970}. There is then a rather tenuous and metaphorical sense in which we could say that the froggy concept of ``fly'' \textsc{is} the firing of these two sets of neurons. Of course, we are several scores of millions of years away from true \isi{conceptualization}; but the journey has certainly begun.

In the course of those years, it might have seemed that perception and \isi{conceptualization} were moving apart, as perception became not only wider in range (most of the environment seems quite undifferentiated to the frog) but more particularized, with so many parameters recoverable that maybe even individuals could be recognizable to one sense or another, or a combination of several (when our dog recognizes us, smell is presumably dominant).\footnote{However, I have some (admittedly anecdotal) evidence that dogs use \isi{cognitive mapping} in recognition. Our dog, Rufus, will rush from the opposite end of the apartment to greet my wife when she comes home, but on meeting her on campus he ignores or even recoils from her until she is just a couple of feet from him, whereupon he performs his usual acts of greeting. It is not easy to account for such behavior unless (as is the case with us) part of the way he recognizes people has to do with a network of particular associations. He recognizes her where he expects her to be, and fails to recognize her elsewhere, in the same way (and why not for the same reason?) that we fail to recognize, on the beach or in a restaurant, the clerk or cashier we may have met dozens of times in a work setting.} And yet the basic mechanics by means of which this enhanced perception was carried out were in fact no different from those of the frog\is{frogs|)}. There might be many more sets of neurons programmed to respond to many more varied types of stimuli, but a percept would be still the particular firing pattern of the particular set of neurons activated by that set of stimuli which constituted the object perceived.
%ORIGINS 223

The problem of how a percept becomes a \isi{memory} is still far from solved. Part of the problem may be that most studies of memory have really been studies of \isi{learning} -- that is, of forced situations in which given factors caused changes of behavior. Thus, if an octopus were trained to attack horizontal but not vertical rectangles, two sets of feature detectors, each of which could formerly initiate more than one program of action-advancement, withdrawal, indifference -- can now only initiate one each, with corresponding changes in the neural connections involved \citep{Bradley1975}. Unfortunately, such findings do not seem to generalize to mammals, where ``the search for the engram'' remains as fruitless as it was thirty years ago \citep{Lashley1950}. Furthermore, it would be unreasonable to expect them to generalize to the quite qualitatively different kinds of memory traces which concern us here. For the kinds of memory traces that modify behavior -- those traditionally studied by psychologists -- may be (although of course they are not necessarily) laid down in ways quite different from those of memories which may only modify behavior in the most indirect of ways, if indeed at all (e.g., my stored \isi{memory} image of my neighbor's new car, accurate enough to enable me to distinguish it from others, but unlikely to prompt me to steal it, polish it, avoid it, etc., and hardly to be described as having been \textit{learned} by me except under the vaguest and most vacuous reading of \textit{learning}).\\\\

Therefore, I shall assume that long-term storage is achieved (precisely how need not concern us) by storing features of images rather than images themselves. Let us assume I can reliably identify several hundred human faces. Now, the mental representations of these faces that I need for matching purposes -- I can think of no other way in which recognition could be carried out -- are not stored separately in some analogue of a box in my head, not even in the form of macromolecules. Rather, each of the horizontal, vertical, slanted, curving, etc., lines that go to make up faces -- as well as lots of other things, of course -- is represented by a particular set of neurons. The superset
%\originalpage{224}
composed by these sets is simply an analogue of the superset of feature-detecting neuron sets. The data recorded by the straight-vertical-line perceiving set of neurons (or however much of them are transferable) are simply transferred to the long-term storage set for straight vertical lines, and so on. The fact that a particular batch of data went into a particular batch of storage sets must also somehow be recorded, in terms of sensitized synaptic pathways or whatever, or I could never recover Aunt Emma's face from its component bits. But in some such general manner -- and I apologize to neurologists for my rather Rube Goldberg picture -- the processes of perception, storing, coding, and accessing must be carried out.

It follows that individual images would not be individually stored -- members of the same class of images would not necessarily be stored together, while the storage of unlike objects might be strikingly similar. Let us consider the possible storage of the percept images of three objects, any one of which would have to be separately and individually recoverable: \textit{Aunt Emma's latest hat}, \textit{the Sugarloaf at Rio de Janeiro}, \textit{the distribution curve for IQ in an average population}. These objects belong, respectively, to three quite distinct classes; the class of hats, the class of mountains, and the class of distribution curves. However, in their general shape they share some obvious similarities. Let \textsc{a} through \textsc{g} represent sets of storage neurons, each set representing storage of a particular parameter. Then \textit{Aunt Emma's latest hat} might be represented by sets \textsc{abcde}, \textit{the Sugarloaf at Rio de Janeiro} by sets \textsc{bcdefg}, and \textit{the distribution curve for IQ in an average population} by sets \textsc{cdef}. If I wish to visualize an image of any one of the three, I activate just these sets.

(And what constitutes the ``I'' that activates? Analogy from observed conspecifics, use of mirrors and other reflecting substances, plus the higher-order ``traffic-control'' neurons which must exist to establish priorities in brain activity if the whole thing isn't to degenerate into electrochemical chaos.)\is{neural infrastructure|)}

Some kind of \isi{memory} storage of particular experiences must go pretty far down the mammalian phylum. So too, I suggest, must
%\originalpage{225}
the power of playback -- voluntary recall of images or sequences of images\is{recall (of memory)}. At the very least, involuntary playback (another name for dreaming) does. Reptiles don't \isi{dream}, mammals do. Moreover, dreaming (human dreaming, for sure; mammalian dreaming, very likely) consists not of just straight playback but of the recombination of stored imagery, something that would be difficult or impossible if memories were individually stored. Once playback, straight or crooked, came under cortical control, our ancestors were well on their way to the world map that is a prerequisite for language -- without which there is hardly anything worth communicating to communicate.

The question evolutionists\is{evolution} will ask at this point is: why? Why should mammals develop these capacities? Prehistory was not a dress rehearsal for \textit{homo sapiens}. What selective advantage did the species gain? Some psychologists have attempted answers in very vague and general terms. For instance, \citet{Harlow1958}, discussing the fact that some apes and monkeys can solve in captivity problems far more complex than they would ever meet in nature, pins his faith on receptor system development, since more finely calibrated receptor systems entail an increase in the central nervous system: ``As long as increasingly complex receptor systems provide the organism with slight survival advantages, one can be assured that increasingly complex nervous systems will develop; and as long as increasingly complex nervous systems develop, the organism will be endowed with greater potentialities which lead inevitably to learning.'' Similarly, \citet{Passingham1979}, who finds it ``puzzling'' that chimpanzees\is{chimpanzee} should have language capacities which ``do not appear to be used in the wild'', surmises either that ``chimpanzees\is{chimpanzee} do in fact use their language capacities in the wild'' -- in ways which two decades of patient and trained observation have somehow still failed to reveal! -- or that ``their abilities \ldots~must be general ones, allowing them to do other things of importance to them in the wild''.

\is{evolution}The vagueness and timidity of these suggestions are, I am sure, due to the Cartesian hangover, although the class ``Cartesian evolutionist'' ought to constitute a logical contradiction. It should be pretty
%\originalpage{226}
obvious that the power to review the past would provide its possessor with another power of the highest value in natural selection: the power to predict. Psychics aside, \isi{prediction} is based on analysis of past events, and becomes of greater importance as creatures evolve and become more complex. Relatively simple creatures lead relatively simple lives; it is possible to program them, up to around the frog level, so that they will respond automatically to all or almost all the contingencies they are likely to encounter. With more complex creatures, in particular with predators who have to keep (literally!) one jump ahead of their prey, not only does the list of conceivable contingencies get too long to program, it would probably be dysfunctional for such creatures to be programmed down to the wire, so to speak. Such programming would leave them unable to respond appropriately, to vary the moment of attack in accordance with the wind, the light, the prey's motions, and countless other environmental factors, to determine which member of a herd to attack, and so on. The power to review past sequences of events, whether at a conscious or an unconscious level, and to abstract those factors which made for success or failure in particular cases, would confer a massive advantage on its possessor -- or one that would have been massive had the prey not developed along similar lines. As shown in the excellent survey by \citet{Jerison1973}, brain size\is{brain size} for both prey and predator has gradually but continuously increased throughout the mammalian era, with the predators always slightly ahead of the prey.

We do not of course know, and have as yet no way of determining, how far down the evolutionary\is{evolution} scale such capacities might extend. But such capacities and more might have been needed to ensure the survival of the primates, creatures who were predators to some species and prey to others; and it is a reasonable assumption that \textit{Dryopithecus}, the presumed common ancestor of ourselves and the chimpanzees\is{chimpanzee}, who lived between five and fifteen million years ago, had them and probably had more.

We have so far surveyed the capacity to form and store percepts and to review percepts and sequences of percepts under voluntary
%\originalpage{227}
control. But we have not yet considered how percepts can become concepts. Until a percept -- the image of a particular entity on a particular occasion -- can be replaced at will by a concept -- the image of a class of entities, divorced from all particular instantiations of that class -- then the power to predict is limited. A creature concerned with prediction does not want to have to say, ``The boar I wounded three years ago did such and such, and the boar I wounded a year ago did the same, but this wounded boar is a different boar so I suppose I'll just have to wait and see''. It wants to be able to say, ``Wounded boars do such and such, so I can anticipate what will happen and be ready to act appropriately''. The prediction may be quite wrong, of course -- with fatal results. But if it is right just that little bit more often than chance, the survival chances of the species are perceptibly enhanced.

Indeed, instantaneity would have rated above accuracy. The creature that could achieve 60 percent accuracy in one second would surely have outlasted the creature that could achieve 100 percent accuracy in ten seconds -- because in those ten seconds, too many of the latter would have gotten themselves killed.

``To generalize is to be an idiot'' \citep{Blake1808},\footnote{Nothing Blake ever wrote should be taken lightly. In the broad brush-strokes with which we have to draw our cognitive maps\is{cognitive mapping}, infinite details are lost, and what is worse, we get locked into stereotypic reactions to stereotypes (\textit{kike}, \textit{freak}, \textit{faggot} are some pernicious examples) which lead us to deny one another's individuality. A creature that could compute from percepts rather than concepts would outshine us as the sun outshines the moon (more on this in \textit{Language and Species}).} but for better or worse, the road to humanity was paved with generalizations\is{generalization}. We assume our ancestors to have been primates not adapted for predation but driven by climatic change to adopt, in part, the habits of predators -- or so most anthropologists have held for a good many years. Lacking the tiger's fang, the leopard's speed, the disciplined pack strategies of the canids, they had to compete with these and more in a dry epoch when pickings were scarce. Under such circumstances they would have selected very fast and very naturally for some kind of instant recognition-and-reaction device -- one that would respond not merely to the briefest of glimpses of possible prey or rival predator, but to the most minimal clues in the environment: movement of a branch at a particular altitude, say, coupled with the appearance of a patch of brown slightly different in shade and texture from the fall leaves that surround it.

%\originalpage{228}

That modern hunters still have such a device, even though changing times have made it more dysfunctional, was illustrated a few years ago when a national magazine carried out an inquiry into shooting accidents during the deer\is{deer|(} season. Hunters were shooting one another instead of the deer\is{hunting accidents}. The vast majority of these incidents occurred in the half-light of dawn or dusk. The shooters, when interviewed, almost invariably said that they had seen a deer -- not ``thought'' they had seen one, but actually seen it -- and only seconds after they had pulled the trigger did this image resolve itself into a wounded dying fellow-hunter. From a few half-perceived dues of color, shape, and texture, they had created phantom deer and reacted to their own creation before additional sensory input could replace the projected image with a real one.

The reader may easily demonstrate a similar if less lethal effect. Simply draw, on a piece of paper or a blackboard, the structure portrayed in \figref{fig:4.1} below:

\begin{figure}
	\begin{center}
		\begin{tikzpicture}
		\node at (0,0) [circle, fill, inner sep=3pt] (dot) {};
		\node [dashed, color=red, circle, fit=(dot), inner sep=10pt] (guide) {}; % add 'draw' option here to show guiding help lines.
		\foreach \angle in {90,126,...,540} {
			\draw [thick] (guide.\angle) -- (\angle:2cm); 
		}
		\draw [thick] (guide.270) -- (270:6cm);
		\end{tikzpicture}
	\end{center}
	\caption{The minimal ``flower''}\label{fig:4.1}
\end{figure}

%\originalpage{229}

\noindent If you then ask what this is, people will reply, nine times out of ten,  ``a flower''. I have tried this many times on students; you can often see their jaws literally drop when you tell them, ``No, it's a dot, nine short lines, and one long one''.

The capacity to construct predictive images obviously entails the preexistence of class concepts. The misguided hunters did not project an image of some specific deer, but rather that of any member of the genus deer. To us, with the elaborate and labeled cognitive map\is{cognitive mapping} which language provides for us, the genus deer seems self-evident. But try to imagine, if you can, the task of constructing the category \textit{deer} from scratch, by inductive reasoning, without benefit of labels or of map. Deer come in a number of shapes, sizes, and species. Some are dark, some are light. Some have horns, some don't, some sometimes do, and some sometimes don't. Where do deer stop and other genera begin? The problems are endless.

Yet as work by \citet{Berlin1972} and his associates has shown, generic names\is{generic naming} are the most richly represented in natural languages -- more numerous than both the higher-order categories (``unique beginners'', e.g., \textit{plant}, \textit{animal}, or ``life forms'', e.g., \textit{tree}, \textit{bush}) or the lower-order ones (``specific name'', e.g., \textit{Ponderosa pine}, \textit{jack pine}, or ``varietal name'', e.g., \textit{northern Ponderosa pine}, \textit{western Ponderosa pine}); invariably monomorphemic (contrasted with specific or varietal names); subjectively perceived as primary; the first to be learned by children. It is a good bet they were among the first words of human language.

Why the genus and not the species? If your eyes are as sharp as I'm sure our ancestors' were, differences between species must often have been as salient as, or more salient than, differences between genera. But behavioral differences would have had greater significance for our ancestors than visual differences. All deer\is{deer|)}, whether large or small, plain or spotted, with or without horns, had a number of things in common: they were fleet of foot; nervous enough to make stalking them difficult but not impossible; often camouflaged by the light-and-shade effects of foliage; excellent eating if you could get them, and so on.
%\originalpage{230}

But the fact that classification of the genera would have been selectively advantageous for our ancestors does not in and of itself make such classification possible. A number of preadaptations would also have had to occur, perhaps the most obvious of which is \isi{cross-modal association} -- the importance of which for language has been stressed in a number of papers by \citet{Geschwind1974}. For the concepts of genera could not have been built on sight alone; each of the senses must have contributed in varying degrees. But the real key to the crucial developments must lie in the nature of the recognition device.

I have said that members of our species, and even dogs, if their behavior is anything to go by, must be able to distinguish individuals, and there is no reason to suppose that our capacity to summon up at will the visual images of individuals necessarily indicates any very recent evolutionary development. I suggested also that these images might be stored in a fractured manner, so that similar sets of bits, when put together in various ways, could constitute very distinct images. But why in that case do we not project genera that would include in the same category, say, \textit{Aunt Emma's latest hat}, \textit{the Sugarloaf at Rio de Janeiro}, and \textit{the distribution curve for IQ in an average population}?

The utility, or lack of it, that such a category might have is beside the point. If we built category concepts on the basis of individual percepts, such would be the kinds of categories we would most likely wind up with. One of the main reasons that we do not is that concepts, as distinct from percepts, do not exist in isolation. We do not delimit percepts in terms of percepts. I do not distinguish Aunt Emma's face because it is bounded on one side by Aunt Mary's face, on another by Cousin Emily's face, and so on; nor (just to show that this fact has nothing to do with any heightened perception of conspecifics) do I distinguish my toothbrush because it is bounded on one side by my wife's toothbrush, on another by my son's toothbrush, etc. But I do distinguish deer because they are bounded by horses on one side, cattle on another side, and so on; I do distinguish toothbrushes in general because they are bounded by hairbrushes,
%\originalpage{231}
nailbrushes, bootbrushes, etc. Deer stop where horses begin. Toothbrushes stop where nailbrushes begin. But Aunt Emma's face does not stop where Cousin Emily's begins, my toothbrush does hot stop where my wife's begins. That is the difference between percept and concept, class member and class. Concepts are delimited in terms of one another, percepts only in terms of themselves.

Concepts are like the counties on a state map, in several ways. Where one stops, another starts. Although each is composed of so many acres and contains so many individuals, none is merely the sum of the acres that compose it or the people who inhabit those acres. Each of them has its place with respect to the others. The same with concepts. Percepts inhabit concepts, but concepts are not the sum of their percepts. \textit{Aunt Emma's latest hat}, a percept, belongs to the concept \textit{hat} and not the concept \textit{mountain}; \textit{the Sugarloaf}, a percept, belongs to the concept \textit{mountain} and not the concept \textit{distribution curve}. It is not because of its individual characteristics that I do not expect to find the Sugarloaf on Aunt Emma's head; it is because I know that the Sugarloaf is a mountain and mountains do not belong on people's heads. When I see the Sugarloaf for the first time, I do not have to work out from scratch all the properties it has, including that of not being on Aunt Emma's head; all those properties follow automatically once I have determined that it is a mountain. Mountains have their place on the map, and so do hats; and those places are different.

But how, on first seeing its picture, did I recognize that it was a mountain (albeit a rather small one) at a distance, rather than a large if rather eccentric hat, up close? Not by computing its peculiar properties. If I had, I could have gone wrong, because in outline it is less like the archetypical mountain than it is like some hats. I did so by putting two things together: the fact that it fulfilled at least some of the qualifications for being a mountain together with its relations to other objects: a harbor, clouds, a cable-car line to its summit. Of course, it could still have been a hat in a Lilliputian model city; just as the deer the hunter shot at could have been (and in fact was) a
%\originalpage{232}
fellow-hunter. The fact that our maps may occasionally let us down does not mean we could get along without them. We would be nowhere without them.

If percepts could be filed fractured, so to speak, concepts must be filed as gestalts. I do not have the slightest idea how this is done, nor to the best of my knowledge has anyone else, although neurologists will quite likely find out in the next century or two. However, since speculation is useful if only to provide candidates for elimination, let us speculate. Having been stored one way as percepts, in a manner based on their immediate sensory images, phenomena would be copied and stored another way in accordance with their observed behavioral properties. Did they lie still or move? If they moved, did they soar, lope, or slither? These heterogeneous bundles of information would again, presumably, be stored in sets of neurons synaptically linked with, and as specialized in function as, those sets of perceptual neurons that distinguish movement from nonmovement, loping from slithering, and the smells characteristic of one set of phenomena from the smells characteristic of another set. However, instead of the same set of neurons representing similar aspects of the images of quite different things, as we supposed was the case in the storage of percepts, separate sets of sets, involving heavy duplication of function, would be required for each network of neurons that represented a concept.

If this were so, it would explain why, while percepts may be stored in literally infinite quantity, the list of concepts, or at least the list of primitive concepts, is certainly finite and probably quite short (of course, an infinite number of secondary concepts -- \textit{timber wolf}, \textit{prairie dog}, etc. -- can be constructed by combining two or more primitive concepts). It would also explain why the human recognition device works as it does. Each superset of concept-representing neurons would include representations of all features of a concept. If indeed the major genera constituted the first concepts (and there would seem to be no likelier candidates), this would mean in effect all features of a genus -- sensory, behavioral, distributional, whatever. Then whenever any sufficient subset of features is detected by the perception neurons --
%\originalpage{233}
a patch of dappled light, motionless, at a certain height above ground in a forest at dawn -- the superset from which that subset is drawn would immediately be activated in such a way as to yield the full concept -- \textit{deer}, in this case. The subject has then ``seen'' a deer, or whatever, and reacts accordingly.

This account is, again, necessarily crude, necessarily vague -- what constitutes a ``sufficient subset of features'' for concept triggering, for instance? -- and quite possibly wrong in most or all of its particulars. It is crude, vague, and possibly wrong because, as \citet{Blakemore1977} observed, studies of \isi{memory} (and allied human capacities) have been ``concerned with the \textit{machinery} \ldots~not the \textit{code} -- the symbolic form in which the events are registered'' (original emphasis); by ``machinery'', Blakemore means ``the manner in which events can cause changes in physical structures'', but the kinds of changes likely to be caused by the mental processes we are considering, consisting as they would consist of no more than the forging of additional links between specialized neurons, would hardly be amenable to observation in the state of today's technology (ten billion neurons with sixty thousand connections each -- where do you start to look?). It is crude, vague, and possibly wrong because neurologists have considered the more ``metaphysical'' implications of their task as somebody else's business, because ``continuists'' of the grunt-groan-or-gesture school have thought that the nature of reality is self-evident and therefore didn't need to be constructed, and because philosophers, who alone could be expected to perceive the problems inherent in perceiving anything at all, have resolutely refused to tie their ballooning speculations down to the nuts-and-bolts of what we already know about what we have in our heads and what we might be expected to be able to do with it. So the whole area slipped between the cracks of the disciplines. But that area still exists, and is crucial in the explanation of human capacities, so a bad map is better than no map at all.\\\\

These last few pages may seem to have taken us a long way from language, but I do not think that is the case. Unless we have some
%\originalpage{234}
notion of all that must have been involved in moving from moment-by-moment perceptions to class concepts -- and it is class concepts that are named, not perceptions, percepts, or the extramental stimuli for these -- then we simply do not know what it entailed for a species to get language. Moreover, until we appreciate just how difficult it must have been to name the major genera -- the flora and fauna, successful interaction with which was our ancestors' very lifeline -- we shall not even begin to conceive the role which is played by the perceiving mechanism, rather than the perceived data, as progressively more abstract phenomena are involved. We will come to that in a moment.

But before we do, we should note that if the foregoing account is correct even in its broadest outlines, we have already suggested an infrastructural motivation for one of the major semantic distinctions observed in the preceding chapters (the SNSD\is{specific-nonspecific distinction (SNSD)}). We saw that both creole speakers and children were able to distinguish with great ease between specific and nonspecific (generic)\is{generic naming} reference. Now, if percepts\is{percepts|)} -- images of particular entities on particular occasions, therefore specific -- and concepts -- images of classes of entities, therefore nonspecific -- are stored in different places and in different ways, this distinction would be built into the neural system. In consequence, something which seems highly abstract and far beyond the powers of two-year-olds, if we suppose it to be acquired in the traditional fashion, would apply automatically \textit{provided that no alternative but incompatible distinctions }(such as those involved in Japanese case and topic marking, for example) were simultaneously being imposed on the child by the target language. Indeed, I shall later suggest that it was just those category distinctions based on sharply differing modes of cerebral coding and storage which were the first to be grammaticized, and which were thus to serve as a kind of scaffolding by which language was able to rise from an initial low plateau of short and relatively structureless utterances.

Now, from recent experimentation, we know that the power to abstract concepts from nature is something that we share with the great apes. As \citet{Mounin1976}, among others, has pointed out, the evidence of what chimps\is{chimpanzee} did voluntarily, after training, is much more
%\originalpage{235}
impressive than what they were trained to do. The fact that they applied names to different-looking objects of the same class, as well as to pictures of such objects, and their frequent generalizations of names to broader classes, shows that to them, names were class names -- concept labels -- and not mechanical responses linked to particular, individual objects after the fashion of proper names. The fact that they invented names for classes of objects whose names they had not been taught -- for refrigerators (\textit{open-eat-drink}), for ducks (\textit{water-bird}), for Brazil nuts (\textit{rock-berry}), for oranges (\textit{orange-apple}): Sarah knew only ``apple'' as a fruit descriptor but had orange separately as a color) -- shows that they had far more concepts floating around in their heads than their caregivers had the time or patience to name for them and also showed power of creativity on a lexical (nonsyntactic) level, a fact we will return to in due course.\footnote{Some scholars remain unimpressed by the evidence that apes have concepts. For instance, \citet{Seidenberg1979} seem to need reassurance that before and after Washoe signed \textit{water-bird} he did not also sign \textit{banana-bird}, \textit{water-berry}, \textit{banana-berry} -- in other words, they at least envisage the possibility that signing apes proceed like demented computers, throwing off random strings of signs (they have, after all, been reinforced for signing) from which biased experimenters simply pick out the rare one which happens, by pure chance, to be contextually appropriate. Leaving aside the unmerited slur which this casts on the morals and/or wide-awakeness of many dedicated researchers, the approach adds a Cartesian twist to the old behaviorist-nativist\is{behaviorism} controversy: scholars who are behaviorists with regard to animals and nativists with regard to people. It is more parsimonious as well as more fruitful to suppose that when animals similar to ourselves evince behavior like ours, similar mechanisms underlie both sets of phenomena.}

With regard to the independence of this power from anything you could call training, it is worth citing a passage from \citet{Mounin1976}: ``Sarah, all alone in her cage (outside any experimental situation) picked up objects or signs and composed utterances on the models of the structures she had just learned \ldots. Can one discern the transition of the main and primary function of her code, social communication, to a secondary use of it, the possibility of developing for oneself the expression of one's own view of the world? \textit{Or} does this expression \textit{only} represent play?'' (emphasis added).

This passage comes very close to blinding insight, yet it still manages to get things the wrong way around. Mounin is right, of course, in that the Premacks taught Sarah her code for strictly communicative purposes, so that if she turned it to private, computational purposes, that use would be secondary in a rather narrow sense. But in a much broader, evolutionary sense, things were the other way around. Possession of an elaborated world-view must precede, not follow, communication on even the lowest of linguistic levels. Sarah and Sarah's species must already have had an interior world of concepts, not of percepts, or they would have been unable to transfer names from one object to another, still less from one class to another.
%\originalpage{236}

Moreover, a name like Washoe's \textit{rock-berry} (for Brazil nut) is a metaphor at a level appropriate for barroom joking, if not poetry; it shows awareness of a superclass of which both berries and nuts are members, and the sharing of an abstract quality -- hardness, not normally associated with that superclass -- by nuts and a member of another, non-vegetable superclass. The coiner of such expressions has a cognitive map\is{cognitive mapping} of no mean quality.

A further telling, if oblique, bit of evidence for this claim comes from \citet{RumbaughEtAl1976}, who report that it took Lana 1,600 trials to learn the names for \textit{banana} and \textit{M \& M}, but that the next five items were acquired in less than five trials each -- two of them in two only. This stunning and instantaneous increment is inexplicable in terms of Lana's having ``learned how to learn'' in the course of those 1,600 trials; \isi{learning} curves just don't jump like that. It is much more plausible to suppose that for a long time Lana simply couldn't figure out what her trainers were trying to do, and then suddenly it clicked: ``My God, they're feeding me concept names -- why couldn't they have \textit{told} me, the dummies?'' The concepts had been there all the while, and only the link between them and these mysterious new things that people were doing to her needed to be forged.

Finally, Mounin's use of \textit{or} and \textit{only} is a striking example of anthropocentric, or perhaps I should say Puritan business ethic, modes of thinking. On the one hand, you have ``developing for oneself the expression of one's own view of the world'', an activity automatically assumed to be solemn, to be heavy, to be \textit{work}, in fact; therefore, on the other hand, something that is \textit{play} couldn't possibly be ``developing for oneself \ldots'', etc. \citet{Piaget1962} came nearer the bone when he claimed that the symbolic function arises first in \isi{play}, and anyone who has watched a young mammal exploring the environment for the first time knows that ``play'' and ``building a cognitive map''\is{cognitive mapping} are isomorphic activities (young lizards don't play because they don't have the spare brain cells). It may look like ``mere play'' to the supercilious human observer, and indeed it is play -- the animal wouldn't do it if it weren't fun -- but it is also the means by which lower creatures
%\originalpage{237}
as well as human children set about constructing the mental representation of the world which gives them varying degrees of predictability and thus enables them to control to a greater extent their own chances of survival.

Now, if chimps\is{chimpanzee} can have concepts and label them just as we have concepts and label them, and if we know (or are reasonably sure) that we have a common ancestor in \textit{Dryopithecus}, then we can begin to get some kind of evolutionary\is{evolution} perspective on the development of linguistic infrastructure. When we find behavioral homologies in closely related species, we can reasonably assume that these homologies represent a common inheritance from a common ancestor (\citealt{CampbellEtAl1970}; \citealt{Hodos1976}; \citealt[Figure~1.4]{Dingwall1979}). This would mean that the power to conceptualize and the potential for naming go back at least as far as \textit{Dryopithecus} and maybe further back than that. In a moment I will try to answer the fascinating question that everyone must want to ask at this point: ``Why, if language is so spectacularly adaptive and if the basic infrastructure has been around for so long, didn't it develop millions of years sooner?'' But first, there is more to be said about the problems of \isi{conceptualization} and naming.\\\\

We began by tackling the infrastructure of language at just that point where the gap between language and the external world was most easily bridged; where the classes to be named were at least classes of discrete entities. Let us now turn from entities to their attributes and in particular to color.

Color is not something that really exists in the external universe. We have all seen the landscape ``change color'' as the sun declines without thinking it at all odd or stopping to remember that the purpling of noon's green hills is due simply to the shortening of the wavelengths of light reflected from them. Color is simply created by the interaction between those wavelengths and sets of specialized perceptor neurons, longer wavelengths appearing as red, slightly shorter ones as orange, and so on across the spectrum. But color vision adds yet another set of parameters to those that are already sorting percepts into their
%\originalpage{238}
appropriate classes. The boundary between two colors, for instance, is often a boundary and sometimes perhaps the only boundary between another entity and its background.

Useful though color vision is, it presents serious problems for language, problems of a kind quite different from those inherent in the naming of the species or genera. Creatures are discrete; the spectrum is one and continuous. We can perceive light at wavelengths of between roughly 380 and 800 millimicrons, and we can perceive it equally well at any wavelength within those limits. It is true that we can say of some colors, ``that's a real green'', or ``a true yellow'', but there are points in between where we cannot say whether green or yellow is involved.

If Og and Ug had sat down, as in some of the more simplistic Flintstone\is{Flintstones approach@``Flintstones approach''} scenarios, with a bunch of different-colored pebbles to help them, maybe, and started out to ``name the colors'', they would have been stymied from the word go. Even more sophisticated accounts which would still assume some degree of arbitrariness and voluntary control in naming run up against the insuperable obstacle that words demand concepts, and concepts demand boundaries; but colors have no boundaries, so theoretically you should be free to cut up the spectrum into as many chunks as you fancy and draw the lines between them just where you feel like drawing them. In fact, as \citet{Berlin1969} demonstrated in their pioneering study, nobody is free to do any such thing. Basic \isi{color terms} (terms neither borrowed from names of pre-existing objects, e.g. \textit{orange}, nor compounded, e.g.. \textit{dark green}, \textit{yellowish brown}, etc. -- that is to say, primitive concepts) are highly predictable across languages, and the semantic range of each term is determined by the number of terms in any given language system and by the ranges of pre-existing terms (if this sounds familiar, remember it was exactly the way I said TMA systems\is{tense-modality-aspect (TMA) systems} were structured, back in \chapref{ch:3}, and we will look at these, too, later in the present chapter). This is to say that if a given language has only two basic \isi{color terms}, those terms must be ``dark'' and ``light''; if it has three, they can be only ``dark'', ``light'', and ``red''; and so on.
%\originalpage{239}

\is{neural infrastructure|(}The neurological substrate of this structuring of color has been explained \citep{McDaniel1974,Kay1978} in terms of Hering's ``opponent'' theory of \isi{color discrimination} (\citealt{Hering1920}; since experimentally confirmed for certain species of primates, cf. \citealt{deValoisEtAl}). Primate brains, and those of some other orders, have various sets of perceptor neurons each adapted to different hands of the spectrum and activated only by stimuli that fall within those wavelengths. One pair of sets monitors the ranges corresponding to red and green. One member of the pair hits its maximal firing rate when stimulated by central red and its minimal firing rate when stimulated by central green. The other member of the pair hits its maximal firing rate when stimulated by central green and its minimal firing rate when stimulated by central red. Similar pairs deal in a similar way with yellow-blue and the light/bright versus dark/dull distinction.

The far-reaching implications of the Berlin \& Kay\ia{Berlin, Brent}\ia{Kay, Paul} discovery have yet to be absorbed by the scientific community. The conclusions reached in a summary by \citet[527]{ClarkEtAl1977} are fairly typical in their unrevealing, indeed inaccurate, nature: ``The very physiology of the human visual system makes some colors more salient than others. Children find these colors eye-catching and easy to remember \ldots. There is more occasion to talk about salient colors and listeners assume that speakers are more likely to be talking about them. Color terminology\is{color terms} is universal because the human visual system is universal.''

Quite apart from its chatty, wasn't-everything-simple-after-all tone, and its evident confusion of perception with \isi{lexicalization}, this passage makes a grave factual error. The whole point of the Berlin \& Kay\ia{Berlin, Brent}\ia{Kay, Paul} thesis is that color terminology is \textsc{not} universal. If the color systems of languages reflected universalities of the human visual system then \is{color terms}color terminology would always be the same and always mean the same. But it is not and does not.

What happens in these languages that have only ``dark'' and ``light''? Presumably speakers of these languages have the same visual system as everyone else, and presumably children \isi{learning} these languages
%\originalpage{240}
find red, yellow, blue, etc., as ``eye-catching'' as any other children. And if all the primary colors are equally salient, how is it that no language starts by distinguishing only green and blue, and then works its way back across to red in the opposite direction?

It is worth going into the structuring of \isi{color terms} in some depth here as I believe this structuring is paradigmatic of a number of other semantic areas, some of them much more important than that of color.

First, and contra Clark \& Clark, there is no simple one-to-one relationship between neurological equipment and semantic structure. Rather, the nature of neurological equipment enables semantic structure to be divided up in a number of possible ways. At the same time, it prohibits semantic structure from being divided in an infinitely greater number of ways, any of which might seem a priori no less logical or possible, and imposes rigid constraints on the sequence in which any given analysis of the semantic structure can be rendered more complex.

Let us look at some prohibited \isi{color terms}. No language has the term *\textit{reen} meaning `red and/or green, but nothing in between', or the term *\textit{yellue} meaning `yellow and/or blue, but nothing in between'. There would seem to be no a priori reason for the absence of these terms, for it is easy to construct not only meanings but also possible neurological substrates for them. Thus, *\textit{reen} would be the representation of activity in the red-green receptors (and no others), while *\textit{yellue} would be the representation of activity in the blue-yellow receptors (and no others). However, we know that lexicalization does not simply represent outputs of particular neuronal sets, for two reasons. First, many languages have a term equivalent to \textit{grue} `green and/or blue', which represents partial outputs of two opponent sets, rather than the full output of one opponent set. Second, the factor that allows \textit{grue} to exist, while blocking *\textit{reen}, seems to be perceived spatial contiguity\is{contiguity constraints}, which of course corresponds to wavelength contiguity. Green and blue are contiguous on the spectrum; red and green, or yellow and blue, are not.
%\originalpage{241}

It has often been noted that spatiotemporal contiguity is a condition on naming; no language has a word such as *\textit{larm} meaning `leg and/or arm', or *\textit{shee} meaning `shoulder and/or knee'; in no language can I say, *\textit{I teach on mwidays} meaning `I teach on Mondays, Wednesdays, and Fridays'. However, a further look at \isi{color terms} will show that spatiotemporal contiguity\is{contiguity constraints}, although a necessary condition on naming, is not a sufficient condition. If it were, some languages would have a word *\textit{yeen} meaning `yellow and/or green' instead of \textit{grue}. Yellow and green are just as much contiguous as green and blue. Their conjunction would mean conjoining the outputs of two opponent sets, but the same is true of green and blue.

There would seem to be two possibilities. \textit{Grue} conjoins the two short-wave\-length outputs of two opponent sets: *\textit{yeen} would conjoin the long-wavelength output of one opponent set (yellow) with the short-wavelength output of the other (green). Perhaps one kind of conjunction can be lexicalized and the other cannot; we simply do not know enough to say. But it is also possible that what can be lexicalized at any given stage of development may be constrained by the order in which \isi{lexicalization} takes place.\footnote{That the nature of linguistic facts can be determined by the order in which they necessarily occur and/or originally occurred has already been suggested in the contrast between the development of tense that takes place in learners of English and that which takes place in learners of Italian. Those who continue to believe (see Note \ref{Fn3.1}, this chapter) that there is nothing to be learned from learning how language developed should read and compare these two cases and then ask themselves whether their attitude is not one of simple obscurantism.}

\ia{Berlin, Brent}\ia{Kay, Paul}This brings us inevitably to the much deeper question: why were the basic \isi{color terms} added to human language in just the order that Berlin \& Kay showed them to be? The answer may lie in a suggestion of potentially immense explanatory power first made by \citet{Stephenson1973} but not, to the best of my knowledge, subsequently developed: that the Berlin \& Kay sequence of dark/light-red-green/yellow-blue may reflect the order in which color perception became established phylogenetically.\ia{Berlin, Brent}\ia{Kay, Paul}

The argument, although hard to support from empirical studies -- species representing the appropriate evolutionary\is{evolution} stages may all be extinct -- is nevertheless a highly plausible one. Stephenson points out that mammals were originally nocturnal and could probably only make lighter-darker distinctions; as they began to shift to diurnal habits, after the extinction of major reptilian predators, the perception of light-wavelength distinctions became selectively advantageous (it
%\originalpage{242}
would permit a much sharper and finer differentiation of the environment). Stephenson argues that such perception would have begun with the longer wavelengths.

The transfer from the phylogeny of perception to the phylogeny of language would then have come about in the following manner. In any line of development, neurological structure is always incremental; no species sloughs off its neural inheritance in the act of adding new layers; the new layers are simply superimposed on the old ones.\footnote{This is not, of course, to say that older structures do not undergo changes, adaptations, and linkages. The neural dysfunction known as Gilles \isi{de la Tourette's syndrome} is one that affects the limbic area, yet its victims shout lexical obscenities as well as more animal-like cries. In general, lexical utterances are under cortical control, but in the case of those which express strong emotion, like nonverbal vocal utterances, linkage between the speech areas of the neo-cortex and the limbic area must have been forged at some stage subsequent to the former's development.} It follows that older layers have a longer time in which to establish themselves, to multiply numbers cells and cell connections. This process is likely to be halted or reversed only if the related capacity becomes dysfunctional to a species -- which color perception is unlikely to do unless our species is forced back to a nocturnal pattern. Thus, other things being equal, the older of any two capacities should be the stronger. The greater neural strength of the oldest -- the light-dark distinction -- would then lead to its being first lexicalized; the neural strength of the next oldest -- long-wavelength (red) perception -- would lead to its being second lexicalized, and so on.

I shall therefore propose the following hypothesis: \textit{those semantic distinctions whose neural infrastructure\is{neural infrastructure|)} was laid down first in the course of mammalian development will be the first to be lexicalized and/or grammaticized in the course of human language development}. In the present state of our knowledge, such a hypothesis can have only a tentative status; yet we will see, when we consider the possible evolution of TMA systems\is{tense-modality-aspect (TMA) systems}, that it can still have considerable power.

After red, languages can lexicalize either yellow (next wavelength down from red, also the ``high'' member of the next color-opponent set) or green (the ``low'' member of the set already activated). It may be that herein lies the reason for the absence of *\textit{yeen}. If one or the other member of *\textit{yeen} must be individually lexicalized, then a large category consisting of just those members cannot subsequently be constructed: \isi{lexicalization} proceeds unidirectionally toward an ever finer dissection of the color area, so that while existing categories
%ORIGINS 243
may be split, they can never be added to or collapsed. But again, research into the color vision capacities of more species of primates may clarify the situation by demonstrating a phylogenetic order of acquisition for the shorter wavelengths too.

We should also look at how the meaning of individual terms is affected by sequential development of semantic subsystems since there is good reason here also to suppose that similar phenomena will be found elsewhere. In their original (\citeyear{Berlin1969}) treatment, \citeauthor{Berlin1969} referred to ``dark'' and ``light'' as ``black'' and ``white''. Indeed, ``black'' and ``white'' is what these terms shrink to in an eleven-term system like that of English where other terms have spread over most of the semantic ground. Yet it should surely be obvious that as \isi{lexicalization} progressively dissects semantic areas, the meanings of the earliest lexical items must change: ``black'', which originally embraces half the spectrum, must gradually reduce in scope until it eventually occupies only a narrow band of it. Similarly, ``red'' in a three-term system must include much -- orange, maybe the darker yellows -- which it cannot possibly include in the eleven-term English system, which contains orange, yellow, and pink as units. Thus, the semantic range of terms in subsystems is determined by the number of terms in such subsystems and by the semantic ranges of the other terms.

Constraints such as these will loom ever larger as we continue to traverse \isi{semantic space} away from representations of concrete entities and toward representations of ever more abstract relationships. So far, the semantic infrastructure we have dealt with is in all probability shared by \textit{Homo sapiens}, \textit{Pantroglodytes}, and \textit{Dryopithecus}. I doubt whether similar sharing extends to much or even any of the areas we are about to enter. Indeed, if we were reconstructing to a strict chrono\-logical timetable, we should probably drop semantics here and start talking about syntax, since from here on out, syntactic and semantic developments were almost certainly intercalated and their interaction served to drive language up along a beneficial spiral. However, in the interests of clarity of presentation, and to counteract the obsession with ``communication'' that has so far vitiated any understanding
%\originalpage{244}
of how language must have evolved, I shall continue to deal with semantic infrastructure (or rather with such small patches of it as there is space to deal with) in order to show just how much conceptual preadaptation was necessary before a ``communicative system'' as simple as the simplest of early creoles could be made to function communicatively. Later on, we will retrace our steps to the present point and deal with the early development of syntax, relating the latter, wherever possible, to concomitant developments in semantics already touched on.%\\\\

The first of the semantic areas I shall touch on concerns predications which may be felt to be central in any structured language system: \textit{There is an X}, \textit{X is at Y}, \textit{Z has X}, \textit{X is Z's}. I shall refer to the relationships expressed by these predications as Existence\is{existential|(}, Location\is{location|(}, Possession, and Ownership\is{ownership|(}. I should emphasize that these labels are chosen only for convenience of reference and are not meant to have any particular semantic significance: ``possession\is{possession|(}'', for instance, is grossly inadequate for the semantics of \textit{has}, which might better, though still inadequately, be defined as ``stands in a close and superordinate relationship to''.

In an original and insightful study, Eve \citet{Clark1970} reviewed the ways in which these four relationships are represented across a sample of fifty-odd languages. She found a high degree of similarity in the syntactic structures involved, but a good deal less similarity in \isi{lexicalization}. Some languages (indeed, almost half the sample) used only a single morpheme to lexicalize the entire area; others used four different items, i.e., lexicalized each of the four relationships differently. Between these extremes there were several different patterns, with two or three of the relationships being jointly lexicalized, but seldom the same two or the same three from one language to the next. Not surprisingly, Clark concluded that, in this area, the lexicon was without internal structure.

At first sight, an area such as this might seem to be affected by constraints far different from those which would affect the area of 
%\originalpage{245}
body parts or even the more abstract area of \isi{color terms}. One would not expect to find, for example, contiguity constraints\is{contiguity constraints} of the type that bar items like *\textit{yeen} and *\textit{shee}, since the relationships we are now talking about do not seem to have any discernible concrete correlatives of which contiguity or noncontiguity could reasonably be predicated. And yet, contiguity constraints\is{contiguity constraints} exist here too. 

Consider \figref{fig:4.2}. %below:
If the four relationships are arranged spatially as in \figref{fig:4.2}, and if we consider only the primary (shortest, simplest, most frequently used) morphemes in each language -- e.g., not allowing \textit{exist} to substitute for \textit{there \textsc{IS}}, or \textit{possess} for \textit{have} -- the following constraint on \isi{lexicalization} seems to apply: no language can use the same mor\-pheme to express any two noncontiguous relationships (i.e., location and possession, or existence and ownership) unless that same morpheme is also used to express one of the intervening relationships (i.e., existence or ownership in the first case, location or possession in the second). In other words, the \isi{semantic space} mapped in \figref{fig:4.2} is as structured as real space, and, as with real space, only contiguous sectors can be jointly lexicalized. This constraint operates on all the languages in Clark's sample, on all creoles for which adequate
%\originalpage{246}
data are available, and for at least thirty other languages checked so far, or at least one hundred languages in total;\enlargethispage{1\baselineskip} I have not yet met with any counterexamples.

The reasons for the existence of such a constraint in this particular case are far from obvious. The categories involved are not highly abstract, but seem to be mutually inclusive. Species and \isi{color terms} are mutually exclusive: if something is a cat, it is not a dog; if something is red, it is not yellow or blue, and so on. If the \isi{semantic space} associated with species, color, and certain other areas is sharply divided, then such divisions can be regarded as no more than analogues of divisions which exist in the material universe. But it is hard to see what real-world divisions would be correlates of the constraint governing the location-existence-possession-ownership area, since existence and possession (in the relational sense given above) can be predicated of all entities whether abstract or concrete, while location and ownership can be predicated of all concrete (and perhaps some abstract) entities. So why should it not be possible to conjointly express location and possession, or existence and ownership, given that any other pairs, any triples, or all four together may be conjointly expressed?\is{existential|)}\is{location|)}\is{ownership|)}\is{possession|)}

I can think of two possible explanations, not necessarily mutually exclusive. Both explanations involve principles of broad, indeed universal, application. As yet, I know of no way in which these natives could be tested.

The first explanation involves \isi{semantic primes}. The term \textit{semantic prime} is normally used in reference to unanalyzable concepts; here I use it in a rather different sense, to refer to a very limited set binary oppositions; any concept can then be defined in terms of plus and minus (and perhaps null) values for these oppositions,\enlargethispage{1\baselineskip} in the same way as phonological units can be defined in terms of plus and minus values for Jakobsonian distinctive features.\footnote{In fact, discussion of semantics would be clearer if \textit{semantic prime} were reserved exclusively for category distinctions of potentially universal application (like the SNSD, the PNPD\is{punctual-nonpunctual distinction (PNPD)}, etc.) and if what are sometimes referred to as ``\isi{semantic primes}'' were referred to as \textit{primitive concepts}. However, note that primitive concepts are not necessarily constructed out of semantic primes.}
%\originalpage{247}

Semantic change\is{linguistic change} would then proceed in a manner analogous to phonological change. A phonological change cannot spread from voiceless velar or bilabial environments (\,\underline{~~~~} --voi, --cor) to voiced apical environments (\,\underline{~~~~} +voi, +cor) without first occurring in voice-less apical environments (\,\underline{~~~~} --voi, +car), or in voiced velar or bilabial environments (\,\underline{~~~~} +voi, --cor), or both. In the same way, semantic change could not spread from an environment which had minus values for two semantic primes to an environment which had plus values for those same primes without first affecting at least one environment which had a minus value for one prime and a plus value for the other prime.

An example can be found if we compare the article system of Modern English\is{English!articles} with the article system of \ili{Guyanese Creole}\is{Guyanese creole!articles}, which is probably not much different from the article\is{articles} system of Middle English (the theory predicts that when an article system arises, it will be governed by similar constraints irrespective of whether it arises in a creole system or elsewhere). The Guyanese system is shown in \figref{fig:4.3}. %below:

\begin{figure}[p]
	\begin{center}
		\begin{tikzpicture}[baseline]
		\node at (0,0) (ownersh) {Ownership};
		\node at (4,0) (locati) {Location};
		\node at (0,-3) (possessi) {Possession};
		\node at (4,-3) (existen) {Existence};
		
		\node (gr1) [draw, fit=(ownersh) (existen), inner xsep=1.25cm, inner ysep=1cm] {};
		\draw (gr1.north) -- (gr1.south); \draw (gr1.east) -- (gr1.west);
		
		\end{tikzpicture}		
		\caption{Semantic space for four relationships}
		\label{fig:4.2}
	\end{center}
\end{figure}

\begin{figure}[p]
	\begin{center}
		\begin{tikzpicture}[baseline]
		\node at (0,0) [rectangle split, rectangle split parts=2] (def) {+P +S\nodepart{two}``Definite''};
		\node at (4,0) [rectangle split, rectangle split parts=2] (indef) {--P +S\nodepart{two}``Indefinite''};
		\node at (0,-3) [rectangle split, rectangle split parts=2] (gen) {+P --S\nodepart{two}``Generic''};
		\node at (4,-3) [rectangle split, rectangle split parts=2] (oth) {--P --S\nodepart{two}``Other''};
		
		\node (gr1) [draw, fit=(def) (oth), inner xsep=1.25cm, inner ysep=1cm] {};
		\draw (gr1.north) -- (gr1.center); \draw (gr1.east) -- (gr1.west);
		
		\node [left=\baselineskip of gr1.west] (gr1west) {};
		\node [right=\baselineskip of gr1.east] (gr1east) {};
		\node [above=\baselineskip of gr1.north] (gr1north) {};
		\node [below=\baselineskip of gr1.south, fill=white, inner xsep=.25cm] (gr1south) {\huge };
		
		\path let \p1=(gr1north.base), \p2=(gr1.north east) in node at (\x2, \y1) [fill=white, left] (gr1NE) {\it wan};
		\path let \p1=(gr1north.base), \p2=(gr1.north west) in node at (\x2, \y1) [right, fill=white] (gr1NW) {\it di};
		
		% fill=white in preceeding \paths and the following pgfonlayer is used so that dashed lines to not cross "wan" and "di"
		
		\begin{pgfonlayer}{bickertonbg}
		\draw [decoration={markings, mark=between positions 0 and 1 step 1 with {\arrow[line width=0.1mm, scale=2]{|}}}, postaction={decorate}, dashed] (gr1west.south)  |- (gr1south.west)  -| (gr1east.south) ;
		\draw [decoration={markings, mark=between positions 0 and 1 step 1 with {\arrow[line width=0.1mm, scale=2]{|}}}, postaction={decorate}, dashed] (gr1west.north) |- (gr1north.west);
		\draw [name path=draw1, decoration={markings, mark=between positions 0 and 1 step 1 with {\arrow[line width=0.1mm, scale=2]{|}}}, postaction={decorate}, dashed] (gr1east.north) |- (gr1north.east);
		\end{pgfonlayer}
		
		\node [below=2\baselineskip of gr1south] (legend) {(P=presupposed; S=specific)};
		
		\end{tikzpicture}
	\end{center}
	\caption{Semantic Space for Guyanese Articles}\label{fig:4.3}\is{articles}
\end{figure}

%\originalpage{248}

%\originalpage{249}

In \figref{fig:4.3}, ``definite'' and ``indefinite'' have their traditional meanings; ``gener\-ic'' refers to the subject NP in \textit{The dog/A dog/Dogs is/are (a) mammal(s)}, and ``other'' includes NP in the scope of negation, ``a book or books'', and similar cases (see Chapters \ref{ch:1} and \ref{ch:2} for a more detailed analysis of the creole system). It was claimed earlier in this chapter that the specific-nonspecific distinction had as its cerebral foundation the differential storage of percepts and concepts; if this is so, then the SNSD must represent one of the oldest (phylogenetically speaking) of \isi{semantic primes}. If it is old, it must (by the infrastructural hypothesis proposed in our discussion of \isi{color terms}) be strong, and this superior strength may account for the configuration of \figref{fig:4.3}. Although the SNSD divides the entire semantic area, with ``zero'' on one side and ``some marker or other'' on the other, the presupposed-nonpresupposed distinction (\textit{presupposed} in this context refers to ``information presumed shared by speaker and listener'') divides only the +specific area. Now, there is no a priori reason why the latter distinction should not divide the entire area; generics\is{generic NP} are +P because everyone can be assumed to know class names, while ``other'' is --P because no one can be expected to know which was the dog that X \textsc{didn't} see or which was or were the book or books that Y might have bought. But, as we saw with colors, semantic infrastructure tells you where lines \textsc{may}, but not where lines \textsc{must}, be drawn between lexicalizable areas of meaning.

One feature of \figref{fig:4.3} is that there is no overlapping of the territory of different \is{lexicalization}lexicalizations; there is no such thing in GC as a sentence in which you could change the article of any NP without simultaneously changing the meaning. This generalization does not, of course, apply to English. In \textit{The dog is a mammal} you may change the article to anything you like without materially affecting meaning, and sentences such as \textit{there are no cows here} and \textit{there isn't a cow here} are synonymous. In fact, we may compare the GC situation shown in \figref{fig:4.3} with the English situation shown in \figref{fig:4.4}. % on the following page:

\begin{figure}
	\begin{center}
		\begin{tikzpicture}[baseline]
		
		% This figure needs some more exact measurements
		\node at (0,0) [rectangle split, rectangle split parts=2] (def) {+P +S\nodepart{two}``Definite''};
		\node at (4,0) [rectangle split, rectangle split parts=2] (indef) {--P +S\nodepart{two}``Indefinite''};
		\node at (0,-3) [rectangle split, rectangle split parts=2] (gen) {+P --S\nodepart{two}``Generic''};
		\node at (4,-3) [rectangle split, rectangle split parts=2] (oth) {--P --S\nodepart{two}``Other''};
		
		\node (gr1) [draw, fit=(def) (oth), inner xsep=1.25cm, inner ysep=1cm] {};
		\draw (gr1.north) -- (gr1.south); \draw (gr1.east) -- (gr1.west);
		
		% These are auxialiary nodes. I think the figure can be produced more elegantly, but I have not figured out the optimal way yet.
		
		\node [left=1em of gr1.west, fill=white, inner xsep=0cm, inner ysep=.25cm] (gr1west) {\it the};
		\node [left=3em of gr1.west] (gr1west2) {};
		\node [right=1em of gr1.east, inner ysep=0cm] (gr1east) {}; %inner ysep here is to prevent dashed lines from making "breaks" between ends of point.
		\node [right=3em of gr1.east] (gr1east2) {};
		\node [above=\baselineskip of gr1.north] (gr1north) {};
		\node [below=\baselineskip of gr1.south] (gr1south) {};
		\node [below=2\baselineskip of gr1.south, inner xsep=0cm] (gr1south2) {};
		\node [left=4.5em of gr1.west] (gr1west3) {};
		\node [below=3\baselineskip of gr1.south] (gr1south3) {\underline{\large  \hspace{.75em} \textit{s}}};
		
		
		\path let \p1=(gr1east), \p2=(gr1south2.base) in node at (\x1, \y2) [fill=white] (gr1SE) {\it a};
		%		\path let \p1=(gr1north.base), \p2=(gr1.north west) in node at (\x2, \y1) [right, fill=white] (gr1NW) {\it di};
		
		% fill=white in preceeding \paths and the following pgfonlayer is used so that dashed lines to not cross "wan" and "di"
		
		\begin{pgfonlayer}{bickertonbg}
		\draw [decoration={markings, mark=between positions 0 and 1 step 1 with {\arrow[line width=0.1mm, scale=2]{|}}}, postaction={decorate}, dashed] (gr1south.west)  -| (gr1west)  |- (gr1north.west) ;
		\draw [decoration={markings, mark=between positions 0 and 1 step 1 with {\arrow[line width=0.1mm, scale=2]{|}}}, postaction={decorate}, dashed] (gr1north.east) -| (gr1east) |- (gr1south2) -| (gr1west2.south);
		\draw [name path=draw1, decoration={markings, mark=between positions 0 and 1 step 1 with {\arrow[line width=0.1mm, scale=2]{|}}}, postaction={decorate}, dashed] (gr1west3.south) |- (gr1south3) -| (gr1east2.south);
		\end{pgfonlayer}
		
		\end{tikzpicture}
	\end{center}
	\caption{\isi{semantic space} for English articles}\label{fig:4.4}\is{articles}
\end{figure}

Here, \textit{the} has spread from +P +S to +P --S, on the basis of both ``defi\-nite'' and ``generic'' being +P, while \textit{a} has spread from --P +S to +P --S, but only by virtue of having first spread to --P --S, on the basis of both ``indefinite'' and ``other'' being --P; of course, once \textit{a} has reached ``other'' it can then spread to ``generic'' on the basis of their both being --S. In other words, a contiguity constraint\is{contiguity constraints} similar to that governing \figref{fig:4.2} obtains, preventing ``definite'' and ``other'', or ``indefinite'' and ``generic'', from being jointly lexicalized unless\enlargethispage{1\baselineskip} intermediate categories are also jointly lexicalized.

A similar spreading process of individual lexicalizations\is{lexicalization} across \isi{semantic space} could account for the variable ranges of lexical items
%\originalpage{250}
in the \is{location|(}location-existence-possession\is{possession}-ownership\is{ownership|(} area\is{existential|(}. Let us make the same assumption for that area as we made for articles: that the configuration that emerges in creoles is the primary configuration whenever articles appear (including, of course, in the original development of human language as well as in the development of every existing natural language). Then the primary configuration for the location, etc., area will be as shown in \figref{fig:4.5}. % below:

\begin{figure}[h]
	\begin{center}
		\resizebox{.75\textwidth}{!}{
		\begin{tikzpicture}[baseline]
		\node at (0,0) (ownersh) {Ownership \textit{(a)}};
		\node [below=4\baselineskip of ownersh] (possessi) {Possession \textit{(get)}};
		\node [right=4cm of ownersh] (locati) {Location \textit{(de)}};
		\node [below=4\baselineskip of locati] (existen) {Existence \textit{(get)}};
		\node [draw, thick, fit=(ownersh) (existen), inner xsep=2cm, inner ysep=1cm] (group) {};
		\draw [thick] (group.east) -- (group.west); \draw [thick] (group.north) -- (group.center);
		\end{tikzpicture}
	}
	\end{center}
	\caption{\isi{semantic space} for location, etc., in GC}\label{fig:4.5}
\end{figure}

The resemblance to the configuration of \figref{fig:4.3} is obvious. Again, two semantic areas are jointly lexicalized, while the remaining two are separately lexicalized. Again, as with \figref{fig:4.3}, we know that the pattern illustrated is one that is followed by most, perhaps all, creole languages, and one that cannot be explained by appeal to the structures of the languages that were in contact at the time the creoles came into existence. If this represents the primordial pattern, then those languages which separately lexicalize all four relationships would have reached that state by dividing and separately lexicalizing the two lower quadrants, while those that jointly lexicalize three or even four quadrants would have reached that state by procedures similar to those which spread \textit{the} and \textit{a} to the second and third quadrants, respectively, but without at any stage of the process jointly lexicalizing noncontiguous quadrants.

However, it remains to identify the \isi{semantic primes} by virtue of which the contiguity constraint\is{contiguity constraints} is maintained in the domain of Figures \ref{fig:4.2} and \ref{fig:4.5}. Clearly, the specificity prime, dominant in article systems, cannot be involved, for any entity must be marked as +specific before it can have existence, location, \isi{possession}, or ownership pre\-dicated of it. However, there is evidence that presupposedness, the next prime down, so to speak, may be crucially involved. Entities of which location and ownership can be predicated must be assumed known to the listener: compare \textit{the desk is in a corner} with *~\textit{a desk is in a corner}, or compare \textit{the briefcase is mine} with *~\textit{a briefcase is mine}. On the other hand, entities of which existence and possession can be predicated must be assumed unknown to the listener; thus, we have \textit{there is an answer} versus *~\textit{there is the answer},\footnote{The reading ``The answer is \textit{there}!'' is of course not intended.} and \textit{I have a cold} versus *~\textit{I have the cold} (the fact that the latter sentence is grammatical under contrastive stress, as in \textit{(It's) I (that) have the cold, not Mary}, is, of course, completely beside the point). 

Perhaps less clear here is exactly what the second prime in\-volved is. I shall suggest, very tentatively and provisionally, something I shall call ``relatedness''.  A claim that something exists entails no claim that that something is significantly related to anything else; similarly, a claim that something is located somewhere entails no claim that there is any significant connection between that something and its location. However, claims of \isi{possession} and ownership involve a substantive link of some kind, whether genetic (\textit{Bill has children}, \textit{those children are Bill's}), creative \textit{(Mary had an idea}, \textit{that idea was Mary's}), or of some other nature. We could then illustrate \isi{semantic primes} and their interrelationship as in \figref{fig:4.6}. %on the owing page:

%\originalpage{252}

\begin{figure}
	\begin{center}
		
		\resizebox{\textwidth}{!}{
		\begin{tikzpicture}[baseline]
		\node at (0,0) (1All) {All entities};
		\node [below left=2\baselineskip and 24mm of 1All] (2S) {--S};
		\node [below right=2\baselineskip and 24mm of 1All] (2S2) {+S};
		\draw (2S2) -- (1All.south) -- (2S);
		\node [below left=2\baselineskip and 24mm of 2S2] (3P) {+P \textit{(the)}};
		\node [below right=2\baselineskip and 24mm of 2S2] (3P2) {--P \textit{(a)}};
		\draw (3P2) -- (2S2.south) -- (3P);
		\node [rectangle split, rectangle split parts=2, below left=2\baselineskip and 3mm of 3P] (4R) {+R\nodepart{two}(ownership)};
		\node [rectangle split, rectangle split parts=2, below right=2\baselineskip and 3mm of 3P] (4R2) {--R\nodepart{two}(location)};
		\node [rectangle split, rectangle split parts=2, below left=2\baselineskip and 3mm of 3P2] (4R3) {+R\nodepart{two}(possession)};
		\node [rectangle split, rectangle split parts=2, below right=2\baselineskip and 3mm of 3P2] (4R4) {--R\nodepart{two}(existence)};
		\draw (4R) -- (3P.south) -- (4R2);
		\draw (4R3) -- (3P2.south) -- (4R4);
		
		\end{tikzpicture} 
		}
		
		\caption{Hypothetical tree structure for semantic primes}\label{fig:4.6}
	\end{center}
\end{figure}

%\originalpage{253}
This would enable us to define ownership as +P +R, location as +P --R, possession as --P +R, and existence as --P --R. If this were the case, no lexicalization could spread directly from ownership\is{ownership|)} to existence\is{existential|)} (or vice versa) or from location to possession (or vice versa), since in either case the process would involve simultaneously reversing the polarity of two semantic primes. The observed facts for this area would thus be fully accounted for.\is{location|)}

However, doubts about the status of ``relatedness'' -- which does not appear to figure crucially in any other semantic area, unlike presupposedness -- may make it worthwhile to consider an alternative explanation for these facts.

A slightly different kind of contiguity constraint\is{contiguity constraints} has recently been claimed by \citet{Keil1979,Keil1981}. The constraint envisaged by Keil derives from a structure which he terms a ``Predicability Tree''. A \isi{predicability tree} defines the range of different predication types over various \isi{semantic classes} of NP (see \figref{fig:4.7} on Page~\pageref{fig:4.7}). Each predication type ranges only over those classes of NP which it dominates in the structure. Thus, predications such as \textit{X is interesting} and \textit{X is thought about} can be made of any class of NP, while at the
%\originalpage{254}
furthest extreme, predications such as \textit{X is honest} and \textit{X is sorry} can be made only of the class of NP that is +animate, +human.

\begin{figure}
\begin{center}
	\resizebox{\textwidth}{!}{
		\begin{tikzpicture}[baseline,align=left]
		% First Column
		\node at (0,0) (1) {IS INTERESTING\\IS~THOUGHT~ABOUT};
		\node [below left=4\baselineskip and 2cm of 1, right, fill=white] (4) {IS~NEARBY\\IS~AT~THE~CORNER};
		\node [below left=4\baselineskip and 1cm of 4,right, fill=white] (redheavy) {IS RED\\IS HEAVY};
		\node [below left=4\baselineskip and 1cm of redheavy,right, fill=white] (tallskinny) {IS TALL\\IS SKINNY};
		\node [below left=4\baselineskip and .5cm of tallskinny, right, fill=white] (deadsick) {IS DEAD\\IS SICK};
		\node [below left=4\baselineskip and .5cm of deadsick, right, fill=white] (asleephungry) {IS ASLEEP\\IS HUNGRY};
		\node [below left=4\baselineskip and .5cm of asleephungry, right, fill=white] (honestsorry) {IS HONEST\\IS SORRY};
		% Connetion between 1st column
		\begin{pgfonlayer}{bickertonbg}
		\draw (1.south) edge [bend right=25] (honestsorry.100);
		\end{pgfonlayer}
		
		% Other Columns
		\node [below right=\baselineskip and 3.5cm of 1] (2) {love\\fear};
		\node [right=2cm of redheavy] (hourlong) {IS AN HOUR LONG\\HAPPENED YESTERDAY};
		\node [below right=\baselineskip and 2.5cm of hourlong] (thunderstorm) {thunderstorm\\sunrise};
		\node [below right=4\baselineskip and 1cm of hourlong,left] (purpose) {IS ON PURPOSE\\IS X'S FAULT};
		\node [right=4em of 4] (3) {IS~ABOUT~X\\IS~TRUE};
		\node [below right=\baselineskip and 2.5cm of 3] (storyidea) {story\\idea};
		\node [right=2cm of tallskinny,right] (leaksout) {LEAKS OUT\\OF BOXES};
		\node [below right=2\baselineskip and 2cm of purpose] (fightkiss) {fight\\kiss};
		\node [below right=2\baselineskip and 2cm of leaksout] (milkwater) {milk\\water};
		\node [above right=.5\baselineskip and 1.25cm of deadsick,right] (fixedbroken) {IS FIXED\\IS BROKEN}; 
		\node [above right=.5\baselineskip and 1.25cm of asleephungry,right] (wilted) {IS WILTED\\BLOOMS}; 
		\node [below=2\baselineskip of milkwater] (carref) {car\\refrigerator};
		\node [below=2\baselineskip of carref] (flowertree) {flower\\tree};
		\node [below=2\baselineskip of wilted] (pigrabbit) {pig\\rabbit};
		\node [below=2\baselineskip of pigrabbit] (mangirl) {man\\girl};
		
		% Connections for other columns
		\draw [dashed] (1.south) -- (2.west); \draw (1.south) -- (3.north); \draw [dashed] (3.south east) -- (storyidea);
		\draw (4.315) -- (hourlong.150); \draw [dashed] (hourlong.south) -- (thunderstorm.west); \draw (purpose) -- (hourlong.south); \draw (redheavy.315) -- (leaksout); \draw [dashed] (purpose) -- (fightkiss.west); \draw [dashed] (milkwater.west) -- (leaksout); \draw (tallskinny) -- (fixedbroken); \draw [dashed] (fixedbroken) -- (carref.west); \draw (deadsick) -- (wilted); \draw [dashed] (wilted) -- (flowertree.west); \draw [dashed] (asleephungry) -- (pigrabbit); \draw [dashed] (honestsorry) -- (mangirl.west);
		
		
		% another versino of this image is here: http://www.yale.edu/cogdevlab/aarticles/morethingschange.pdf
		
		
		\end{tikzpicture}
	}
\end{center}
\caption{The predicability tree ({\it from \citealt[Figure~1]{Keil1979}})}\label{fig:4.7}
\end{figure}

Keil's predicability tree is based on work by Sommers (\citeyear{Sommers1959,Sommers1963}, etc.), which first pointed out the existence of what Keil calls ``the \isi{M constraint}''. The M constraint prevents any pair of predicates (A, B) from intersecting, i.e., A and B ``can never span terms in common and also have terms that just A spans and terms that just B spans'' \citep[16]{Keil1979}. It also follows from this that no predicate can span two noncontiguous sets of terms unless it also spans all intervening sets of terms.

Experiments carried out by Keil with children as young as kindergarten age suggest that the M constraint is unlikely to be learned by experience. Even the youngest children had somewhat truncated versions of the predicability tree, and such violations of the M constraint as were found tended to support Keil's hypothesis rather than disconfirm it. For example, children who claimed that \isi{dreams} were tall (thereby apparently violating the hierarchy of predicability) revealed under further questioning that they believed dreams to be physical objects: ``They're made out of rock'', ``They just got grass on them'', ``They turn white and go up in the sky'' were among their answers \citep[110]{Keil1979}. Thus, the violations arose through assignment of ``\isi{dreams}'' to an inappropriate category, rather than a violation of the hierarchy per se. Since children's output, as we have seen, is anything but isomorphic with their input, it cannot be claimed that the absence of M-constraint violations in their speech is merely a reflex of a similar absence in adult speech. There would appear to be no way in which they could negatively define the scope of predications as a result of inductive processes; thus, Keil's results further support the argument of \citet{Fodor1975}, referred to at the end of \chapref{ch:3}, that one could not learn the extensions of the predicates of a natural language unless one already knew the extensions of those predicates.

Although the M constraint is strikingly similar to the types of \isi{contiguity constraints} that we observed in connection with \isi{color terms} and the area of location, etc., it relates to predication (the
%\originalpage{255}
establishment of a relationship between two lexicalizations)\is{lexicalization} rather than delimiting the scope of lexicalization itself. Still, since \textit{have}, \textit{be}, etc., and their cross-linguistic equivalents are indeed predications, it may be that the predicability hierarchy affects permissible lexicalizations within that semantic area. We noted above that existence and possession could be predicated of all things, and thus would include the entire tree in their scope; location\is{location|)}, however, could only be predicated of classes dominated by the second node down (\textit{is nearby/at the corner}), while ownership could only be predicated of classes dominated by the third node down (\textit{is red/heavy}). Joint scope of existence and possession could therefore have favored their joint lexicalization, while the disjoint scopes of location and ownership would have favored disjoint lexicalization.

In the present state of our knowledge, there is no principled way to choose between the two explanations. Those explanations, however, have served to show us other ways in which \isi{semantic space} is struc\-tured, and suggest that the contiguity-constraint\is{contiguity constraints} approach may yield a rich store of insights into the massive conceptual infrastructure that underlies, and that alone could make possible, the simplest ``communi\-cative'' uses of language.\\\\

Before turning back to survey the growth of the syntactic struc\-tures that were based upon that infrastructure, we should look at one last area of \isi{semantic space} where contiguity constraints\is{contiguity constraints} arising from \isi{semantic primes}, rather than from the predicability hierarchy, appear to be operative. At the same time, problems that were deferred to the present chapter when we encountered them in \chapref{ch:2} (in connection with creole variability in the treatment of iteratives\is{iterative|(}) and again in \chapref{ch:3} (in connection with variable treatment of iteratives by children) may now be dealt with.

This area can best be understood if we start from those problems. Readers will recall that although a majority of creoles (including Guyanese Creole, which here as elsewhere will be taken as representative) merge iteratives with duratives in a single nonpunctual category,\is{nonpunctual aspect}
%\originalpage{256}
\ili{Jamaican Creole} (and perhaps one or two others) treats \is{iteratives} the same way as past punctuals, while S{\~a}o Tomense (and perhaps one or two others) treats iteratives the same way as futures (and perhaps other members of the irrealis category -- existing descriptions are too inadequate for one to tell).

As was seen in the discussion of \citet{BrockartEtAl1973} in \chapref{ch:3}, there is more than one way of looking at iteratives. From one viewpoint, an iterative predication such as \textit{John walks to work} ranges over an ill-defined series of instances in which John already has walked (and may be expected to continue to walk) to work. Since it does not represent a single event perceived as a unit (such an event as might be represented by \textit{John walked to work last Thursday}, say), it can be regarded as falling into the nonpunctual\is{nonpunctual aspect} category along with events perceived as extended and uncompleted processes (\textit{John is/was walking to work}).

But, from another viewpoint, each of the series of actions over which \textit{John walks to work} ranges is itself an isolated event seen as a unit. If one regards the nature of the units in the series as primary, rather than the fact that those units constitute a series, then iteratives can be perceived as falling into the punctual category.
\is{irrealis modality}
From yet a third viewpoint, one can point to the fact that while sentences like \textit{John worked yesterday} or \textit{John is working today} refer to specific occasions on which John worked or is working, sentences like \textit{John works} do not. A sentence such as \textit{John works} may be true even if John is not working now and even if John works considerably less than the average person. The key to the difference here lies in what it takes to establish the truth value of an iterative predication. Let us look a little more closely at the problem of how we would assign truth value to the sentence \textit{John walks to work on Thursdays}.\is{truth values} 

We cannot falsify this sentence by pointing to a particular Thursday on which John did not walk to work. But we would be wrong if we assumed that the sentence means ``John walks to work on most Thursdays''. Not only does it not mean this, but it is also the case that the sentence could be falsified for any individual member of any set of Thursdays or for any combination of Thursdays (provided that such a combination did not equal the sum of all Thursdays) and still be true. Let us suppose that John drives to work every Monday, Tuesday, Wednesday, and Friday, and also on a majority of Thursdays, but on the remaining Thursdays, he walks to work. Then it is true that \textit{John walks to work on Thursdays} (but not on Tuesdays, Fridays, etc.). Moreover, let us suppose that John has only ever walked to work on one Thursday. In that case, the sentence \textit{John does not walk to work on Thursdays} is false and can be shown to be false by instancing the solitary occasion on which he did walk to work on a Thursday. If that sentence is false, its converse, \textit{John walks to work on Thursdays}, must be true, no matter how uninformative or misleading it might appear to be. 

It should be obvious then that predications of the iterative class do not refer to events in the same kind of way that other types of predication refer to them. \textit{John walked to work last Thursday} is true if and only if John walked to work last Thursday, and \textit{John is walking to work today} is true if and only if John is walking to work today. In fact, we could claim that \textit{John walks to work on Thursdays} does not refer at all to any specific events, but rather to a generalized concept which may be based on one or more such events. Since the realis category embraces real events in real time, it could be concluded that iterative ``really'' belongs in the irrealis\is{irrealis modality} category.

The foregoing paragraphs constitute an informal account of the relationship between iterative\is{iterative|)} and the nonpunctual\is{nonpunctual aspect}, punctual, and irrealis categories. The question is now whether, in terms of well-motivated semantic primes, we can show formally how those categories would interact in an analogue of the relevant area of \isi{semantic space}.

The status of punc\-tu\-al-nonpunctual and realis-irrealis\is{irrealis modality} as semantic primes will be dealt with a little later on in this chapter, when we try to see whether the ordering of TMA markers can be accounted for in evolutionary terms. For the present analysis we need only these and one other primary distinction which has already been independently established, i.e., specific-nonspecific. Predications like  \textit{John works} or
%\originalpage{258}
\textit{John walks to work} may be regarded as having the same relationship to predications like \textit{John worked yesterday} or \textit{John is walking today} as generic NPs\is{generic NP} have to particular-reference NPs, or as concepts do to percepts. In other words, habituals are --specific, while nonhabituals are +specific.

The SNSD\is{specific-nonspecific distinction (SNSD)} thus crosscuts the area of \isi{semantic space} which includes the punctual-nonpunctual\is{nonpunctual aspect}\is{punctual-nonpunctual distinction (PNPD)} and realis-irrealis\is{irrealis modality} distinctions. In order to adequately represent this situation, we would require a three-dimensional model, but for convenience we will represent the SNSD as a square boundary within a larger square, as shown in \figref{fig:4.8} on Page~\pageref{fig:4.8}. Since, as has been stated already, semantic infrastructure determines where conceptual boundaries \textsc{may}, but not where they \textsc{must}, be drawn, the configuration of \figref{fig:4.8} leaves the three analyses of Figures \ref{fig:4.9}.9(a), (b), and (c) (p.~\pageref{fig:4.9}) as further possibilities.\is{English!tenses}

Analysis (a) of \figref{fig:4.9}.9 corresponds to the Guyanese (majority creole) analysis; analysis (b), to the \ili{Jamaican Creole} analysis; and analysis (c), to the \ili{S\~ao Tomense} analysis. It leaves open, of course, a fourth analysis: that of English, \ili{Yoruba}, and a number of other languages which would correspond to \figref{fig:4.8}. In this analysis, habituals are separately grammaticized (\textit{John works}) from continuatives (\textit{John is working}), punctuals (\textit{John worked}), and various kinds of irrealis\is{irrealis modality} (\textit{John will work}, \textit{John would work}). It should be noted, however, that the Romance languages in general follow the analysis of \figref{fig:4.9}.9(a), the majority creole analysis, merely superimposing upon it the past-non past distinction: \ili{Spanish} \textit{yo  trabajo} means `I am working' or `I work', while \textit{yo trabajaba} means `I was working' or `I worked (habitually)', and in consequence, \textit{yo trabaj} is limited to `I worked (punctually, on a particular occasion)'.\\\\

\begin{figure}
\begin{center}
	\begin{tikzpicture}[baseline, every node/.style={rectangle split ignore empty parts=false}]
	\node at (0,0) (habitu) [rectangle split, rectangle split parts=3] {(habitual)\nodepart{two}\nodepart{three}--S};
	\node (habitualfit) [draw, fit=(habitu), inner sep=1cm] {};
	\node (conditiona) [above right=\baselineskip of habitualfit.north east, rectangle split, rectangle split parts=3] {(conditional)\nodepart{two}\nodepart{three}+S}; 
	\node (pas) [above left=\baselineskip of habitualfit.north west, rectangle split, rectangle split parts=3] {(past)\nodepart{two}\nodepart{three}+S}; 
	\node (cont) [below left=\baselineskip of habitualfit.south west, rectangle split, rectangle split parts=3] {+S\nodepart{two}\nodepart{three}(continuous)}; 
	\node (futu) [right=2\baselineskip of habitualfit.340] {(future)};
	\node (group) [draw, fit=(pas) (cont) (conditiona), inner sep=3\baselineskip] {};
	\draw (group.south) -- (habitualfit.south); \draw (group.west) -- (habitualfit.west); \draw (group.north) -- (habitualfit.north);
	\node [above left = .5\baselineskip of group.north]  {+R}; \node [above right = .5\baselineskip of group.north]  {--R};
	\node [below left = .5\baselineskip of group.south]  {+R}; \node [below right = .5\baselineskip of group.south]  {--R};
	\node [above left = .5\baselineskip of group.west]  {+P}; \node [below left = .5\baselineskip of group.west]  {--P};
	\node [below=3\baselineskip of group.south] {(R = realis, P = punctual, S = specific)};
	\end{tikzpicture}
\end{center}
\caption{\isi{semantic space} around habituals}\label{fig:4.8}
\end{figure}


% SOMETHING IS WRONG HERE (reporting floatrow package error related to \caption)
%\begin{center}
	\begin{sidewaysfigure}[h]
		\begin{minipage}{6cm}
			\resizebox{6cm}{!}{
			\begin{tikzpicture}[baseline]
			\node at (0,0) (PR1) {+P+R} ;
			\node at (4,0) (R1) {--R} ;
			\node at (0,-4) (PR2) {--P+R} ;
			\node at (4,-4) (R2) {--R} ;
			\node (gr1) [fit=(PR1) (R2), draw, inner sep=2em] {};
			\node at (2,-2) (P1) [inner sep=2em] {--P}; \draw (P1.west) |- (P1.north) -| (P1.east) |- (P1.south); %horizontal centering seems to be off for P1
			\draw (gr1.north) |- (P1.north); \draw (gr1.west) -- (P1.west); \draw (P1.south) -| (gr1.south);
			\node [below=\baselineskip of gr1.south] (legend) {(a)};
			\end{tikzpicture}
			}
%			\caption{(a)}
		\end{minipage}	
		\begin{minipage}{6cm}
			\resizebox{6cm}{!}{			
			\begin{tikzpicture}[baseline]
			\node at (0,0) (PR1) {+P+R} ;
			\node at (4,0) (R1) {--R} ;
			\node at (0,-4) (PR2) {--P+R} ;
			\node at (4,-4) (R2) {--R} ;
			\node (gr1) [fit=(PR1) (R2), draw, inner sep=2em] {};
			\node at (2,-2) (P1) [inner sep=2em] {+P}; \draw (P1.west) |- (P1.south) -| (P1.east) |- (P1.north); %horizontal centering seems to be off for P1
			\draw (gr1.north) |- (P1.north); \draw (gr1.west) -- (P1.west); \draw (P1.south) -| (gr1.south);
			\node [below=\baselineskip of gr1.south] (legend) {(b)};			
			\end{tikzpicture}
			}
%			\caption{(b)}
		\end{minipage}
		\begin{minipage}{6cm}
			\resizebox{6cm}{!}{
			\begin{tikzpicture}[baseline]
			\node at (0,0) (PR1) {+P+R} ;
			\node at (4,0) (R1) {--R} ;
			\node at (0,-4) (PR2) {--P+R} ;
			\node at (4,-4) (R2) {--R} ;
			\node (gr1) [fit=(PR1) (R2), draw, inner sep=2em] {};
			\node at (2,-2) (R3) [inner sep=2em] {--R}; \draw (R3.south) -| (R3.west) |- (R3.north); 
			\draw (gr1.north) -| (R3.north); \draw (gr1.west) -- (R3.west); \draw (R3.south) |- (gr1.south);
			\node [below=\baselineskip of gr1.south] (legend) {(c)};
			\end{tikzpicture}
			}
%			\caption{(c)}
		\end{minipage}
		\label{fig:4.9}
		\caption{Alternative analyses of habitual space}
	\end{sidewaysfigure}
	
%\end{center}

We now have a vague inkling (probably little more than that, as it may turn out) of the complexities of \isi{semantic space}: a space that had to come into existence before language as we know it could be born. Some of that space was required for the very first, earliest, and simplest stages of language. Other parts, although they were not
%\originalpage{261}
immediately required, probably came into existence prior to the emergence of language, as we shall see, but were only incorporated into language as language grew. Yet other parts may only have come into existence subsequent to the initial stages of language development. However, I suspect that such parts, if they exist, will prove to be minor, and that the common notion, more often implicit than explicit (if made explicit, it is hard to defend), that language bootstrapped its way upward, creating the conceptual categories it needed as it grew, producing thought, consciousness, and volition as mere epiphenomena, is simply false.

As I try to develop the scenario of how a language based on the conceptual categories we have surveyed could have developed, I shall incur a heavy debt to a seminal work in glottogenesis, \citet{Lamendella1976}. This paper represents the first systematic attempt to use the development of language in the child as a possible model for the development of language in the species. Lamendella claims that ``ontogeny manifests a repetition of several phylogenetic stages in the neurofunctional system that allows human infants to learn languages''. In his case, as in mine, ``it strains credulity to pretend that language as we know it \textit{suddenly sprang up intact as a cultural invention} in the absence of \textit{extensive cognitive and communicative preadaptations}'' (emphasis added); he envisages, accordingly, a series of hominid species, each developing a particular element or stage of language and then transmitting that development to the next species via the genetic code. 

Lamendella defends the foregoing model against accusations of Lamarckism by pointing out that in all species, individual members show differences in their capacities. Thus, at any given stage of the development toward full language, relatively slight differences in the associated capacities would have conferred a selective advantage on their possessors, so that there would have developed ``a concentration of genotypes producing [these capacities] in the gene pool of the species''. Thus, the average capacity of the hominid line at stage \textit{n}+1 would have equaled the maximum capacity at stage \textit{n}, and the
%\originalpage{262}
biological foundations of language would have been laid down, not in a single cataclysmic event, but in an ordered series of steps.

This series would then necessarily repeat itself in the course of child acquisition since, as Lamendella points out, ``more recently encoded genetic information generally tends to unfold later in ontogeny so as to preserve the temporal sequence in which the new components of the genetic information code were laid down''. Lamendella is careful to show that his claims do not fall under the two main criticisms to which early recapitulationist\is{recapitulationism} theories in biology were subject. First, he points out that ``embryonic'' stages of language may reproduce not the developmental stages of \textit{adult} language but the language of children at corresponding stages. At any stage, adults using general-purpose strategies might have developed language beyond the range of contemporary children, although without being able to transmit such developments via the genotype. Second, he is aware that embryological features do not always or necessarily occur in the same order as their corresponding evolutionary\is{evolution|(} features, so that the developmental stages of child language do not necessarily occur in the same order as corre\-sponding stages in the original development of language.

\largerpage[-1]
With regard to this latter point I think that Lamendella is too cautious. Recapitulationist theory in general biology had to cover a very wide range of phenomena, many of which were only very re\-motely connected. Consider any pair of such phenomena, say, dentition and the structure of the foot in a given species. Clearly, these two things are not wholly unconnected since we do not normally find herbivores with claws or carnivores with hooves. However, within both herbivorous and carnivorous species there is quite a wide range of tooth and foot structures, detailed development of each of which must have proceeded with a good deal of independence from the other. It should therefore be unsurprising that on occasion the precise sequence of developments should have been shuffled somewhat between phylogeny and ontogeny -- that, for example, in a given phylum, a certain type of tooth might have developed earlier than a certain type of foot, but that, in the embryonic forms of some contemporary species, that type
%ORIGINS 263
of foot might develop earlier than that type of tooth. However, when we are dealing with the development of language, we are dealing with a very tight subsystem of neural structures rather than with a wide range of quite dissimilar physical features; and within such a sub\-system, a high degree of mutual interdependence might be expected to obtain. We would expect, therefore, that reversals of phylogenetic ordering in the ontogeny of language would be quite rare, if indeed any exist at all.

I shall not examine in detail the stages that Lamendella proposes, which differ in some respects from those to be suggested here; his work was carried out from a slightly different perspective and his conclusions are worthy of study in their own right. I shall return to the last of our speechless ancestors, whose cognitive equipment need not have differed in any material respect from that of the contemporary great apes.

Earlier in this chapter reference was made to the question why, if there was such massive preadaptation for language, it did not arise earlier. Attempts to account for this fact often take the form of simply pointing to the parlous state of hominids\is{hominids|(} expelled from an arboreal Eden and forced to compete with fitter predators; the compensatory advantage offered by language then seems self-evident. But evolution does not behave like the U.S. Cavalry; if it did, it would surely have ridden to the rescue of the \isi{gorilla}, now threatened more seriously by our species than our species was ever threatened by others. Need does not create function unless that function is already within a species' grasp.

This view might seem to directly contradict the view expressed earlier that intense interspecific competition may have rapidly expanded the cognitive capacities of our species. In fact, there is no contradiction. Cognitive growth -- the increase in the capacity of creatures to analyze the environment and predict outcomes -- has always been the major thrust of evolution, and to claim this is in no sense to be guilty of teleology, since the more cognitively developed any species
%\originalpage{264}
becomes, the greater would be its chances of survival. Thus, the hominid line may have been capable of a relatively rapid growth of cognitive capacity, precisely because there was already a broad evolutionary\is{evolution|)} base to build on. But there could be no basis to build on with regard to language, since the kind of cognitive capacity hominids were only now building -- the conceptual capstone, so to speak, on the vast arch of perception that had been building ever since the first microorganism responded to light or to the touch of another -- was the necessary prerequisite for the most rudimentary form of language.

Yet the question remains. If apes have adequate prerequisites for at least a fraction of what we have in the way of language, then the probability is that \textit{Dryopithecus} had similar prerequisites, and that gives a period of at least five million years in the pongid line, and \textit{x} million years in the hominid line, in which the capacity for language existed, and the need for language existed, but there was no language.

Here we must consider the channel problem. However refined the conceptual schemata, however detailed and accurate the cognitive map\is{cognitive mapping} that a species can construct, it will profit that species little (except in terms of individual survival) unless there is also a mode of expression. The only two modes of expression that seem to have even a chance of being viable for primates are the vocal and the manual\is{manual channel}\is{vocal channel}. Without full cortical (consequently voluntary) control over one or another of these channels, language as communication would not have been possible.

However, the channel problem has quite another dimension, a dimension seldom referred to but equally critical. This dimension is, in fact, twofold. We will take the second half and then the first half. The second half is: when A, the first hominid ever to use either a sound sequence or a gesture referentially, made such sequence or gesture to B, another hominid, how did B know that A was communicating referentially, and not merely coughing, clearing his throat, scratching himself, or brushing a fly away? The first half is: given the same situation, how did A, totally ab ovo, conceive the idea of representing some object or event in the environment in terms of a sound sequence or gesture -- an act unprecedented since the Big Bang?

%\originalpage{265}

These problems cannot be dismissed by hand-waving. Either language began as a consciously intended performance, in which case we have to show both how the intent could have been formed and how a conspecific could have grasped both the fact that there was an intent and the reference that was intended, or it began accidentally. Although it is no aim of this chapter to add to the already overlong list of Flintstone\is{Flintstones approach@``Flintstones approach''} scenarios, one of the (possibly numerous) ways in which language could have arisen accidentally is the following: Mrs. Og, breast-feeding a lusty one-year-old with one hand, is trying to feed herself with the other. Young Og, ready for a change of diet, makes a grab for the meat. Mrs. Og pushes him away. He tries harder, babbling in his frustration: \textit{gaga}. His stubbornness amuses Mrs. Ug, sitting nearby, and she imitates \textit{gaga} and maybe makes a playful grab for the meat. For a while after that, the favorite joke in the tribe is to creep up on somebody, shout \textit{gaga}, and try and grab his or her meat. Perhaps it dies out, as jokes do. Perhaps words were found and lost and found again a score of times before they took root, or perhaps the slightly older kids picked it up and began to use it seriously when they got hungry or when they thought the grown-ups were dividing the food unfairly.

Or a slight variant on this: Ig, young Og's uncle, is pretending to be a tiger, an avuncular activity still widespread today and presumably of no very recent evolutionary history. Young Og withdraws in real or simulated fear, shouting \textit{wawa!} Uncle Ig imitates him, and again every one laughs, but tigers are not everyday occurrences, so the thing is quickly forgotten. But a couple of days later Ig sees a real tiger about to pounce on Og. By a sheer fluke he yells out \textit{wawa!} instead of the regular alarm call, and Og saves himself in the nick of time. Maybe they and the rest of the band are able to kill the tiger, and dance and embrace around its carcass like European soccer players after a goal, shouting \textit{wawa!} And the word, perhaps soon followed by others of a similar nature, gets incorporated into the earliest of human rituals; for, as \citet{Marshack1976} insightfully observed, ``Language, in fact, may have been as useful, or more useful, in this cultural realm than in the comparatively self-evident strategies utilized in hunting, butchering and gathering''.

%\originalpage{266}

Many such scenarios could be elaborated, all equally probable (or improbable). How the Rubicon was crossed is of minor concern; what matters is how it was reached and what happened after it was crossed. But origin stories like these which feature ludic and jocular components do have some advantages. First, they do not require intent on anybody's part, and since they do not require intent, they do not require understanding, at least in the everyday sense of that term. Thus, they neatly avoid both halves of the understanding-intentionality problem referred to a few paragraphs earlier. Secondly, they are based on behaviors -- imitative and joking behaviors -- which are independently attested for other members of the primate family and which therefore must have been common to all our immediate ancestors. Thirdly, they provide an element which may be essential in the acquisition of lan\-guage anywhere in the universe: external modeling\is{language!external modeling of}.

It is not, I think, accidental that chimps\is{chimpanzee} did not acquire language until we taught them. It cannot be the case that they lacked the intelligence to invent it, since they can use it creatively (within, admittedly, quite narrow limits) once their pump has been primed, so to speak. It could be that the conceptual leap is too great to be made in a single stride by any species -- that some kind of external model is needed, whether that model is intentional (as was the case with human teaching of apes) or unintentional (by young human children, as in the stories above); otherwise, the whole idea of referential communication would have been just too radical to work out (in either sense of \textit{work out}). But if this is so, there is a channel block for the pongid line that did not exist for the hominid line.

In other primates, vocal outputs have not come under sufficient cortical control for the \isi{vocal channel} to be viable for linguistic use; the great apes cannot suppress spontaneous vocalizations, have very little if any capacity for voluntary vocalization, and ``show little or no ability to imitate sounds'' \citep{Dingwall1979}. But if hominids could have imitated and assigned meaning to the spontaneous vocalizations of children, why could not chimps\is{chimpanzee} or other primates have done the same with their own infants' spontaneous gestures?

%\originalpage{267}

If we replay the two scenarios given above with an ape cast, the reason will become obvious. Instead of \textit{gaga} for `meat' or more probably some more general `food', you would have had some kind of grabbing motion. Instead of \textit{wawa} for `tiger' you would have had some kind of fear behavior. Paradoxically, infant gestures could not have served as proto-words \textit{because they were not arbitrary enough}. For the first signs to have had a narrow enough range to fit individual concepts, they must have had \textsc{no range}, have been quite empty, communicatively speaking, so that they could be filled by the particular reference of the immediate context, by ``food'' or ``tiger'', as the case might be. You could not use a grabbing motion as a symbol for food because there were so many other things you might grab for. You could not use a fear gesture as a symbol for a tiger because there were so many other things you might be afraid of. But something that had no clear meaning for the parent, such as a child's pre-speech utterance, could be hooked to any of the hominid's preexisting concepts precisely because it lacked any such general associations.

There would be little point in spending so much time on the actual emergence point of language if the suggestions just given were not a logical outgrowth of all that we have already discussed. The major point of this chapter has been that language grew out of the cognitive system used for individual orientation, \isi{prediction}, etc., rather than out of prior communicative systems. It would follow from this that the most likely means of expression, when this cognitive infrastructure finally emerged as a communicative system in its own right, would have been one which was quite separate from, and unlikely to be confused with, the prior system. True, both hominid calls and hominid proto-words would have been in the \isi{vocal channel}, but the acoustic ranges of the modern ``call system''\is{call systems} -- shrieks, laughter, etc. -- and those of speech sounds do not overlap and very likely have never overlapped.

Once the Rubicon was crossed, progress may well have been rapid, a matter of a few generations, since the necessary infrastructure for a fairly rudimentary level of language would have already been in
%\originalpage{268}
place. Chimps\is{chimpanzee!language capacities of} have progressed (with training, granted) from one-word to several-word utterances in a matter of months, so I suspect that the one-word, two-word, etc., stages of early child development do not necessarily reflect stages in adult language development, but rather rehearse cognitive growth stages in the hominid\is{hominids|)} line that \textsc{preceded} the emergence of language. Not a lot turns on this, either way, and even how we would decide between the two alternatives is at present very far from being clear. But somehow the idea of our ancestors communicating via one-word utterances for several millennia while awaiting the growth of the requisite neurological infrastructure (whatever that might have been!) that would permit them to add word two to word one falls short of being wholly persuasive. In the absence of any evidence to the contrary (but bearing in mind the possibility\is{hominids!possible language capacities of} that such evidence might appear at any time) we will conclude that in the first flush of language, our ancestors were able to get about as far as chimps\is{chimpanzee} have; that is, they could:

%\setcounter{itemize}{0}
\begin{itemize}
\item[(a)] Lexicalize concepts corresponding to classes of sensorily perceptible entities and sensorily perceptible attributes of entities (things like \textit{color} and \textit{size} as opposed to things like \textit{courage} and \textit{justice}).
\item[(b)] Lexicalize secondary concepts by conjuncts of primary concept names.
\item[(c)] Organize brief (up to 3--5 word) utterances on a predominantly topic-comment basis (i.e., proceeding from the proximal to the distal, the old to the new, more or less irrespective of case-role relations).
\item[(d)] Despite (c), distinguish in a pinch between X-Vs-Y and Y-Vs-X sequences (e.g., form appropriately, and react appropriately to, the difference between \textit{Roger tickle Lucy} and \textit{Lucy tickle Roger}, in at least a majority of cases).
\end{itemize}

On the other hand, it is likely that they, in common with modern primates, were not able to:
%\originalpage{269}

%\setcounter{itemize}{4}
\begin{itemize}
\item[(e)] Produce utterances of more than one clause.
\item[(f)] Grammaticize even the most basic semantic distinctions, such as those of tense, plurality, possession, etc.
\end{itemize}

These two capacities are, as I shall try to show, phylogenetically linked. Together they constitute minimal requirements for anything even approaching the kind of language we have today, and the reluctance of many linguists and psychologists to accept that, lacking them, modern apes could be capable of language, is very understandable. However, such linguists and psychologists feel under no obligation to give an account of how language was initially acquired, which makes things easier for them, but does not do anything toward helping us to understand ourselves. What apes have, what our ancestors had, you may or may not call language, but it seems to me simply bizarre to suppose that it wasn't something that you had to have in order eventually to have languages like those of today. Those who disagree have no right to do so unless they can provide a more plausible route to our present situation.

\citet{Seidenberg1979}, in reviewing (pessimistically) the linguistic achievements of apes, make the point that no convincing evidence has yet been provided that an ape can use a sign for any object that is not in its immediate environment. This is equally true of children's language in the first few months of acquisition, of course; and indeed, with only (a)--(d) as one's resources, it is hard to see how reference could escape from the prison of the here-and-now. But being able to talk, if only about the here-and-now, is an immense advantage for children, and was presumably at least an equal advantage for our forefathers, over not being able to talk about anything at all. You could convey highly specific warnings, bring about cooperative behavior, settle disputes, even construct primitive rituals. In rituals, displacement begins; the head of the cave-bear\is{cave-bear} on a pole stands for all the cave-bears who control the warm caves you will need in order to get through the next Ice Age. But it is one thing to be able to think displacement, and quite another to be able to talk it.

%\originalpage{270}

Consider the following situation. You are Og. Your band has just severely wounded a cave-bear. The cave-bear\is{cave-bear} has withdrawn into its cave. Ug wants to go in after it. ``Look blood. Bear plenty blood. Bear weak. Ug go in. Ug kill bear. Ug plenty strong''. You want to be able to say something along the lines of \textit{the bear we tried to kill last winter had bled at least as much as this one, but when Ig went in after it to finish it, it killed him instead so don't be such an idiot}. Since in order to think this all you had to be able to do was to replay the memory of events you yourself had witnessed, I can see no reason to believe that you could not have thought it because you didn't have the words to think it in. But saying it is another story. Let's suppose you try. Since you have nothing approaching embedding, there is no way you can use a relative clause to let the others know which bear you are thinking about. Since you have no articles or any comparable device, there is no way you can let the others know that you are talking about a bear that they know about too. Since you have no way of marking relative time by automatic tense assignment or even adverbs, there is no way you can let the others know that the bear you want to talk about is one that is not here anymore. Since you have no verbs of psychological action (we'll see why in a moment), there is no way you can use the verb form itself to inform the others that you are speaking of a past time (\textit{remind}, \textit{recall}, \textit{remember}, etc.). You can try ``Og see other bear''. Everybody panics. ``Where? Bear where?'' ``Bear not here''. Some laugh, some get angry; Og's up to his practical joking again. ``Bear kill Ig'', you try. Now even the ones who are laughing are sneering. ``Ig! Ig dead! Og crazy!'' If you have any sense, you shut up, or someone will get the idea to push you into the cave instead of Ug.\\\\

It was mentioned earlier in the chapter that the power to predict\is{prediction} the course of future events was what gave a selective advantage to those species which developed their cognitive capacities, and that this power depended crucially on the power to categorize and analyze past events. Both powers in turn depend upon the quality of the cognitive map\is{cognitive mapping} --
%\originalpage{271}
its accuracy, degree of detail, and universality or lack of it. A language that could advance beyond the initial plateau of the here-and-now could potentially do two things which would lead to an exponential increment in the survival power of the species possessing it.

\is{comprehension strategies|(}First, it could code the cognitive map\is{cognitive mapping} in such a way that \isi{processing time} would be drastically reduced. One can think nonverbally, by processing images, or one can think verbally, using lexical items instead of images; in order to utter, or comprehend, or merely mentally construct the sentence \textit{John drove the tan Oldsmobile from Arkansas to Texas}, it is not necessary to frame mental images of John, or driving, or Oldsmobiles, or Arkansas, or Texas. A number of psychological experi\-ments (several referenced in \citealt{Hamilton1974}) have shown that where labels for objects are available, human subjects perform more effec\-tively and much more rapidly; for instance, \citet{GlucksbergEtAl1966} showed that solution times for label-aided as against label-free versions of a problem differed by a factor of fifteen to one. The mere fact that processing time is reduced automatically makes possible many analyses that could not previously have been attempted. For instance, where previously there might have been only time to model a single hypothetical solution to a practical problem (such as that of dealing with an angry cave-bear\is{cave-bear} in its cave without getting killed in the process), there is now time not only to model several hypothetical solutions but also to compare them and make a choice on the basis of that comparison.

Second, it could make solutions available to other members of the species. Cognitive development without the power to communicate the results achieved by it may serve the survival of the individual but cannot serve the survival of the group. You could remember about the bear that killed Ig, but if there is no way in which you can convey your thinking to Ug, then the odds are that although you won't get killed, Ug will, and so will lots of Ug's children and grandchildren. True, your smart genes will multiply, while their dumb ones won't, but all that will do is bring a little bit nearer the time when the species will break through the here-and-now barrier and achieve, not just
%\originalpage{272}
predictability, but the dissemination of predictability -- the unique capacity that launched a single primate species on its unprecedented career.\\\\

Let us consider some fairly minimal requirements that language  must have satisfied before it could emancipate itself from the here-and-now. First, the structure of one-clause sentences must have been stabilized. It must have been stabilized because freely variable word-order\is{word order} minus case-marking devices equals growing ambiguity as two-and three-clause sentences develop. In fact, word-order cannot have stabilized \textit{so that} longer sentences should be unambiguous; there must have been some motivation at the single-clause level. Let us consider what such motivation might have been.

To begin with, we need to look at something apparently quite unconnected with sentence-order -- that is, \isi{word-formation}. Although there is an extensive and controversial literature on the range of distinctive speech sounds that early species (in particular, Neanderthal man) could have produced -- see \citet{Spuhler1977} for references -- there can be little doubt that that range was considerably smaller than the range of our own species. Let us assume a capacity for five consonants and three vowels (not much less than the range of modern Hawaiian, with eight consonants and five vowels) together with CV syllable structure; this would give a maximum capacity of only 15 monosyllabic words and 225 disyllabic words. Moreover, all languages we know of under-utilize their inventories, leaving numerous lexical gaps, so that the practically attainable total would be lower still. Factors such as these would encourage use of the same lexical item in causative and non-causative senses. In that case, as we saw in Chapters \ref{ch:2} and \ref{ch:3}, only the frames N\textsubscript{ii}V and N\textsubscript{i}VN\textsubscript{ii} (where N\textsubscript{ii} is nonagentive and N\textsubscript{i}, agentive) would distinguish causative from noncausative\is{causative-noncausative distinction (CNCD)} senses of V.

Let us now consider a hypothetical word, \textit{keke}, which means `die' in the context N \textit{keke}, but `kill' in the context N \textit{keke} N. We have assumed that the first word-order in early language was topic-comment,
%\originalpage{273} 
with shared, old information first (or zeroed) and nonshared information second. There is now a potential conflict. Let X be old information and Y new information, and let it be the case that Y killed X. Topic-comment order would then call for \textit{X keke Y}, equivalent to `X was killed \textit{by} Y'. However, \textit{X keke Y} would also correspond to the structure N\textsubscript{i}VN\textsubscript{ii}, in which V has its causative sense and N\textsubscript{i} is agentive -- yielding an alternative reading, `X killed Y'. In theory the conflict might be resolved by adopting either strict topic-comment or strict SVO order, but since the latter holds less chance of ambiguity than the former, and is therefore fractionally more economical in processing time, we can assume either that it was universally adopted or that those languages that failed to adopt it died without issue. In fact, languages that did fail to adopt SVO must surely have died out when the strict-order languages achieved embedding and complex structure; it is tempting, although quite futile, to speculate that what caused the large size of the Neanderthal cranium was the apparatus needed to process (and store in short-term memory) multiply-ambiguous parsings of multiclause sentences in which the constituents were not systematically ordered.\is{word order}

If we accept Lamendella's hypothesis, there is support for the foregoing picture from acquisition\is{language!acquisition of} processes. \citet{Bever1970} has demonstrated the existence of what he terms ``Strategy C'' -- ``Constituents are functionally related internally according to semantic constraints'' -- and ``Strategy D'' -- ``Any Noun-Verb-Noun (NVN) sequence within a potential internal unit in the surface structure corresponds to actor-action-object''. Experiments carried out by Bever and his associates indicate that children between two and three rely on Strategy C to comprehend sentences but that a little later they switch to Strategy D. This serves to explain the otherwise quite baffling fact that children's performance with regard to sentence types which involve nonagentive initial NPs (passives\is{passive}, clefts)\is{clefting} actually deteriorates rather than improves between three and four.

The acquisitional sequence Strategy C-Strategy D would then replicate stages in the early development of language. Strategy C would have had to be developed in order to interpret case roles in the stage
%\originalpage{274}
in which topic-comment ordering\is{word order} was dominant. Strategy D would have succeeded it as soon as sentence-order stabilized and became the primary marker of case relations. Note that, originally, adoption of Strategy D would have had none of the dysfunctional side effects that it does nowadays with children acquiring English since, at that time, there were no passives\is{passive} and no clefts\is{clefting}; Strategy D would have given the right answer every time.

We can assume that neural modifications accompanied the change. What these may have been is still beyond anyone's power to determine; what they would have had to be able to accomplish is slightly less opaque. There is no evidence that SVO ever got hardwired into the system, but assignment of case roles must have become automatic, and underlying this must have been a hierarchy of cases with the rank-order, \textit{agent-experiencer-patient} -- subjecthood in any given sentence being assigned to the highest-ranking case in that sentence. Also, if the ape experiments are anything to go by, speech would have had to be speeded up considerably (\citet{RumbaughEtAl1976} report a human-chimp\is{chimpanzee} conversation of only twenty-one sentences which took nine minutes): more rapid processing would presumably have required qualitative as well as quantitative increases in neurons and neuron connections.\is{neural infrastructure}

So far we have assumed a limit of two case roles per sentence. However, this does not mean that there were only two case roles in the hominid\is{hominids} repertoire. Insofar apes can use tools and give things to one another, one must assume that cases such as instrumental and dative are potentially within their grasp. But problems arise once a third case role is added.

Any two case roles can be ordered around V so that the higher of the two precedes V and the lower follows. But presence of a third means that two NPs must be conjoined. This creates \isi{parsing problems}. If you want to say something like \textit{Ug gave Ig's meat to Og}, there are three possible ways in which you can overcome these problems.

You can indicate the oblique cases with prepositions, or postpositions, or some other purely grammatical case-marking device.\is{comprehension strategies|)}
%ORIGINS 275

In \textit{Ug gave Ig's meat to Og}, \textit{'s} marks the genitive and \textit{to}, the dative case. It is perhaps possible, but highly unlikely, that our predecessors could have invented grammatical case marking ab ovo; even in many synchronic languages, case markers can be traced back to original content which have been bleached of their original semantics and downgraded from their original syntactic roles.

In the absence of grammatical marking, you can simply string case roles together and hope that Strategy C -- which must simply be overridden, not erased, by Strategy D -- will suffice to parse the result. In most cases it may, but in many it will not. The sentence introduced above, for example, would come out as \textit{Ug give Ig meat Og}, which might be parsed as `Ug gave Ig's meat to Og' but could also be parsed as `Ug gave Ig the meat of Og'. Note that parsing mistakes in \isi{discourse} must be cumulative; the listener who thought Ig got Og's meat and the listener who thought Og got Ig's meat would put quite different constructions on the sentences that followed.

The third alternative would be to preserve the two-case-roles-per-sentence restriction and conjoin sentences: \textit{Ig have meat, Ug take meat, Ug give Og}. This is cumbersome but unambiguous. But note that if the second occurrence of \textit{Ug} is omitted, you get \textit{Ug take meat give Og} -- the same serial structuring of dative-incorporating sentences that we found as a frequent feature of creoles in \chapref{ch:2}.

In fact, verb serialization, probably arising out of paratactic\is{parataxis} conjunction plus equi-deletion, represents the only plausible means by which early language could have broken out of single-clause structure. It is difficult for us now to appreciate the magnitude of the advance that was involved. The single-clause apelike proto-language was, as we have said, almost certainly limited to dealing with physical activities in the here and now. Sentences representing mental activities almost always demand more than one clause. If we say that something happened \textit{when} something else happened, or will happen \textit{if} something else happens, or happened \textit{because} something else happened, we are representing not something that we have perceived directly through the senses, but the result of some kind of mental computation performed
%\originalpage{276}
on sensory inputs (or, to be more precise, on things that originated as sensory inputs but that have already had a lot of processing done to them, along lines suggested earlier in this chapter). Still more clearly, if we \textit{remember}, or \textit{believe}, or \textit{think}, or \textit{hope}, or \textit{expect} that something happened or will happen, or if we \textit{want} or \textit{hope} or \textit{decide} to do some\-thing, we are again directly representing a mental operation on the product of past inputs or the projected product of possible future ones, and in either case, one that cannot be expressed in a single clause. The gap between monopropositional sentences and \isi{multipropositional sentences} is the gap between talking only about observables in the external world and communicating the contents of one's mind. And the bridging of that gap must have constituted the greatest single step in what anthropologists mean by the ugly terms ``hominization'' or ``sapienization'' -- the process of becoming the kind of species that we now are.

Verb serialization\is{verb serialization} helped to bridge this gap, and the way in which it accomplished this is worth looking at a little more closely. At first glance, the results of verb serialization may look a little like those underlying structures that were once proposed by generative semanticists in which verbs were disintegrated into what were supposedly primitive concepts; perhaps the most widely discussed of these was the proposed derivation of \textit{kill} from \textit{cause to become not alive}. Similarly, if one found a language that expressed the meaning of \textit{bring the book to me} as the equivalent of \textit{carry the book come give me}, it might seem that sentences of the latter type reflected the absence of a means for generating derived lexical forms. Such a view might lead to the conclusion that there were two types of action, a type that was ``semantically complex'' (capable of being broken down into primes) like \textit{kill} or \textit{bring}, and a type that was ``semantically simple'' (its members being themselves primes) like \textit{cause} or \textit{carry}.

Such a view is, I think, incorrect. There is probably no action verb which is either intrinsically simple or intrinsically complex in the ways suggested above. How actions came to be lexicalized is something which, like so many other things of equal or greater importance, we
%\originalpage{277}
have had to skim over or ignore altogether in an account as compressed as this one. However, we need to note that verbs are abstractions from sensory input in a way that nouns are not. At first glance, one might think that the referent of a verb like \textit{hit} was as unambiguously unitary as the referent of a noun like \textit{dog}, although in fact \textit{John hit Bill} could be rendered more accurately (if more circumlocutiously) as \textit{John clenched fist John drew-back arm John thrust forward arm fist met Bill}. In fact, there are perhaps no ``semantically simple'' verbs that could not be represented in a ``semantically complex'' way, and vice versa. What determines whether a particular referent action is repre\-sented by one verb or more than one is nothing to do with semantic complexity, but has a lot to do with the number of case roles the action involves. It is precisely those actions which involve a number of case roles that are singly lexicalized in prepositional languages, and multiply lexicalized in verb-serializing\is{verb serialization} languages.

The aid supplied by verb serialization\is{verb serialization} in bridging the gap between monopropositional and multipropositional sentences had nothing to do with semantics. Verb serialization simply made available structures more complex than had existed hitherto -- structures that added the possibility of NVNVN to the previous NV and NVN structures.\\\\

Now we need to consider how the representation of mental activities could have commenced. We have a syntactic bridge, but we also need a semantic bridge. I shall propose that the semantic bridge was provided by two classes of verbs: verbs of reporting and verbs of perception. Both represent actions that are in some sense ``more physical'' than the true \isi{psychological verbs} of thinking, hoping, remembering, etc. Both entail dual-propositional sentences. Both are likely to be of high utility in hunting-and-gathering communities where members frequently split up in their search for food and need to con\-vey to the others information about their degree of success in that search. I shall not attempt to determine priority as between these two classes.

Verb-class membership would now become critical in parsing.
%\originalpage{278}
The developing grammar would generate NVNVN sequences, but these would be ambiguous between two interpretations, e.g., NV[NVN] or NVN[(N)VN] (where the constituent in parentheses had been equi-deleted). However, if the first V was one of perception or reporting, the second N would be subject of the second V; if the first V belonged to some other class, the second N would be the object of the first V, and the sentence would be parsed as a serialization\is{verb serialization}. When the ``true'' psychological verbs came to be added, they too would follow the first of these patterns.

The development of reporting verbs would have begun at the same time as the development of displacement. If I report what another person said and that other person is not present, then obviously the saying must have occurred on a previous occasion. If I tell you \textit{Ug say honey here}, it requires no Socratic intellect to figure out that the honey may be here now (although of course it need not be) but that the saying of \textit{honey here} by Ug must have occurred at a previous time (and perhaps in another place, although my capacity to translate Ug's actual utterance of \textit{honey here} is something else that cannot simply be assumed). However, as sentences become more complex, the need to distinguish observation from computation, earlier from later, and general from specific statements must increase. Failure to make such distinctions, preferably in some quite rigorous and automatic way, leads to parsing problems which could compound even more rapidly than parsing problems arising from case assignment. Some scaffolding is required that will accurately fix the place of sentences in the world of \isi{time} and reality; TMA systems\is{tense-modality-aspect (TMA) systems|(} supply this scaffolding.

\citet[170]{Quine1960} expressed frustration and puzzlement with the fact that all sentences of all human languages must obligatorily express tense, but then, from Reichenbach on, philosophers have glaringly failed to make any kind of sense out of TMA systems. Their recipe has always been, ``Take the distinctions that are said by traditional grammarians to be made in modern English and reduce them to some kind of a formal schema''. Since the advantages, if any, of this approach are totally opaque to me, I shall discuss it no further. From
%ORIGINS 279
an evolutionary viewpoint, it appears plausible that the only distinc\-tions the first TMA system could grammaticize must have been distinctions which were somehow already implicit in the ways in which the brain processed and stored information. If certain types of information were already stored in different places or in different ways, then attaching some kind of grammatical index to the products of different stores would not have presented too much difficulty. On the other hand, the only possible alternative -- that the species invented categories for which there was no such preexisting infrastructure, and then either built a redundant set of infrastructures to reprocess it, or somehow assigned marking with 100 percent efficiency in the absence of such infrastructure -- is at best an improbable one.

People find this hard to comprehend because categories such as ``past'', ``pres\-ent'', and ``future'' seem quite natural and transparent. In fact, the so-called ``moment of speech'' which marks the elusive ``point present'' which is the linchpin of Reichenbachian analysis is an abstraction which can never be experienced but can only be inferred by beings who already have produced some kind of time-marking device. People talk about ``present'' as if it were somehow on a par with ``past'' and ``future''; but while any single point action can be in the ``past'' or the ``future'', no such action can be in the ``present'', simply because it must already be in the ``past'' before you can get time to open your mouth to talk about it. As for ``future'' and ``past'', the former is of dubious status in that events assigned to it, however probable or plausible, are artifacts of the imagination ontologically indistinguishable from wants and wishes, however unlikely or even counterfactual, while the latter, although the most tangible of the three, suffers in utility from being internally undifferentiated.

In fact, time presents itself in experience as an unchanging state -- it always was, is, and will be ``now'', as far as the experiencing individual is concerned -- and, with an assist from memory and prediction, as a constant and unbroken flow pouring against us. No remotely plausible mechanisms of perception or neural processing would seem to yield the neat bisection of time into two equal portions divided by a
%\originalpage{280}
constantly moving point which constitutes the ``commonsense'' analysis of time-imprisoned Western man.\footnote{It is an open question whether any language could make the past-present-future distinction before the culture that used it produced any kind of time-measuring device. The fact that time-enslaved linguists may have analyzed preliterate languages as having such a distinction is, of course, no proof of anything -- they have consistently done the same for creoles and they have been consistently wrong in so doing. In fact, there already exist more careful studies of such languages (e.g., \citealt{Arnott1970,Welmers1973}) which explicitly recognize the absence of the characteristic Western temporal framework. Analysis of TMA systems is too subtle to be left to logicians.}\enlargethispage{1\baselineskip} Far different is the case for the distinctions to be argued here.

I shall propose that if the distinctions of anterior, irrealis, and nonpunctual are the TMA distinctions consistently made in creole languages, and if these distinctions struggle to emerge, as they seem to, in the course of natural language acquisition\is{language!acquisition of}, then they represent the primary TMA distinctions made in the earliest human language(s), and appear in all three places because of their \isi{naturalness}. Since the word ``naturalness'' has been subjected to so many abuses, I had better make very plain what I mean by it in this context. The naturalness of a distinction is assumed to be an all-or-nothing characteristic and not a matter of degree. A distinction is natural just in case it corresponds to a difference in the mode of perceiving, processing, storing, or accessing data in the brain, such difference in turn depending on specific features of the brain's physical structure. It is assumed that only distinctions of this kind can be candidates for primary grammaticization.

Quite obviously, in the present state of our knowledge, any claims about brain structure can have no more than hypothetical status. This fact is no excuse for imitating the ostrich, as does Muysken when he claims (\citeyear{Muysken1981a}) that an earlier and much sketchier account of this area\footnote{In \citealt{Bickerton1974}.} ``will remain arbitrary until we know a lot more about the functioning of the brain''. We will not know a lot more about the functioning of the brain until we have made and compared and evaluated a lot more models of the brain along the lines of the one I have tried to construct in this chapter. The idea that scientists ``increase knowledge'' simply by ``finding out facts'' in the absence of any kind of theoretical \isi{model-building} is an illusion which, remarkably enough, flourishes only among those who themselves deal with mainly theoretical issues, while it simply does not exist among workers in the physical sciences, who so much take for granted the interaction of speculative models and empirical findings that they never even see the need to defend their methods. In fact, it is quite conceivable that we could track every dendrite to its synapse and still not have the faintest idea
%\originalpage{281}
how the brain worked, just because we had no adequate model of what all its electrical and molecular activity might be designed to accomplish. Therefore, to try to rebut the claims made here with the mere cry of ``You can't prove it!'' is as irrelevant as it is redundant. Those who disagree with the model presented here, which may indeed be wrong in detail or even in totality, have no recourse other than to construct better ones.\\\\

Muysken was right, however, in pointing out that my earlier account had failed to explain the syntactic ordering of TMA markers, and accordingly, the present account will remedy that deficiency. Let us review some relevant evidence. We know that the ordering of markers in creoles is always TMA, anterior-irrealis-nonpunctual. We know that in VO languages, as we are assuming the primordial language(s) to have been, free verbal elements which modify the meaning of the main verb usually precede the main verb. We know that the commonest source for TMA markers in creoles (and in other languages) is that of former full lexical verbs.\footnote{Another common source is (phonologically salient) auxiliary verb forms in the superstrate. However, since there could not have been auxiliaries before there were auxiliaries, the situations of creole and primordial languages will differ in at least this respect.} We will assume that whatever distinctions the original markers may have made, the markers themselves were derived from full lexical verbs. We will further assume that the markers must have been added in some order, that is to say, they were not aided all at the same time. These two assumptions seem to me to be unexceptionable.

Almost as unexceptionable is the assumption that when the first marker was added, it became an immediate constituent of the verb, and hence any markers added subsequently would have to be positioned externally to the unit formed by the verb and the first marker. Certainly, it is hard to think of any motivation there could have been for inserting a new marker \textsc{between} the original marker and the verb. Granted, we cannot prove that this did not happen. But there are ways in which the assumption can be tested.

Earlier in this chapter it was claimed that between any pair of distinctions, the distinction whose neural infrastructure\is{neural infrastructure|(} had been laid down earliest in phylogeny would be the first to be realized in language.
%\originalpage{282}
Also, by Lamendella's hypothesis, the distinction first realized in language should be the first to be realized in the acquisition of language\is{language!acquisition of}. Thus, in principle, we have two different ways of testing the assumption made above about adding order, two ways that are completely independent of one another: if both yield the same answer, then this constitutes mutual support for the two hypotheses, and if the answer yielded by both is the answer yielded by our (independently motivated) assumption, then further support is provided for the assumption.

According to that assumption, the nonpunctual\is{nonpunctual aspect}\is{punctual-nonpunctual distinction (PNPD)|(} marker, being always closest to the verb, represents the first of the three distinctions to be grammaticized. Therefore, punctual-nonpunctual should be the first of the three distinctions to acquire the appropriate neural infrastructure, and it should also be the first to be acquired by children.

In \chapref{ch:3}, we surveyed a considerable body of evidence which suggested that whatever children might be thought to be learning (and sometimes they might be thought to be learning past-nonpast before other distinctions), what they really learned first was punctual-nonpunctual. Our second criterion is thus satisfied. With respect to the first, let us consider possible neural infrastructures for punctual-nonpunctual. One of the earliest neural structures known to us is that which underlies the phenomenon known as \textit{\isi{habituation}}. In \textit{Aplysia}\is{Aplysia@\textit{Aplysia}}, a sluglike marine mollusk whose nervous system contains only a handful of ganglia with a few hundred neurons each, the sensitive organs are extruded from a mantled cavity and consist of a gill for breathing, a siphon for eating, and a purple gland. The last two serve as primitive organs of perception. If anything touches the siphon or the gland, the gill retracts into the cavity. However, if you touch either gland or siphon at regular, brief intervals, the withdrawal response will diminish in both speed and intensity until eventually it is extinguished. \textit{Aplysia} has done its equivalent of deciding that your actions are nonthreatening and thus it is wasteful to respond to them.

\textit{Aplysia's} actions are of course entirely automatic and represent the workings of a mechanism whih has evolved in the vast majority of
%\originalpage{283}
animate creatures to prevent them from being wholly at the mercy of every external stimulus. It enables them to disregard irrelevant stimuli and reserve their energies to react to imminent danger or to seize feeding opportunities. If mechanisms such as this go back as far as mollusks, they antedate by some hundreds of millions of years any mechanisms that might underlie the other two TMA distinctions.

Clearly, \isi{habituation} mechanisms have grown considerably more sophisticated since \textit{Aplysia} emerged. Each of our senses has mechanisms that filter abrupt and sudden outside stimuli, which require immediate action on our part, from ongoing or persistently repeated stimuli, which do not. Driving down a crowded street, we are not at all perturbed by the constant movement of countless pedestrians, but let a ball bounce off the edge of the pavement, and (hopefully) we instantly slam on the brakes in anticipation of the child that may follow it. Working alone in an empty house, we pay no attention to sporadic noises in the street outside or the background murmur from the freeway a block or two off; we probably do not even consciously hear these things if we are engrossed in what we are doing; but let the slightest sound come from the rooms around us, and we stop whatever we are doing and become instantly alert. After the event we may tell the story as if we \textsc{decided} to brake or \textsc{decided} to attend to the strange sound, but these are post hoe rationalizations of our neuronal watchdogs' purely autonomous activities. In other words, the sorting of punctual from nonpunctual\is{nonpunctual aspect} actions is done for us automatically, and it seems reasonable to suppose (although it is still far from provable) that percepts in the \isi{memory} store are somehow coded with reference to whether they originated from sets of neurons specialized for perception of punctual events or from sets specialized for nonpunctual ones.

This capacity to make the punctual-nonpunctual\is{nonpunctual aspect} distinction in real life, so to speak, must have been crucial to our ancestors, intermediate as they were between those who might prey on them and those on whom they might prey. It is hard to think of any distinction which could have been more important for them to make as they began to build up the store of communal experience that would become
%\originalpage{284}}
the traditional wisdom of human groups. The interrelation of punctual and nonpunctual, foreground and background, provided basic ways of analyzing and classifying the diverse experiences with natural forces and other species which could now be handed on from generation to generation, growing as it spread through time, yielding knowledge of a wide range of phenomena and the actions appropriate in the presence of those phenomena.

Alone of the three TMA distinctions, punctual-nonpunctual correlated with observable phenomena. The \is{irrealis modality}realis-irrealis distinction contrasts observed events with events that are unobservable, at least at the time of speech; the anterior-nonanterior contrasts, not events at all, but the relative timing of events, a highly abstract feature. Punctual-nonpunctual, however, can be directly observed whenever a single action interrupts a more protracted or a repeated one. It could therefore have been grammaticized at a stage when only physical objects or events were capable of being grammaticized or lexicalized. Whether or not grammaticization took place this early, all the evidence suggests that punctual-nonpunctual was the first TMA distinction to be grammaticized, and accordingly, the form that marked the distinction would have been juxtaposed to the main verb. 

To find the evolutionary ancestry of the second distinction, realis-irrealis\is{irrealis modality}, we need to know the earliest source for items in the memory store that did not originate in the organs of perception. In all probability that source was dreaming. Dreaming began with mammals -- reptiles, as far as we are aware, do not dream -- and its origins and evolutionary function remain mysterious. One explanation treats \isi{dreams} as ``providing for better building of the \isi{memory} model by continued operation of the mechanism for memorizing during the night, even when no further information from external sources is available'' \citep[209]{Young1978}. Certainly, dreams appear to permute actual experiences in ways that produce novel constructs. However, we have hypothesized that items in the memory store are coded in ways that reveal the source of each item. If this is so, all items in the store must have (at least) coding which will indicate whether they originated from perceptions
%\originalpage{285}
of the external world or whether they lacked any such origin. At whatever point our ancestors achieved the power to consciously manipulate the memory store in order to generate hypothetical with future events or ``might-have-beens'', a new dimension would have been added to irrealis\is{irrealis modality}, but the essential coding difference would not have been affected; whatever was internally generated would be coded differently from whatever was externally generated. Nowadays, of course, most of us can consciously and quite explicitly distinguish, if required to do so, between events that really happened and events that are the product of dreams, desires, wishes, and expectations; if we cannot, we are separated from the remainder of the species and maintained in institutions specializing in this and similar conditions until such time as we recover the capacity. To be able to tell realis from irrealis\is{irrealis modality} is a crucial part of being fully human. But the foundation of this capacity and of our capacity to mark verbs in a way appropriate to the status of their referents must be the same: some kind of neural coding of memory items that reflects internal as opposed to external source.\is{neural infrastructure}

Unfortunately, in the case of realis-irrealis\is{irrealis modality} and anterior-nonanterior, we cannot draw the evidence that we drew from child acquisition in the case of punctual-nonpunctual.\is{punctual-nonpunctual distinction (PNPD)|)} While it is highly possible that children make irrealis distinctions before they make anterior distinctions, the point is not easy to prove since the lack of correspondence between the bioprogram\is{language bioprogram} TMA system and the systems of most target languages is such that it is by no means easy to tell when children have acquired whatever forms may correspond to \is{irrealis modality}irrealis and whatever forms may correspond to anterior. It is true, for instance, that children learning English acquire futures long before they acquire pluperfects, but since future does not correspond one-to-one with \is{irrealis modality}irrealis and pluperfect does not correspond one-to-one with anterior, it would be unfair and unrealistic to base any claims on this fact alone. Hopefully, studies of acquisition of those creole languages which preserve the original distinctions fairly intact, as well as more sophisticated studies of the acquisition of other types of language, may be able to provide the needed evidence.

%\originalpage{286}

However, even in the absence of such evidence, it seems likely that anterior was the last of the TMA distinctions to be added. In order to make the distinction, the order of past events has to be accessible. Perhaps all creatures that have memories have mechanisms, as we must, by which the order in which memories are laid down corresponds with the order in which the relevant experiences occurred. However, recoverability of that order is another matter, for any kind of recoverability entails volitional manipulation of the memory store, and there is no reason to suppose that volitional manipulation preceded nonvolitional manipulation (i.e., dreaming). Thus, the antecedents of anterior are almost certainly more recent than the antecedents of irrealis.\is{irrealis modality}

Furthermore, the utility of anterior as a category would be unlikely to arise until discourse had become fairly complex. Anterior marking is primarily a device which alerts the listener to backward shifts of time in a narrative or a conversation, thus enabling him to preserve the correct sequence of reported events -- a must if features such as causality are to be extracted from it -- even when the reporting diverges from that sequence. Thus, not only are the mechanisms under\-lying anterior probably more recent than the mechanisms underlying irrealis\is{irrealis modality}, but the functional need for anterior is almost certainly more recent than the functional need for irrealis.

If this is the case, we can claim that according to four sets of criteria -- age of infrastructure, age of functional utility, time of child acquisitions, and sequence within Aux -- the three basic TMA\is{tense-modality-aspect (TMA) systems|)} distinctions are ranked in the order: nonpunctual\is{nonpunctual aspect} first, irrealis\is{irrealis modality} second, and anterior third.\footnote{Order in terms of distance from the verb is of course intended, and not the left-to-right ordering of surface constituents.} Note that the surface order of tense-modality-aspect which this yields is not only the order of creoles but also what has been assumed from \citet{Chomsky1957} on to be the underlying order for \ili{English}, and perhaps other languages too.

Although considerations of space have prevented us from survey\-ing a number of other features -- such as the development of pronouns, pluralization, movement rules, etc. -- which must have accompanied or closely followed the developments actually described, we have carried our account of the early history of language to a point at which, in its
%\originalpage{287}
degree of complexity, it can have fallen but little short of an early creole language\is{creole!and language origins|(}. In other words, we have brought language close to a point at which, for all practical purposes, the biological development of language ceased, and the \is{culture}cultural development of language began. I have not even attempted to provide a time scale for these develop\-ments, either absolute or relative; they may have been spread out over two or three million years or they may have come in a series of bursts or even (though this is intrinsically less likely) in a single explosion of creativity.

Although at present we can do little more than guess, the suggestion by \citet{Hockett1973} that there might be some connection between the emergence of fully-developed language and the sudden and extremely rapid series of \is{culture}cultural changes that were initiated some ten thousand years ago is quite an appealing one. There is something inherently implausible in the idea that an evolutionary\is{evolution} line which had existed for countless centuries within the hunting-and-gathering framework in which some members of our species still exist should suddenly begin to grow crops, herd animals, build permanent settlements, construct complex belief systems, and evince countless other behaviors typical of our species, and highly atypical of all others, merely because certain small areas had exceeded their carrying capacity (if indeed they had). With all species, areas exceed their carrying capacity from time to time, and the result is always the same -- the species moves, if there is anywhere to move to, and if it is not an unduly territorial species; otherwise, individual members of the species die off until the balance of nature is restored. Similar experiences must have happened to our ancestors countless times and in countless places during the \isi{Pleistocene}, with its sudden and extreme changes of climate, but the responses must always have been the same: migration or population loss.

It seems likely that agriculture\is{agriculture} commenced not as a reaction to climatic change, population imbalance, or any other external cause, but rather as a result of vast changes in the computational and com\-municative power of the species. Dearth was feared rather than experienced,
%\originalpage{288}
and plans were made to prevent it. The shift from taking what nature provided, an attitude characterizing all previous species, to attempting to control nature was a vast one involving the power to construct an imaginary future and then communicate that construct to others so that concerted efforts could be made to realize it. Such attempts could hardly have been carried out without the aid of a language developed at least to the extent that we have envisaged here; but if such a language long antedated the birth of agriculture, how was it that that and all the other arts and sciences were not born far earlier than in fact they were?

At present, no adequate answer can be attempted. In any case, the precise dating of the events detailed in this account is really irrelevant. Some series of events such as have been described must have happened at some time during the last couple of million years or so for our ancestors to have passed from a state of no language to a state in which there existed languages recognizably similar to those of today. When those events occurred is a matter of legitimate interest, but not one that can affect either positively or negatively the validity of the foregoing account.

No one can be more acutely aware than I that the account given here is provisional, hypothetical, and can at best serve as no more than a rickety bridge between our present condition of almost total ignorance and some future state in which we may have at least a handful of relative certainties to build upon. However, the purpose of this chapter never was to write a definite prehistory and early history of language, but rather to show that, first, a series of capacities that might be plausibly held to have been latent in our last speechless ancestors, plus some capacities that could plausibly have evolved in the course of constructing a linear vocal language, could have yielded something recognizably similar to an early creole language, and second, that on the basis of what we at present know about our own species, such an outcome -- a creole-like language -- would have been intrinsically likelier than any other kind of possible language. The test of such an account lies not in whether this detail or that detail of it may be proven true
%\originalpage{289}
or false, but in whether or not it proves possible to build better (more plausible, more detailed, more explanatory) models.\is{model-building}

If the present model is in essence correct, and if a creole-like language was the end product of a long period of biological evolution\is{evolution}, then the overall capacity to produce languages of this type (itself a composite of neural capacities that preexisted any kind of language and neural capacities that were added as language evolved)\footnote{\label{Ch4:Fn15}It was observed in \chapref{ch:2} that the similarities between creole languages were in many cases closer and more consistent in the semantic component than they were in the syntactic component. This result would issue very naturally if the semantics of language depended on relatively old neural structures while syntax depended partly on relatively new neural structures but also partly on extraneural factors intrinsic to the task of building a linear vocal language. These latter factors might in a number of cases permit more than one possible solution to a given structural problem, whereas with semantic structures, single solutions would be imposed in almost all cases.} must at that point (and for the rest of the life of the species, it should go without saying) have formed a part of the genetic inheritance of every individual member of the species. It would then unfold, as we have claimed, as part of the normal growth development of every child -- in most cases, being quickly overlaid by the local cultural language, but in a few, emerging in something not too different from its original form. It would merely require triggering by \textsc{some} form of linguistic activity from others -- how much, and of what kind, remains one of the most interesting questions we can ask about language -- which is why wolf children, who share our biological inheritance, cannot speak, and why the interesting experiments of \iai{Psammetichus}, \iai{James IV}, \iai{Frederick II}, and \iai{Akbar the Great} all failed.\is{neural infrastructure}

It is not without some interest that the account given here resembles, in some respects, the Biblical account of language. The Bible\is{Bible, the} claims that language is a divine gift. This account can offer no objection to such a belief, assuming that God has chosen to work through evolutionary process; certainly, both accounts firmly reject the suggestion that language was in any sense a conscious or deliberate human invention. The Bible claims that our species originally spoke a single language. This account claims the same, with a slight qualification: the issue of whether language first arose in one group or in several independently is entirely irrelevant since, assuming the latter, all groups would have had the same neurological equipment, and thus their languages, although perhaps differing in lexical choices (as modern creoles do, for that matter) would have been structurally identical or almost so. The Bible claims that human language diversified coincidentally with a sudden surge of technological capacity, symbolized\is{creole!and language origins|)}
%\originalpage{290}
by the erection of the Tower of Babel\is{Babel, tower of} (a tower aimed at reaching heaven, i.e., usurping powers over nature which were properly part of the divine prerogative). This account would also claim (and I will develop the claim a little further in the next paragraph) that human language diversified as a direct result of rapid \is{culture}cultural and technological diversification, aiming, consciously or not (and in our time it has become a conscious goal) at ``The Conquest of Nature'': I would be the last person to adduce Scriptural authority in support of a scientific theory, but the resemblances are intriguing, to say the least.

The question most frequently asked about the theory presented in this volume is: ``If our biological inheritance provides for us a ready-made language, so to speak, how is it that we ever abandoned that language in favor of the diverse and far more complex languages of today?'' The answer is that, in a sense, the biological language self-destructed. It had made possible the construction of cognitive maps\is{cognitive mapping} more detailed and complete than those available to any previous species, maps which enabled their users to enter what was in effect a wholly new cognitive domain, a domain, in which events could be predicted and forestalled and even altered rather than passively endured as all previous species had endured them. It had conferred on our species the power to \textsc{live differently} -- differently from the past, and differently from one another.

So, differently was how they lived. Previously, as in all other species, our ancestors had all lived roughly the same kind of life; if they happened to live near a mud flat, they would include shellfish in their diet; if they didn't, they wouldn't; and that was about the extent of the difference. Now, some went on hunting and gathering and some became pastoralists and some became cultivators and some founded cities and lived by farming other people. New needs arose. New categories were established to take care of those needs. Some groups found it convenient to code verbs in such a way that the evidential status of any remark was immediately apparent. Some groups found it convenient to code nouns in such a way that the major \isi{semantic classes}
%\originalpage{291}
to which they belonged were immediately apparent. These new categories were superimposed on the old ones, but a language is a system or it is nothing, so that this superimposition shifted and distorted the older, more ``natural''\is{naturalness} categories and in some cases, perhaps, overlaid them completely. This, too, was natural, in its way. No biological language could have been designed to suit the needs of all humans under all the different circumstances in which humans could live; indeed, if any such language could have been designed, it would either have been itself subject to change (since \isi{cultural evolution} is not a closed process) or if not so subject would have been positively dysfunctional, since it could not have adapted to our changing needs and priorities. Thus, one hundred centuries of cultural change and development have produced the world of diverse, yet underlyingly similar, languages which we know today.\\\\

But not only cultural factors served to change\is{linguistic change} the bioprogram language\is{language bioprogram}. Factors concerned with language processing are also operative. I will illustrate just two different types of such factors here.

The first involves relative clauses. As we saw in \chapref{ch:1}, HCE has no surface marker of \isi{relativization}\is{English!relativization}\is{Hawaiian Creole English!relativization}, even where English obligatorily requires one, provided that there is a head noun. If there is not a head noun, then an English relative pronoun is supplied. Thus, we get headed relatives like \textit{da gai gon lei da vainil fo mi bin kwot mi prais} `The guy \textsc{who} was going to lay the vinyl for me had quoted me a price', with no marking, but headless relatives like \textit{hu go daun frs iz luza}' (\textsc{the one}) who goes down first is the loser', with an English relative pro\-noun. Obviously, the difficulty of incorporating English relatives per se cannot be what is responsible for sentences of the first type. Rather, the cause must be, first, that all HCE sentences require some kind of overt subject (except imperatives, of course), and, second, that as we hypothesized in earlier chapters, HCE lacks -- ``used to lack'' might be more accurate -- a rule that would rewrite NP as N S, but possesses a rule that would rewrite NP simply as S, thus yielding the structure NP[NP V X] VP for both the above sentences.
%\originalpage{292}

However, as was shown in \citet{BeverEtAl1971}, zero relative pronouns in sentences where the head noun is subject of the relative clause can cause serious ambiguities in a minority of sentences. Practically all creoles now have some kind of relative marking, pre\-sumably as a consequence of such processing problems. Thus, change\is{linguistic change} away from the bioprogram pattern can set in very quickly even where it is not triggered by language contact, if the functional pressure is sufficient.\is{relativization}

The second factor involves \isi{word order}. It has been claimed here that the original language order was SVO with serialization\is{verb serialization} but that this order was not necessarily hard-wired. This directly contradicts a claim by \citet[Chapter~7]{Givn1979} that the original language order was SOV. Givn's evidence is that a majority of the world's language families are either synchronically SOV or reconstruct back to SOV, while change in the reverse direction is rare. But in fact, serial SVO often forms an intermediate stage between SVO and SOV in Austro\-nesian languages, which are changing under the influence of \ili{Papuan} languages \citep{Bradshaw1979}. In our original language, a similar change could have come about in the following manner: first, there occur a number of NVNVN sequences in which the final N is realized as a pronoun; second, object pronouns become cliticized; third, the first V is reanalyzed as a preposition. In this way, a structure that was originally analyzed as Subject-Verb-Object-Verb-Object changes until it can be reanalyzed as Subject-Preposition-Oblique Case-Verb -- SXV, in fact. This is then interpreted as the canonical order, and any full-NP objects left behind the verb are moved in front of it in order to remove what now appears to be an anomaly. It is, of course, not necessarily implied that all early languages followed this course; but if a number of them did, then the data which Givn took as proof of original SOV could easily be accounted for.\\\\

There is not space here to discuss in detail how the bioprogram\is{language bioprogram} theory would affect the theory of linguistic change\is{linguistic change}. It should be apparent that an entire volume could easily be written on this topic.

%ORIGINS 293
The study of linguistic change has been effectively paralyzed for many decades by the empirically groundless belief that all the world's current languages are at a similar level of development. Even the study of Greenbergian universals\is{universals, linguistic} led only to suggestions of a kind of ceaseless seesawing between OV and VO orders. I would predict that, right or wrong, the present theory would at least give something tangible for diachronic linguistics to chew on.

However, it should at least be pointed out that the present theory does not claim a steady progression away from the bioprogrammed base. Quite apart from the drastic recyclings which \isi{pidginization} precipitates, there are likely to be partial reemergences of bioprogram\is{language bioprogram} features in a number of linguistic situations, prominent among these being, first, the constant surfacing of so-called ``substandard'' varieties in classes where prescriptive monitoring is minimal, and second, contacts between typologically different languages (such as the Austronesian-Papuan clash mentioned above) which set in motion extreme change processes in one party or the other. Thus, despite a very rightly skeptical survey by \citet{Polome1980} which concludes that creolization may hardly ever or never have been responsible for historical changes, there may still be some truth in the persistent claims that \ili{Germanic}, or \ili{Egyptian}, or Old \ili{Japanese} may owe some of their features to ``creolization''. In fact, Polom would still be correct in claiming that true creolization had not taken place; the creole-like features would be derived from the same bioprogram that is responsible for creoles and for many acquisitional features, but surfacing under rather different and somewhat less radical circumstances than those which give rise to creoles.

We have now completed our survey of creoles, acquisition, and origins, showing the wide range of similarities that unite the first two and that could derive in both cases from the reenactment of the third. In the fifth and final chapter I shall briefly summarize the theory which these findings support, and place it in the context of existing linguistic theories, and I shall also glance at a few of the more obvious arguments that may be brought against it.
\is{language!origins of|)}
%CONCLUSIONS 295