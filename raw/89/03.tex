\chapter[Judging Grammaticality]{Judging Grammaticality: The Nature of Metalinguistic Performance}\label{sec:3}

\epigraph{\textit{Metalinguistic data are like 25-cent hot dogs: they contain meat, but a lot of other ingredients, too. Some of these ingredients resist ready identification.\\[-2\baselineskip]}}{\citep{Birdsong1989}}
\section{Introduction} \label{sec:3.1}

The purpose of this chapter  is to explore some of the basic qualities of grammaticality judgments and some current thinking on their theoretical status, as a prelude to examining detailed studies of their behavior under various experimental manipulations in the two subsequent chapters. I cite some experimental work, but also a fair amount of theoretical discussion.

The structure of the chapter is as follows. In \sectref{sec:3.2}, I ask how it is that we can get people to assess grammaticality, what tasks have been invented for this purpose, and what their relative merits are. I then consider in \sectref{sec:3.3} what has been a most important and controversial feature of the judgments that result from these tasks\schdash{}namely, that people seem to judge grammaticality in a graded rather than a dichotomous fashion. This is perhaps the most widely studied topic in the literature on grammaticality judgments; a major issue is how to get at these scalar judgments \textit{reliably}.  In \sectref{sec:3.4}, I  speculate on how the intuitions behind our judgments might arise, how a sentence is processed for judgment,  the extent to which the hypothesized process could reflect the grammar, and how we might make it do so more transparently. \sectref{sec:3.5} tackles more directly a view that has become almost unanimous among psycholinguists, that no privileged status can be accorded to judgment data over any other sort of performance data, and that we therefore cannot draw direct conclusions about grammar from them. Numerous researchers have made this argument in various ways, and I review the
% 54
% Judging Grammaticality  55
major contributions. Finally, I relate the high-level properties of grammaticality judgments discussed in this chapter to the low-level properties to be examined in the next two chapters.


\section{Tasks that Access Grammaticality}\label{sec:3.2}

\is{metalinguistic tasks}\is{grammaticality!tasks for accessing/assessing}In this section I look at some of the methods researchers have used to induce subjects to express their feelings on the grammaticality of sentences, as a prelude to the detailed discussion of experimental work that begins in \sectref{sec:3.3.2}. This list is not exhaustive (see \citet[106]{Labov1972b}, and \citet{BialystokEtAl1985} for other types of intuitional judgments), and I concentrate on those methods that require the least inference on the part of the experimenter. For instance, I am not concerned here with inferring grammaticality on the basis of spontaneous conversations or texts, because such inference is problematic and because subjects are not engaged in explicit judgment, which is the focus of this examination.\footnote{As an example of such an activity, one could imagine using almost any measure that is correlated with grammaticality. For instance, \citet{Miller1963}
show that amid loud background noise, grammatical sentences can be shadowed much more accurately than ungrammatical ones, but one would not want to take such differential perceptibility as sufficient evidence for grammaticality.
}
Still, a number of tasks have been used productively to investigate subjects' intuitions indirectly, or to gain additional information. Many of these are represented in the studies I review in subsequent chapters. I start by extending the term \textit{judgment} beyond the paradigm case of asking the subject, ``Do you think this is a good sentence?''

The first extension we can make is to supplement judgments in various ways. For instance, we can ask subjects to explain their judgments.\is{metalinguistic tasks!explaining one's judgments} In the case of sentences judged bad, this can involve asking subjects why they feel the sentence is bad, or where in the sentence the problem is. Such questioning helps to ensure that the reasons for which subjects reject sentences are relevant to the theoretical issue at hand. While there is potentially a lot of information to be gained by this method, there are problems as well. For instance, it is not clear that subjects will be able to answer such questions in all cases. As \citet[110]{Birdsong1989} puts it, the response
``ungrammatical'' can result from a ``rather vague, gestalt-like impression''; it just sounds bad. At other times, a subject can detect something specific that is deviant about a sentence. It would be worthwhile to examine under what conditions these two feelings tend to arise, assuming subjects can reliably
report  the difference;  the question  appears  not to have been  studied. Some researchers deny that posing such questions to subjects is \textit{ever} a useful procedure. \citet{Botha1981}, for example, believes that people do not know the reasons for their intuitive judgments  and cannot justify  them,  so it is senseless  to  ask for  such justification.  (See \sectref{sec:2.4} on introspection for more discussion of this issue.) This suggestion poses another methodological  problem as well, namely, how to balance this task for the sentences that are considered good, to avoid a biased procedure. It seems to make no sense to ask, ``Why is this sentence good?''\footnote{A linguist might respond to such a question by demonstrating that the sentence judged to be grammatical can be generated from the available mechanisms in the grammar, or that it satisfies all the relevant well-formedness constraints, but naive subjects cannot be expected to attempt this.}
Some experimenters  who have worried  about this problem seem to have used a paraphrase\is{metalinguistic tasks!paraphrasing} task instead, which is useful in the sense that it helps to ensure that a subject actually thinks about the sentence in question and takes the intended reading. (In fact, \citet{ConnorsEtAl1993} had their  subjects paraphrase  the stimuli \textit{before} judging them.) Another type of extension of the judgment task, particularly useful  in marginal  cases, is to ask under  what  conditions, if  any, the sentence could be grammatical. The subject could refer to a number  of different  conditions: the context of the utterance (e.g., ``Only in a cartoon world where toasters can think''); prosodic features (e.g., ``It's OK with heavy stress on \textit{dog}''); restrictions on referents  (e.g., ``It's good as long as \textit{they} refers to something animate''); or novel lexical items (``Then \textit{of} would have to be a noun''). A parallel task for the ungrammatical cases might be correction,\is{ungrammatical sentence, correction of}\is{metalinguistic tasks!correcting ungrammatical sentences} i.e., asking the subject how to fix an ungrammatical sentence (e.g., what words to add or remove). Generally, we are interested in the \textit{minimal} necessary  changes. If the initial judgment  is scalar rather than binary, it might make sense to ask both kinds of questions about the same sentence, i.e., ``When would it be good as it stands?'' and ``How could you make it completely  good?''

We can also go beyond explicitly asking for grammaticality assessments and look to other metalinguistic tasks in collecting this information.\footnote{Even \citet{Birdsong1989}, whose entire book is devoted to metalinguistic performance, believes this term requires a ``rather vague interpretation.''\is{metalinguistic performance (skills)!definition} Its most important feature seems to be the objectification of language, or attention to linguistic form rather than content. Birdsong\ia{Birdsong, David} also suggests that metalinguistic performance describes ``language-related activities typically not associated with the casual conversation and listening of non-linguists'' (p. 62). \citet{Cazden1976} describes it thus: ``It is an important aspect of our unique capacities as human beings that we can not only act, but reflect back
on our own actions; not only learn and use language, but treat it as an object of analysis and evaluation in its own right. Metalinguistic awareness, the ability to make language forms opaque and attend to them in and for themselves, is a special kind of language performance, one which makes special cognitive demands, and seems to be less easily and less universally acquired than the language performances of speaking and listening'' (p. 603). See \citet{Gombert1992} for a survey of uses of the term.}

%\textsuperscript{3}
 One simple variation is to request rank orderings of sentences by grammaticality, a procedure
% Judging Grammaticality  57
that I examine further in \sectref{sec:3.3.4}. One might also ask for a comparison of the \textit{type} of violation in bad sentences, e.g., asking whether two sentences are bad in the same way. Another interesting method makes use of ambiguity.\is{metalinguistic tasks!ambiguity detection} If we have a sentence that is uncontroversially good under one reading, but questionable under another (e.g., the \textit{that}-trace sentences discussed in \sectref{sec:2.3.2}), we can ask subjects whether it is ambiguous, and then verify their answers by eliciting paraphrases of the readings they find. In fact, the latter task without the former can provide some of this information without putting subjects in a judging mode at all, which (it will be argued in \sectref{sec:3.4}) might be important. Getting at the grammaticality of an alternative reading of a sentence via judgments is particularly tricky, as \citet{Householder1973} points out. The kind of judgment needed\schdash{}whether the sentence is grammatical under reading X, when it is clearly good under reading Y\schdash{}might require a different kind of judgment than one of simple grammaticality, in that the task involves evaluating a structure-meaning pair.

The most widely cited nonjudgment tasks, which were very popular in the 1960s and early 1970s, are the so-called \isi{compliance tests}. \citet{QuirkEtAl1966} are often cited as the originators of these tests. The task is to transform a stimulus sentence in some way, for example, to convert it from a statement to a question, to make it negative, or to switch its pronouns. The experimenter is actually not interested in these operations at all, but in whether the subject changes the remaining portion of the sentence while converting it. For instance, in investigating the grammaticality of a bare adjective complement of \textit{regarded}, the task might be to convert the sentence \textit{He is regarded insane} into a question. The dependent measure is the number of relevant noncompliances (RNCs), instances when subjects change the relevant part of the sentence, in this case the complement (e.g., by the insertion of the word \textit{as}). This constitutes noncompliance with the instructions, since subjects are told to make only the change that the experimenter requests. An RNC suggests that the subject considers the original form to be ungrammatical, although we must be careful about potential interfering effects such as forgetting the exact syntax of the original. Key to such an interpretation is the requirement that the transformed sentence would be just as deviant as the
original\schdash{}the operation must neither remove nor add deviance. Of course, whether a sentence meets this criterion is up to the judgment of the experimenters. (See \citet{Itkonen1979} for the criticism that what constitutes an RNC in these experiments also depends on the experimenters' own intuitions.)

\citegen{QuirkEtAl1966} original series of experiments compared tests measuring RNCs (operation tests)\isi{compliance tests} with two other types of task. Selection tests\is{selection tests} are like \isi{operation tests} except that a set of possible responses is given to the subjects, who must simply select the response they prefer. Judgment tests involve rating sentences on a 3-level scale: ``wholly natural and normal,'' ``wholly unnatural and abnormal,'' or ``marginal or dubious.'' The researchers argue for the use of a three-tiered scale as a compromise between the arbitrary responses that they believed would result from the use of a two-tiered scale, which they consider ``absurdly gross,'' and the 7-point scale that is more typical in psychology, which they consider ``unduly arbitrary.''\is{rating scale!examples of}\is{rating scale!choice of} In eliciting judgments, they preferred to ask about natural and normal language, combining grammaticality with meaningfulness and other factors, rather than trying to focus on structure alone. They wanted to compare judgments with the other tasks because they believe that direct questioning is the \textit{least} reliable way of getting at structural intuitions. They wanted to shift subjects' attention away from the issue of interest, and the notion of grammatical deviance in general, by the use of operation tests. The use of judgment and operation tests involving the same sentences allowed Quirk \& Svartvik to pinpoint the reasons for an ungrammatical judgment without asking subjects about them directly. Interestingly, though, a graph of the number of subjects accepting various sentences does not at all resemble a graph of the number of compliances on the
same sentences. Although the overall correlation of these measures is r = 0.73, this figure drops to 0.5 when 13 clearly grammatical control sentences are excluded. One major reason for this discrepancy is that there might be no obvious way to repair certain kinds of ungrammaticality, so that no RNC response was possible although a given sentence was clearly bad in some way, e.g., the semantically anomalous \textit{Timber was creeping up the hill}. Based on the two graphs, Quirk \& Svartvik conclude that there is no clear-cut threshold of grammaticality. \citet{Stolz1969} correctly points out that the generalizability of their results is limited by the fact that they did not look at specific classes of rule violations, but often tended to focus on particular lexical items.

In a subsequent book, \citet{GreenbaumEtAl1970} describe in great detail several orally-administered batteries of \isi{operation tests}, as well as relative and
% Judging Grammaticality  59
absolute judgment tasks. The obvious question again is whether \isi{compliance tests} and judgment tests gave the same results for particular sentences. Unfortunately, their presentation does not allow a concise overall summary of the results, so we are limited to somewhat vague generalities. Greenbaum \& Quirk found a large degree of agreement between the two measures, and they attempt to provide very detailed explanations of the minor systematic discrepancies. For instance, sentences that violate lexical co-occurrence restrictions are judged bad but are not changed, whereas sentences with certain word order errors\is{word order violations, effect on grammaticality judgments} are changed but not judged bad. \citet{Tottie1977} rightly cautions, in response to performance tests like these (although her comments could apply equally well to judgment tests), that we should ask ourselves

\begin{quote}
whether we are actually justified, from a psychological  as well as from a linguistic point of view, in asking subjects to substitute one word for another or to produce negative or interrogative counterparts of affirmative sentences. Obviously, the sentences produced in that way cannot \textit{a priori} be assumed to be equivalent to spontaneously produced linguistic structures of the same type. ... However, we need to know a good deal more about the psychology of speech production before we can arrive at anything more than a very tentative evaluation of such tests. (p. 209)
\end{quote}

A more recent technique for assessing grammaticality, which is just beginning to show its full potential, is the measurement of event-related brain\is{brain, as source of grammaticality data} potentials (ERPs;\is{ERPs (Event-Related Potentials)}; see \citet{Garnsey1993} for an excellent introduction to the use of this technique in language research). These are patterns in the electrical activity of the brain, measured by scalp recordings during the presentation of stimuli, in this case, sequential visual presentation of words. Electroencephalogram readings are broken down into component waveforms and categorized by the direction of change of the potential, positive (P) or negative (N), and the typical latency in milliseconds (e.g., 300, 400, etc.) from the stimulus onset. Three ERP components have been identified with well- or ill-formedness of sentences: N400, P300, and P600. \citet{KutasEtAl1983} teased out the triggers of N400 using three types of stimulus sentence: syntactically well-formed and coherent; well-formed but containing one semantically anomalous content word; and ill-formed but semantically coherent, containing mismatches of tense or plural morphemes. In all cases, the primary task for the subjects was reading for content, although they
were warned that errors might appear. The experimenters found that semantic anomalies elicited N400s, but grammatical errors did not, although they point out that the latter were considerably more subtle than the former. In a later study,  \citet{VanPettenEtAl1991} compared syntactically well-formed anomalous sentences with random word strings and found that the ERPs elicited by the final word of each string type differed significantly. They interpreted the reaction to the well-formed strings as belonging to the P300 class of ERPs, which occurs in a wide variety of tasks, but here seemed to be associated with syntactic closure, the realization that a sentence is complete. P600 appears to indicate temporary parsing failures, whether or not they are subsequently resolved. In particular, it occurs in certain garden-path sentences at the point where the initial parsing choice fails, e.g., at \textit{to} in (\ref{ex:3:1}a), but not at the same word in the superficially similar non-garden-path sentence (\ref{ex:3:1}b).
\citep{OsterhoutEtAl1992}. A P600 has also been found to occur upon presentation of the word \textit{was} in (\ref{ex:3:2}a), but not in (\ref{ex:3:2}b) \citep{OsterhoutEtAl1994}.

\ea\label{ex:3:1}
\ea The broker persuaded to sell the stock ...
\ex The broker hoped to sell the stock ...
\z
\z

\ea\label{ex:3:2}
\ea The lawyer charged the defendant was lying.
\ex The lawyer charged that the defendant was lying.
\z
\z

\noindent
Ideally, one would also hope to find a reliable ERP\is{ERPs (Event-Related Potentials)} correlate of actual, not just temporary, grammatical violations, so that overt judgments could be independently verified, but in practice this will not be so straightforward. Not only are ERP experiments costly and difficult to conduct, requiring very carefully controlled and unnatural reading conditions, but the interpretation of the results is not straightforward.  Still, we  might  hope  that  someday  ERP research  will  at least
help us to disentangle various sources of judgments of ungrammaticality (See \sectref{sec:7.2} for a description of a promising study.)

There are obviously many important questions about the relationships among metalinguistic task performance\is{metalinguistic performance (skills)!versus competence} of the kind we have been considering, regular linguistic performance,\is{metalinguistic performance (skills)!versus primary linguistic performance} and competence,\is{competence (grammatical)!versus performance} several of which are considered in Sections \ref{sec:3.4} and \ref{sec:3.5} below.
(Many of the authors I cite in those sections construe the area of metalinguistic performance even more broadly than I have in this section, and include tasks that do not bear on grammaticality, but I believe that their discussion applies equally well to our domain.) It is not even clear whether we should speak of metalinguistic indicators as a whole, because there is considerable debate as to whether metalinguistic skill is a unitary phenomenon. From a developmental perspective, \citet{Hakes1980} argues that it is, whereas from a cross-cultural perspective, \citet{ScribnerEtAl1981} argue that it is not, because people who do well on one task often do poorly on another (see \sectref{sec:3.5}, and also \sectref{sec:4.4.2}, for the latter). \citet{Birdsong1989} views metalinguistic performance as a \textit{collection} of \textit{skills},\is{metalinguistic performance (skills)!as skilled behavior} arguing that it shows three typical features of skilled behavior: there are differences in the number and kind of skills that individuals exhibit; there are differences in the degree to which individuals exhibit a given skill; and the skills tend to improve with practice or training. The reader is referred to \citet[51\textendash{}54]{Birdsong1989} for detailed evidence on each of these points, which are somewhat controversial (not all of Birdsong's\ia{Birdsong, David} evidence comes from judgments). Within the scope of the present book, Scribner \& Cole's work bears on the first two features of skilled behavior, and linguist/nonlinguist differences (see \sectref{sec:4.4.1}) bear on the third. If Birdsong's\ia{Birdsong, David} view is more or less correct, then these skills can be expected to make their own contributions to acceptability results, apart from the contributions of linguistic competence. Intertwined with these issues is the deeper question of whether we are really interested in what forms people actually use, as opposed to what they claim they use, or what they passively accept. We know that use of a construction does not imply acceptance and vice versa \citep{Greenbaum1976a}, and sociolinguists have long known that speakers might deny using forms that they actually use frequently in everyday speech. As \citet{Labov1975} demonstrates, this phenomenon is not even limited to socially significant linguistic variables. He describes numerous subjects who used positive \textit{anymore}\is{anymore, positive use of@\textit{anymore}, positive use of} in recorded conversations, yet when asked directly, they claimed never to have heard it, felt that it is not English, misinterpreted its meaning, and showed other signs of bewilderment. Labov\ia{Labov, William} points out that ``this puts us in the somewhat embarrassing position of knowing more about a speaker's grammar than he does himself'' (p. 35). (\citet{HindleEtAl1975} give similar anecdotal reports.) Various metalinguistic tasks will reflect the three sets of sentences\schdash{}those actually used, those claimed to be used, and those accepted\schdash{}to different degrees.\footnote{For instance, \citet{HindleEtAl1975} present anecdotal evidence suggesting that the task of judging shows a bias towards incorrect rejections as opposed to incorrect acceptances, i.e., towards lower-than-deserved ratings, as measured by speakers' actual usage.}
%\textsuperscript{4}
Which set is most relevant might depend on whether one believes that linguistic competence is separate from production and comprehension mechanisms, a question I take up again in \chapref{sec:6}.

\section{The Nature of Graded Judgments}\label{sec:3.3}
\subsection{Is Grammaticality  Dichotomous?}\label{sec:3.3.1}

\is{grammaticality!dichotomous versus scalar}The following passage, from R. \citet{Lakoff1977}, probably reflects the beliefs of most newcomers to linguistics regarding the possible grammatical status of sentences: ``It was tempting to believe that linguistic markers, like other animals, came in pairs, and it was therefore natural to assume that grammaticality was an either-or question. ... This seemed to us the way things ought to be in a well-ordered universe, and we were still capable of believing, with our endearing childlike faith, that the linguistic universe was well-ordered'' (p. 73). Despite Lakoff's\ia{Lakoff, George} apparent disillusionment, many linguists have wanted to maintain the principle that grammaticality is a dichotomous notion: ``In general, then, if we find continuous-scale contrasts in the vicinity of what we are sure is language, we exclude them from language'' \citep[17]{Hockett1955}; ``What with vigorous leadership and willing followership, the doctrine of discontinuity has found its fullest acceptance among American scholars'' \citep[2]{Bolinger1961}. On the other hand, it is clear that judgments of grammaticality come in more degrees,\is{grammaticality!degrees of} and in many cases these represent genuine multivalued phenomena (see below). Even in as early a work as \textit{LSLT}, Chomsky\ia{Chomsky, Noam} asserts that ``there is little doubt that speakers can fairly consistently order new utterances, never previously heard, with respect to their degree of `belongingness' to the language'' (p. 132). How are we to reconcile scalar judgments with an underlying dichotomy? Is it that the grammar assigns degrees of status to strings after all, and judgments simply reflect these? Or is it the judgment process itself that maps two-valued grammaticality to scalar acceptability by factoring in behavioral variables? Both views have been argued for in the literature, along with a third, intermediate position. Let us consider them in turn, before surveying the experimental literature to see to what extent each gains empirical support.

The  best-known proponents of the view that grammaticality occurs on a continuum\is{grammaticality!degrees of} are Haj Ross,\ia{Ross, John Robert} George Lakoff,\ia{Lakoff, George} and their followers in the late 1960s and early 1970s. Ross\ia{Ross, John Robert} (e.g., \citeyear{Ross1972}) used the term \textit{squish}\is{squish} to refer to a continuum of grammaticality in connection with a particular construction (see \citet{HindleEtAl1975} for more on squishes\is{squish}). \citet{Lakoff1973} summarizes the conclusions of this line of research as follows:

\begin{quote} 
\begin{itemize}
\item[(i)] Rules of grammar do not simply apply or fail to apply; rather they apply to a degree.
 
% Judging Grammaticality  63
\item[(ii)] Grammatical elements are not simply members or nonmembers of grammatical categories; rather they are members to a degree.

\item[(iii)] Grammatical constructions are not simply islands or non-is\-lands;\linebreak rather they may be islands to a degree.\is{islands (syntactic)}

\item[(iv)] Grammatical constructions are not simply environments or non-envi\-ron\-ments for rules; rather they may be environments to a degree.

\item[(v)] Grammatical phenomena form hierarchies which are largely constant from speaker to speaker, and in many cases, from language to language.

\item[(vi)] Different speakers (and different languages) will have different acceptability thresholds along these hierarchies.  (p. 271)

\end{itemize}
\end{quote}

\noindent
Lakoff\ia{Lakoff, George} continues, ``We are saying that \isi{fuzzy grammar} has a mental reality. The judgments that people make, which are matters of degree,\is{grammaticality!degrees of} are functions, perhaps algebraic functions, of unconscious mental judgments, which are also matters of degree'' (p. 286). (See \citet{LeveltEtAl1977} for a somewhat different application of fuzzy grammar.) While I cannot review in detail the evidence that led to these conclusions, the key point is that the features of sentences that lead to graded judgments when varied do \textit{not} have perceptually related causes, such as the taxing of short-term memory capacity, but rather are based on linguistic concepts such as clause, nominal, adverb, etc.

Let us take as an example some slightly later work by \citet{Watt1975}, who investigated whether grammaticality occurs in degrees.\is{grammaticality!degrees of} His domain of investigation was \isi{strained anaphora}, as illustrated by the following set of related sentences:

\ea
\ea All those who follow Nixon say they approve of his annexing Mackenzie Territory as the fifty-fifth State.
\ex All followers of Nixon say they approve of his annexing Baffin Island as the fifty-sixth State.
\ex All Nixon-followers  say they approve of his annexing The Bahamas as the fifty-seventh State.
\ex All Nixonites say they approve of his annexing British Honduras as the fifty-seventh  State.
\z
\z


\noindent
From a very detailed study of contrasts in sentences involving \isi{strained anaphora}, Watt concludes that there are gradations among grammatical sentences that are
% \textsuperscript{64 } Chapter Three
\textit{not} due to known performance factors, such as memory limits. Rather, these gradations can be accounted for in terms of factors that are already part of the grammar itself,  such as linear order, contrastive stress, and specificity of reference. Watt argues that to try to account for such gradations by extragrammatical means would require needless duplication of the grammar in another part of the mind. This is the complement of Bever's\ia{Bever, Thomas G.} argument, presented in \sectref{sec:2.2}. Bever\ia{Bever, Thomas G.} attempts to avoid duplicating \textit{within} the grammar features that are already required \textit{outside} of it.

Despite their seemingly complementary lines of argumentation, it is clear that Bever\ia{Bever, Thomas G.} and Watt\ia{Watt, W. C.} disagree strongly in the conclusions that they draw. \citet{Bever1975a} is unequivocal in his position:

\begin{quote}
To give up the notion that a grammar defines a set of well-formed utterances is to give up a great deal. This is not to say that it is impossible in principle  that  grammars  are  squishy.\is{squish}  Rather  the  possibility of studying precise properties of grammar and exact rules becomes much more difficult, as Ross\ia{Ross, John Robert} himself  points out.\is{fuzzy grammar!arguments against} Thus, if we can maintain the concept of discrete grammaticality, we will be in a better position to pursue an understanding of grammatical universals. (p. 601)
\end{quote}

\noindent
Bever\ia{Bever, Thomas G.} argues that, if at all possible, judgment continua should be derived from independently-motivated theories of speech perception and production, while the grammar should be left discretely intact. He and Carroll\ia{Carroll, John M.} lay out two alternative positions, then proceed to knock them down:

\begin{quote}
First, we may with Ross\ia{Ross, John Robert} assume that non-discrete data directly imply non-discrete theories of grammar.\is{fuzzy grammar!arguments against} This is not satisfactory: Non-discrete grammar offers no account of why the continua are the way they are. The correspondences between such grammatical analyses and the predictions of our behavioral account would have to be viewed as mere coincidence. Moreover, no distinction at all could be drawn between the squishy intuitions we have been concerned with here and the ineluctable intuitions upon which linguistic theory relies. A second option is to treat \textit{all} acceptability phenomena as behavioral and non-structural \citep{ClarkEtAl1974}. This alternative also is inadequate: It cannot explain the categorical (un)accepta\-bility of examples at either end of a continuum.\is{fuzzy grammar!arguments against}


% \textsuperscript{Judging} \textsuperscript{Grammaticality}  65

The third alternative is that examples with intermediate acceptability rest on an internal confusion by the informant between the application of a linguistic process to a category (e.g., ``S'') and to the typical behavioral reflex of that category (e.g., ``perceptual clause''). This explanation explains a variety of acceptability facts as well as predicting hitherto unnoticed ones. However, it is important to specify what the general conditions are that will lead to an acceptability \isi{squish}. ...

An underlying theme of our proposal is that \textit{all} grammatical properties are categorical and that all apparent departures from this have a general explanation\is{fuzzy grammar!arguments against} in an interactionist framework\schdash{}a totally discrete system of grammar interacting with behavioral processes.  \citep[232--233]{BeverEtAl1981}
\end{quote}


\noindent
(An argument for the third alternative is presented in the study by Gerken\ia{Gerken, LouAnn} \& Bever\ia{Bever, Thomas G.} discussed in \sectref{sec:1.3}.) Thus, the claim that the grammar is discrete does not preclude the existence of graded phenomena\is{grammaticality!degrees of} like those studied by Watt, it merely asserts that part of their explanation must be extragrammatical; see \citet{KatzEtAl1976} for a more detailed general argument.

Bever\ia{Bever, Thomas G.} \& Carroll's\ia{Carroll, John M.} dismissals of positions other than their own are not entirely convincing. First, I do not see how one could ask for more of an account of ``why the continua are the way they are'' than Ross\ia{Ross, John Robert} et al. provide, unless one already presupposes that  the continua  do not  come from the  grammar\schdash{}language just \textit{is} the way it is. Second, Clark\ia{Clark, Herbert H.} \& Haviland\ia{Haviland, Susan E.} do not wish to exclude structural accounts of acceptability phenomena; rather, they argue that structural sources cannot be disentangled from the effects of processing.\is{grammar!versus performance} They claim that grammatical knowledge is not separable from comprehension and production processes, and that traditional grammatical constraints can be alternatively formulated as constraints on the comprehension process, but the latter can still contribute to structurally based judgments. There is no reason why they cannot get categorical judgments from their model. Furthermore, it is an open empirical  question whether there really are large classes of sentences at either end of the scale within which people do not find any acceptability differences.

The  discrete,  dichotomous\is{grammaticality!dichotomous versus scalar}  view  of  grammar  has  been  defended  from  a somewhat different angle by \citet{Carr1990}:

\begin{quote}
It is as well to respond briefly to a frequently voiced but unworrying objection concerning grammaticality judgements as evidence. It is at
%\originalpage{66} %  Chapter Three
times pointed out that there are cases of `asterisk fade', where intuitive responses supply us with a gradient scale of well-formed to ill-formed expressions. The objection is that the evidence here contains grey areas and that the ill-formed vs. well-formed distinction upon which  [autonomous linguistics] rests is thus undermined.

A moment's reflection shows that, far from undermining the distinction, asterisk fade \textit{presupposes} it: one cannot coherently speak of a cline from well-formed to ill-formed without a clear conception of what these are. Furthermore, once we have erected a set of theoretical proposals to deal with the ill-formed and well-formed cases, the theory itself will allow us to decide\is{letting the grammar decide (on unclear cases)} on the status of asterisk-faded expressions, as Chomsky\ia{Chomsky, Noam} has long since observed. (p. 57; emphasis in original)
\end{quote}

\indent
I argue against Carr's\ia{Carr, Philip} second point in Sections \ref{sec:2.2} and \ref{sec:2.3};
his first argument also does not stand up to scrutiny. One can certainly speak coherently of a continuum,\is{grammaticality!degrees of} e.g., from rich to poor, without there being any non-arbitrary dividing line between the two. To my mind, the most compelling reason to believe in grammars embodying small numbers of  discrete  choices  comes  from  learnability.\is{learnability (and discreteness of grammar)}\is{grammar!discreteness and learnability}  Given the standard poverty-of the-stimulus argument, arriving at settings of continuous valued parameters would seem to be impossibly hard for children.

Although Chomsky\ia{Chomsky, Noam} already assumed in \textit{LSLT} that there were degrees\is{grammaticality!degrees of} of ungrammaticality, he went further in \aspects{148--153)}, proposing that the grammar predicts at least three levels or kinds of deviance,\is{three levels/kinds of deviance (\textit{Aspects})} corresponding to the violation of selectional restrictions,\is{selectional restriction violation} subcategorization,\is{subcategorization violation} and lexical category\is{lexical category violation} requirements. It is important to recognize that Chomsky's\ia{Chomsky, Noam} theory assumes the existence of absolute grammaticality. Sentences that violate no constraints of the grammar are assumed to be uniformly grammatical. If a sentence is less than absolutely grammatical, it must violate some constraint(s) of the grammar, and these constraints come in varying degrees of importance. Thus there are no degrees of grammaticality,\is{grammaticality!degrees of} but there are degrees of ungrammaticality. (See \citet[vol. 3]{Levelt1974} and below for some alternative proposals.) In terms of string sets, then, we have a primary dichotomy of good versus bad, with no distinctions among the good sentences but graded distinctions among the bad. It is reasonable to ask whether there is any psychological evidence that this theoretical distinction reflects cognitive reality. Even though acceptability is affected by factors other than grammaticality, one might expect the good/bad dichotomy to show through
% Judging Grammaticality  67
them, if the other factors are relatively independent of grammaticality and ungrammaticality. I am not aware of any clear evidence of this sort. \citet{Ross1979}, reported in \sectref{sec:4.2}, 
did make a distinction between good, marginal, and bad sentences (on the basis of questionnaire data) and found that judgments on the first class showed the least interspeaker and intraspeaker variation, but his study was so methodologically naive that this result cannot be taken as anything more than suggestive until further experimentation is done. \citet{QuirkEtAl1966} make a similar distinction. \citet{Watt1975} claims that his findings argue against Chomsky's\ia{Chomsky, Noam} proposal because his sentences are all generated by the grammar of English, and yet they show differences of goodness. Furthermore, there is no evidence that these differences are of some other kind than the differences we find among ungrammatical sentences. Chomsky's\ia{Chomsky, Noam} proposal also suffers from a major theoretical problem\schdash{}namely, there is no algorithm for determining which grammatical sentence to compare an ungrammatical sentence to, in order to compute its degree of ungrammaticality \citep{Fillmore1972}. (See \citet{Watt1975} for a review of Chomsky's\ia{Chomsky, Noam} later proposals, which I do not discuss here.)

More likely than Chomsky's proposal is a scenario in which grammaticality rating works in much the same way as conceptual classification ratings of the sort elicited by \citet{Rosch1975} under the rubric of \isi{prototype theory}. Just as we can ask, ``How good an example of a bird is a robin/ostrich/butterfly/chair?''  we can ask, ``How good an example of a grammatical sentence is \textit{X}?'' for any string \textit{X}. The responses will likely spread along a continuum\is{grammaticality!degrees of} with no indication of a clear-cut break of the sort discussed above, provided they are not biased by a lopsided rating scale. \citet[47]{KessEtAl1983}
concur: ``Apparently shared linguistic abilities operate on the same type of a graded continuum scale that cognitive abilities of a more general sort do.'' (See \sectref{sec:6.2} for an attempt to formalize judgment gradience along these lines.) We must be cautious in extrapolating from such a result (if it is found) to the nature of grammar, however. Prototypicality effects\is{grammaticality judgments!parallels to prototypicality judgments} do not necessarily imply the absence of an underlying discrete system. As
G. \citet{Lakoff1987} reminds us, Rosch herself never suggested that graded\is{grammaticality!degrees of} classification effects reflect degrees of category membership or representation in terms of prototypical features or exemplars. In fact, empirical demonstrations to the contrary have been made.

\citet{ArmstrongEtAl1983} applied Rosch's original experimental paradigms to uncontroversially discrete concepts such as \textit{even number} and \textit{female}. Subjects were instructed to rate the extent to which exemplars
%\originalpage{68} %  Chapter Three
represented the meaning of the category, and were timed on their responses to true/false categorial questions. They found that the discrete concepts presented the same pattern of results as Rosch's original taxonomic materials. Specifically, the goodness of various exemplars was rated quite uniformly across subjects, and reaction times for deciding membership in a category were longer for the worse exemplars, again with as much cross-subject consistency as for the taxonomic concepts that Rosch studied. Despite being able to grade exemplars consistently on a continuum, the subjects demonstrably knew that membership in categories such as \textit{even number} was an either/or proposition. Which behavior reflects subjects' true cognitive representations of these concepts? \citeauthor{ArmstrongEtAl1983}  do not see these results as contradictory, because their experiment involved two different tasks, judging exemplariness and deciding membership. They discuss various possible theoretical explanations of their results, assuming that the real concepts are discrete and suggesting possible origins of the gradations, e.g., that they might stem from a quick, heuristic identification procedure. Lakoff argues against this last idea, and proposes that prototype effects reflect a mismatch between potentially discrete conceptual knowledge and the real world. For example, in the real world not all unmarried men are eligible to be married, and hence cannot be rated as bachelors to the full extent. However, there are still concepts for which there appears to be no discrete decision criterion, e.g., whether someone is rich, and these also exhibit prototypicality effects. Thus, it appears that graded structure in prototype tasks tells us nothing about the nature of the underlying mental representations. Is the same true of graded structure in grammaticality judgments and its bearing on mental grammars?

\citet{Barsalou1987} suggests that graded structure might be a universal property of categories, and that the properties of an exemplar that determine its goodness as an instance of some category can vary depending on the situation. These properties might include, but are not limited to, similarity to the central tendency; similarity to the ideals of the category frequency of occurrence; and context. Barsalou summarizes his conclusion as follows:

\begin{quote}
The graded structures within categories do not remain stable across situations. Instead a category's graded structure can shift substantially with changes in context. This suggests that graded structures do not reflect invariant properties of categories but instead are highly dependent on constraints inherent in specific situations. (p. 107)
\end{quote}


% Judging Grammaticality  69

\noindent
As I argue, particularly in \chapref{sec:5}, Barsalou's\ia{Barsalou, Lawrence W.} view jibes well with the findings on grammaticality. Judgments are not invariant, and any of a large number of factors can come into play in making a judgment. Barsalou also looked at intra- and intersubject reliability across a wide variety of conceptual types. When people order exemplars by typicality, the average between-subject correlation is about .45. For the same subject judging the same stimuli on two occasions one month apart, it is roughly .75. In both cases it is the moderate exemplars (neither very good instances nor very good noninstances) that are the most unstable. These results also jibe with Ross's\ia{Ross, John Robert} findings. Barsalou goes on to argue that there simply are no invariant representations of categories in the human cognitive system. Invariant representations are merely analytic fictions created by psychologists; perhaps linguists should be added to the list of culprits. Nonetheless, he suggests that the task of judging typicality might not make use of the same representations as judging set membership; the former might use probable properties, while the latter might use discriminative ones.

It might be that the nature of the particular tasks used by prototype theorists (and linguists) inherently induces graded behavior, independent of the nature of the underlying knowledge. If this is so, the status of that underlying knowledge as discrete or continuous must be demonstrated by other means. But how could we ever know whether a grammar, if it exists independent of performance mechanisms, classifies sentences dichotomously? If performance mechanisms induce graded structure by themselves, and if (as I argue) they can never be circumvented because competence is not directly accessible, then it might not be possible to investigate empirically how a grammar itself classifies sentences.\footnote{Wayne Cowart (personal communication)\ia{Cowart, Wayne} suggests that part of the problem here could lie at the level of implementation: although our brains may be trying to realize a discrete system, their hardware is analog, which makes the implementation imperfect.
}
%\textsuperscript{5}
 There are many possible combinations of mental structures that could yield graded acceptability judgments.\is{grammaticality!degrees of} For instance,  \citet{FillmoreEtAl1979b} 
 argue that judgment ratings might reflect the interaction of discretely varying elementary components that only have the appearance of continua.\footnote{Technically there cannot be a true continuum of grammaticality values of sentences, because continua involve an uncountably infinite number of values, and most linguists believe that there are only a countably infinite number of sentences. When linguists speak of grammaticality being a continuum, they typically mean that it is a discrete scale with more than two possible values.}
%\textsuperscript{6}
 \citet{Carroll1979} follows Bever\ia{Bever, Thomas G.} in suggesting that graded acceptability\is{grammaticality!degrees of} can result from a discrete 
%\originalpage{70} %  Chapter Three
grammar plus performance rules of some sort. In either case, neither grades of grammaticality\is{grammaticality!degrees of} nor grades of ungrammaticality would be part of the grammar. It could be that while fully grammatical sentences can be judged as such without much reference to their meaningfulness, interpretability becomes an important factor in judging some ungrammatical sentences. That is, the closer we can come to figuring out what an ungrammatical sentence is supposed to mean, the more likely we are to judge it to be acceptable. (See \citet{Fowler1970} for essentially this argument; he insists that ``an ungrammatical sentence is an ungrammatical sentence is an ungrammatical sentence,'' regardless of how it might be interpretable on the basis of extragrammatical information. Others, such as \citet{Katz1964}, have claimed that there is an identifiable class of \isi{semigrammatical sentences}, by which is meant ungrammatical utterances that are comprehensible.) Questions about the nature of the concept \textit{grammatical sentence} might eventually be answerable, but for now I leave them open and move on to a related question that likely \textit{is} answerable\schdash{}can we obtain useful judgments of degree of acceptability from subjects?

\subsection{Experiments on Chomsky's Three Levels of Deviance}\label{sec:3.3.2}
\ia{Chomsky, Noam}

An enormous amount of research on degrees of (un)grammaticality\is{grammaticality!degrees of} was generated by Chomsky's\ia{Chomsky, Noam} identification of three levels or kinds of deviance.\is{three levels/kinds of deviance (\textit{Aspects})!experiments on} (See \citet{Schnitser1973} for comparison of Chomsky's\ia{Chomsky, Noam} ideas with other contemporary ideas about degrees of badness.) The discussion in \aspectsq spurred a flurry of experiments designed to test Chomsky's\ia{Chomsky, Noam} idea by obtaining judgment ratings. In retrospect, these experiments seem somewhat misguided. Chomsky\ia{Chomsky, Noam} himself never claimed that degrees of \textit{grammaticality} would correspond to degrees of \textit{acceptability;} in fact, he explicitly states that the two do \textit{not} coincide (see \sectref{sec:2.2}).\footnote{It is ironic, then, that current work in syntactic theory regularly makes heavy use of relative degrees of badness.}
%\textsuperscript{7}
 Predictably, the ensuing results have often been contradictory.\footnote{There has been much selective interpretation of acceptability as bearing on grammaticality in this area. If the results go the right way, they are taken as evidence; if not, they are dismissed as performance artifacts.}
%\textsuperscript{8}
 Nevertheless, we can learn quite a bit about the nature of scalar judgment from these experiments. I present here a selective review; see \citet{Moore1972} and works cited therein for further references.
 

% Judging Grammaticality  71

\citet{DowneyEtAl1968} studied the effects of Chomsky's\ia{Chomsky, Noam} three levels of deviance\is{three levels/kinds of deviance (\aspectsq)!experiments on} on acceptability ratings, paraphrasing, and free recall. Subjects rated sentences on a scale from 0 (``completely acceptable'') to 3 (``completely unacceptable''). Subjects were given two examples of how a sentence could be unacceptable, but Downey \& Hakes do not provide details of these examples. The order among subjects' mean acceptability ratings was as predicted, although the difference between subcategorization\is{subcategorization violation} and phrase structure violations was not significant. However, the recall scores showed a reversal of this pattern, with sentences containing selectional violations\is{selectional restriction violation} being harder to remember correctly than those with subcategorization errors.\footnote{Results from the paraphrase task were not quantitatively analyzable; the authors merely discuss what strategies they believe the subjects used.}
%\textsuperscript{9}
 \citet{Stolz1969} performed a replication of this study, adding finer distinctions from Chomsky's\ia{Chomsky, Noam} hierarchy of selectional features, e.g., that the difference between mass nouns and count nouns is greater than that between human nouns and nonhuman nouns, although problems with materials made the possible effect of this difference inconclusive. Stolz also used a 4-point response scale, and told subjects that their responses should be based on \textit{any} kind of deviance, including anomalous meanings as well as form. His results showed that sentence types were rated in the following order from least to most acceptable: random strings; sentences with subcategorization violations;\is{subcategorization violation} sentences with selectional violations;\is{selectional restriction violation} analytic  grammatical sentences; and contingently true grammatical sentences.\footnote{ An analytic sentence is true simply by virtue of the meanings of its words, whereas a contingently true sentence makes a true claim about something in the world.
}
%\textsuperscript{10}


\citet{Moore1972} set out to test a hypothesis somewhat more general than Chomsky's\ia{Chomsky, Noam} proposal, which applies only to verbal features. He asked whether there is an acceptability hierarchy created by Chomsky's\ia{Chomsky, Noam} three types of violation,\is{three levels/kinds of deviance (\textit{Aspects})!experiments on} regardless of where in a sentence they occur. He also sought corroboration for such a hierarchy from sources other than judgments, in particular, subjects' reaction times in making those judgments. Moore's\ia{Moore, Timothy E.} prediction was that a severely ungrammatical sentence should be processed faster than a marginally ungrammatical one, because more thorough processing would be required to detect a subtler error. His first experiment used a paradigm that was adopted in many subsequent studies. Subjects were shown a written sentence with a blank line where a missing word would go (e.g., \textit{Sincerity may \rule{2em}{1pt} the boy}). They were then shown a word
that could fill the blank on a separate screen and were asked to decide as quickly as possible whether the sentence would be ``appropriately completed'' by that word.\footnote{Moore\ia{Moore, Timothy E.} apparently wanted to ensure that subjects took selectional restrictions\is{selectional restriction violation} into account in making their decisions. He says, ``The [experimenter] explained to  [the subject] that terms such as `appropriate' and `acceptable' were deliberately being used, instead of `grammatical,' because of the fact that the inappropriate sentences were inappropriate for varying reasons, some more syntactic than semantic. Inasmuch as `ungrammatical' is frequency employed as being synonymous with  `syntactically deviant,' such instructions attempted to preclude any such dichotomy being set up by [the subject].'' Since his subjects were not linguistics students, however, being presented with this terminology may only have confused them.}
%\textsuperscript{11}
 The incomplete sentences were designed so that there was no way of assessing their grammaticality until the missing word was seen. The sentences in \REF{ex:3:4}, \REF{ex:3:5}, and \REF{ex:3:6} below illustrate stimulus sentences with blank lines in verb, subject, and object position, respectively (shown by the underline under the subsequently presented target word). In each set, the first sentence contains a lexical category violation.\is{lexical category violation} Example (\ref{ex:3:4}b) violates strict subcategorization,\is{subcategorization violation} while (\ref{ex:3:5}b) and (\ref{ex:3:6}b) violate selectional restrictions\is{selectional restriction violation} between the verb and the noun phrase. Example (\ref{ex:3:4}c) violates a selectional restriction\is{selectional restriction violation} of the verb, while (\ref{ex:3:5}c) and (\ref{ex:3:6}c) violate selectional restrictions\is{selectional restriction violation} between the noun and its modifying adjective.\footnote{Moore\ia{Moore, Timothy E.} did not consider strict subcategorization\is{subcategorization violation} to be a property of nouns, and therefore could not make all violations in the (b)-level sentences of the same type. He seems to assume that Chomsky's\ia{Chomsky, Noam} theory predicts that all selectional restriction violations\is{selectional restriction violation} are equally ungrammatical, so (\ref{ex:3:5}b) and (\ref{ex:3:5}c) should be equivalent, and (\ref{ex:3:6}b) and (\ref{ex:3:6}c) should be equivalent. However, since I am not particularly concerned with the theoretical implications of Moore's study, I do not address this issue here.
}
%\textsuperscript{12}


\ea\label{ex:3:4}
\ea Smart voters \uline{uncle} honest politicians.
\ex Noisy dogs \uline{growl} night animals.
\ex Catchy slogans \uline{believe} unwary citizens.
\z
\z


\ea\label{ex:3:5}
\ea Modern \uline{wanders} improve factory efficiency.
\ex Sensible \uline{ideas} distrust public officials.
\ex Nosey \uline{ditches} annoy suburb dwellers.
\z
\z


\ea\label{ex:3:6}
\ea Large factories utilize efficient \uline{hesitates}. 
\ex Big corporations appoint many \uline{machines}.
\ex Factory foremen appreciate eager \uline{tools}. \citep[553]{Moore1972}
\z
\z


\noindent
The main effect of level of violation seemed to support Chomsky's\ia{Chomsky, Noam} theory: reaction times increased from (a) to (b) to (c) sentences. Interestingly, the mean reaction time for filler sentences that were grammatical was between those for (a) and
(b) sentences. However, there were several mitigating interactions. In particular, there was no difference between reaction times for sentences like (\ref{ex:3:4}b) and (\ref{ex:3:4}c), while sentences like (\ref{ex:3:5}c) and (\ref{ex:3:6}c) did show longer decision time than their
(b) counterparts (but Chomsky's\ia{Chomsky, Noam} theory might not have predicted the latter difference). Moore\ia{Moore, Timothy E.} takes this as evidence that the process of checking grammaticality occurs in two passes. First, the major relations between subject, verb, and object are checked, and then relationships within the NP constituents are examined. Under this view, both verbal subcategorization\is{subcategorization violation} and selectional restrictions\is{selectional restriction violation} are examined in the first pass and have no differential status, as reflected in the reaction time data. Several results support the importance of the verb in determining requirements for the rest of the sentence. For instance, although (\ref{ex:3:4}c) and (\ref{ex:3:5}b) constitute exactly the same type of violation, (\ref{ex:3:4}c) took significantly longer to reject. A large problem with this paradigm, of course, is that the sentences differ in many ways not relevant to the violations under study.

A second experiment examined whether grammaticality ratings of the same sets of sentences on a 20-point scale would conform to Chomsky's\ia{Chomsky, Noam} hierarchy.\is{three levels/kinds of deviance (\textit{Aspects})!experiments on} A new group of subjects was told that a sentence was ``acceptable'' if it ``could occur in normal, everyday usage.''\footnote{Moore\ia{Moore, Timothy E.} does not explain why the definition of acceptability was changed from that of the first experiment.}
%\textsuperscript{13}
 Subjects were asked to rate acceptable sentences with a score of  1, whereas scores of 2 to 20 represented increasing unacceptability.\footnote{One positive feature of Moore's\ia{Moore, Timothy E.} instructions was that they explicitly encouraged subjects to look over a few of the (practice) sentences\is{practice trials} to get an idea of the range within which they were working. Subjects were told to make use of the full range of the rating scale.}
 Once again, the main effect of level of violation was as predicted. Mean ratings for (a), (b), and (c) sentences were 13.5, 11.0, and 9.2, respectively, but the latter two ratings did not differ significantly for sentences with blank lines in verb position, contradicting  several previous studies. 
\footnote{Moore\ia{Moore, Timothy E.} suggests that other studies failed to control for the location of the violation,\is{location of ungrammaticality} and hence would not have seen the crucial interaction.}
%\textsuperscript{15}
 \citet{MooreEtAl1979}
attempted to distinguish various possible serial and parallel models that could account for subject-verb-object relations being  checked faster than noun-adjective ones, using the same blank-line paradigm that was used in Moore's first experiment, but with sentences that contained \textit{two} kinds of violation, e.g., \textit{Old houses quarrel valuable relics}, where both subject-verb selection\is{selectional restriction violation} and verbal subcategorization\is{subcategorization violation}  are violated. If both kinds of violation  are searched for in parallel, one
%\originalpage{74} %  Chapter Three
would expect an average judgment speed gain on such sentences as compared to the judgment time required to search for either of the two violations by itself (assuming the search for ungrammaticality is self-terminating), but no such significant gain was found. On the other hand, no significant increase in judgment time was found, suggesting that the search does terminate when one violation is encountered. Moore\ia{Moore, Timothy E.} \& Biederman take this as support for a serial model, where subject-verb-object relations are checked before internal NP relations. A follow-up rating task with no time constraint showed that double violations did decrease the grammaticality of sentences as compared to single violations, so that this rating process, unlike the speeded determination of grammaticality, does not terminate on encountering the first violation.\footnote{This experiment used a 100-point rating scale, but the authors do not say why they felt that such a wide range of possible ratings was necessary.
}
%\textsuperscript{16}


The most recent study dealing with Chomsky's\ia{Chomsky, Noam} three levels of deviance\is{three levels/kinds of deviance (\textit{Aspects})!experiments on} was performed by \citet{Nagata1990b}. His subjects used a 7-point scale to rate three types of violation: lexical category violations;\is{lexical category violation} selectional restriction violations\is{selectional restriction violation} between verbs and their objects; and selectional restriction violations between nouns and their modifying adjectives. Nagata found significant differences of rating in the predicted  order; his results thus support Chomsky's\ia{Chomsky, Noam} distinctions.

\subsection{Other Experiments}\label{sec:3.3.3}

Chomsky's three levels of violation are not the only theoretical constructs that have spawned experimental work on levels of grammaticality. Around the time of Chomsky's\ia{Chomsky, Noam} proposal, some researchers were taking different approaches to the
study of degrees of grammaticality. \citet{Coleman1965} looked at four kinds of stimuli, ranging from random strings to strings where each word correctly matched a valid phrase structure rule in lexical category. His intermediate levels were less
sensible; they involved choosing words from the correct \textit{phrasal} category, e.g., approximating a noun phrase by choosing any two words that could appear in a noun phrase. Example \REF{ex:3:7} shows sample sentences from each of Coleman's four levels.

\ea \label{ex:3:7}
\ea Think apron the wits for about. 
\ex One the could to a her.
\ex The grass seldom were struck Lindy.
\ex The dust could always be Disneyland.
\z
\z
% Judging Grammaticality  75
\noindent
Coleman found that subjects' rank-orderings were significantly monotonically correlated with degree of grammaticality defined in this way. Moreover, other measures besides judgment correlated with this scale. For example, the more grammatical strings were easier to memorize and to perform a \isi{cloze test} \citep{Taylor1953} on correctly. Like many cases to be reviewed in this subsection, these results seem neither particularly surprising nor particularly informative.

Around the same time, \citet{Marks1968} looked at those most mystical of linguistic beasts, multiply self-embedded sentences.\is{center-embedding, multiple} He instructed subjects to judge their grammatical structure, not their length, complexity, difficulty of comprehension, or frequency of usage. For sentences with up to five self-embeddings, his results showed a power-law correlation between degree of embedding and subjects' ratings. That is, unacceptability grew as a function of the number of embeddings to a constant exponent. Another study by \citet{Marks1965,Marks1967} was inspired by Chomsky's\ia{Chomsky, Noam} informal statement that some ungrammatical sentences obviously have more structure than others. Marks's hypothesis was that, in forming judgments of ungrammatical sentences, people consider the serial position of a violation\is{location of ungrammaticality} within a sentence as well as the sentence's status as described by the grammar. Since sentences are processed from left to right, earlier errors should interfere more with processing, because early words prepare the processor for later ones and set up expectations and restrictions. Marks constructed stimulus materials by taking simplex sentences and sentences with infinitival clauses and reversing the order of two adjacent words in various positions, producing a paradigm like the one in \REF{ex:3:8}:

\ea\label{ex:3:8}
\ea The boy hit the ball.\\
\ex Boy the hit the ball.\\
\ex The boy hit ball the.\\
\ex The hit boy the ball.\\
\ex The boy the hit ball.\\
\z
\z


\noindent
Sentences were presented in groups with random order and subjects were asked to rank them from the best English to the worst English. As predicted, noun-determiner inversion was judged less acceptable if it occurred earlier in the sentence. Moreover, sentences like (\ref{ex:3:8}d) were judged to be worse than those such as (\ref{ex:3:8}e), although Marks points out that the two types of inversion found in these sentences are not the same, and serial position might not be the important factor here. But at least in the former case, it is hard to see how any traditional grammar would distinguish the grammaticality of the sentences, since such grammars treat all noun phrases as equivalent. Serial position of anomaly thus constitutes a reasonable candidate for an extragrammatical factor that contributes to acceptability. 

Scott performed a series of similar experiments (\citealt{Scott1969}; \citealt{ScottEtAl1973}), except that he used a single basic sentence order (subject-verb-object-qualifier) and rearranged whole constituents rather than words. His subjects rated each permutation as ``acceptably grammatical'' or ``not grammatical.''\footnote{Subjects were offered a third choice, namely, ``grammatical but with a different meaning from the unpermuted sentence''; we shall not be concerned with this possibility here.}
The percentage of subjects who accepted various permutations ranged from 100\% to 0\%. Scott takes the results to show that there are at least five degrees of grammaticality among these sentences, but this number seems to be arbitrary. We should also keep in mind that, unlike Marks's subjects, Scott's were only giving good/bad judgments, so the gradations appeared only in the pooled results and do not bear on the judgments of individual subjects. Scott tries to account for the numbers of acceptances on the basis of how many constituents were moved and in how many places the canonical constituent order was split. This index does not yield a perfect correlation with judged grammaticality, so Scott \& Mills looked for other factors that might have determined the outcome\schdash{}in particular, meaningfulness.\footnote{Scott \& Mills cite various psychological sources for their definition of \textit{meaningfulness} as ``the association value of a single written verbal unit,'' for which they use frequency of occurrence as a metric. This does not correspond to what other authors have meant by the meaningfulness of a sentence.}
This factor was found to have no significant effect, but a useful outcome of the experiment was that when the permutations were not presented all together with their canonical form, grammaticality was rated much lower, suggesting that people accept a sentence more often if they can see that it is a rearrangement of a grammatical sentence.

In yet another study of the effect of word order on grammaticality judgments,\is{word order violations, effect on grammaticality judgments} \citet{DanksEtAl1971} considered violations of adjective ordering con-\linebreak straints (e.g., \textit{Swiss red big tables} versus \textit{big red Swiss tables}) using a ranking test with the six possible permutations of three prenominal adjectives. The results showed that the position of the adjective that was most closely related to an intrinsic property of the noun was the primary determinant of acceptability: the closer it was to the noun, the higher the sentence was ranked.

More recently, Crain \& Fodor (\citeyear{CrainFodor1985}, \citeyear{CrainEtAl1987}) looked at the effects of different kinds of ungrammaticality on a \isi{sentence matching task},\is{metalinguistic  tasks!sentence matching} where the subject
% Judging Grammaticality  77
must decide whether two simultaneously displayed sentences are identical. The basic finding was that number agreement and quantifier placement errors (shown in \REF{ex:3:9} and \REF{ex:3:10}, respectively) increase matching times, while Subjacency\is{Subjacency violation!in sentence matching task} and (certain) \isi{Empty Category Principle} violations (shown in \REF{ex:3:11} and \REF{ex:3:12}) do not.

%\setcounter{itemize}{8}
\ea \label{ex:3:9}
*Mary were writing a letter to her husband.
\z
\ea\label{ex:3:10}
 *Lesley's parents are chemical engineers both.
\z
\ea\label{ex:3:11}
 *Who do the police believe the claim that John shot?
\z
\ea\label{ex:3:12}
 *Who did the duchess sell Turner's portrait of?
\z


While previous work had attributed this difference to different levels of ungrammaticality, Crain \& Fodor argue that it was due instead to the correctability\is{correctability of ungrammatical sentence} of the error: the first two types of error are easy to correct automatically, while for the other two there is no obvious correction\is{ungrammatical sentence, correction of} that can convert them directly into grammatical sentences. Their claim is that if a correction is made, it must be \textit{undone} in order to perform the matching task,\isi{sentence matching task}\is{metalinguistic  tasks!sentence matching} since the subject must decide whether the sentences are literally identical. In cases like \REF{ex:3:11} and \REF{ex:3:12} no correction is possible, hence the bad sentence can be compared directly. \citet{ForsterEtAl1987} question this interpretation, suggesting that the correlation with correctability is epiphenomenal and cannot be the cause of the observed time differences. Both sets of authors acknowledge that other factors are at work as well, but the possibility that the correctability of a sentence could be a factor in relative ratings of acceptability should not be dismissed; whether it bears any relation to theories of degree of grammaticality is a matter of debate.

\subsection{Ratings, Rankings, and Consistency} \label{sec:3.3.4}

\is{acceptability!number of levels distinguishable}It is a fundamental assumption throughout this book that empirical facts are useful (and interesting) if they are systematic, because they must tell us something about the minds of the subjects who produce them. It remains a matter of analytical interpretation to decide \textit{what} these facts tell us. Thus, we must determine whether graded judgments are systematic, and the results mentioned throughout this section strongly suggest that they are. The next thing one might wish to determine is just how many meaningful distinctions of levels of acceptability (relative or absolute) can be made. This would provide a basis for establishing a
%\originalpage{78} %  Chapter Three
procedure for eliciting such distinctions.\footnote{ But see \citet[7\textendash{}12, 70\textendash{}72]{Cowart1997} for the claim that the choice of response scale might not make much difference to patterns of relative acceptability.}
%\textsuperscript{19}
\citet{Chaudron1983} cites several psychometric studies showing that rating scales generally increase in reliability with increasing numbers of levels up to 20.\footnote{\citet{Snow1975} points out the apparently contradictory finding that psychologists who measure attitudes have shown that subjects find scales with more than seven points hard to use.}
%\textsuperscript{20}
 Presumably this can be shown by giving subjects different sizes of scale on which to rate the same stimuli: if you have too few levels, people collapse true distinctions arbitrarily, whereas if you have too many, people create spurious distinctions arbitrarily. Thus, the ``true'' number of distinctions will show the greatest consistency within (and perhaps also between) subjects. It follows that studies that choose inappropriate numbers of levels add spurious variation to their results, possibly concealing the effects they are supposed to uncover. As far as I am aware, a psychometric investigation along these lines has never been done with specific regard to grammaticality judgments.
 
\is{acceptability!number of levels distinguishable}Even if we can find the optimal size of rating scale, there will still be problems with this measure of grammaticality judgments. One major problem is how to quantify inter- and intrasubject consistency,\is{consistency (between and within subjects)!quantifying}\is{rating scale!defining consistency on} which is an important part of much work in this field. If we use a 20-point scale, should we require two subjects to give exactly the same rating of a sentence in order to consider them consistent? Would plus or minus one position be sufficient? What if two subjects show exactly the same distances between ratings of multiple sentences, but their absolute ratings are offset by some constant? Can we merely say that one is biased toward more conservative or more liberal judgments, and consider their responses to be fully consistent? Depending on the size of the offset constant, that might not seem appropriate, but neither would a conclusion of total inconsistency. If we standardize using \textit{z}-scores, can we be sure we are not throwing away real differences?\footnote{In doing so, we would be implicitly adopting the theoretical position that any such differences simply are not part of what we are studying. For instance, the fact that Speaker A could be consistently more conservative in grammaticality judgments than Speaker B does not tell us anything about their grammars. I do not think we are in a position to say this with any degree of certainty. See \citet[13\textendash{}14, 114]{Cowart1997} for more on the use of standard scores.}
%\textsuperscript{21}
 Similar problems arise if some subjects simply fail to use the whole range of the scale, which can easily happen unintentionally if subjects have no idea what range of sentence types they will see. (For this reason alone, \isi{practice trials} with representative anchor sentences are a good idea) If we are attempting to compare consistency  of subjects between  studies that use different rating
% Judging Grammaticality  79
scales, the consistency measure will have to be scaled accordingly. Such problems have prompted many researchers to consider whether, instead of asking for absolute ratings of sentences, we should instead require subjects simply to rank order them from most to least acceptable. This approach does have certain advantages. For one thing, psychometric research indicates that people are much more reliable on comparative, as opposed to independent, ratings \citep{Mohan1977}. Rank orders also solve the problem of different baselines on a rating scale, and there are nonparametric statistical tests for assessing the consistency or correlation between sets of rank orders. Relative judgments are not without problems, however. One problem is efficiency \citep{MaclayEtAl1960}: the amount of information one can extract from a given number of relative judgments is much less than the amount one can extract from absolute ratings\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)}. While exhaustive pair-wise comparisons are not necessary to arrive at an ordering of a set of sentences, there is surely a limit to how many sentences subjects can handle in one group; intergroup orders must then somehow be elicited.

\is{acceptability!number of levels distinguishable}A further problem with the interpretation of relative judgments is that pairwise differential acceptability might not be transitive.\is{nontransitive paradox} That is, a subject who judges sentence A better than sentence B, and also judges sentence B better than sentence C when considering them two at a time, does not necessarily judge sentence A better than sentence C when they are examined side by side.\footnote{A hybrid solution that solves this and some other problems is to \textit{elicit} absolute ratings but
\textit{convert} them to rankings. Under this solution, circularity can never arise.}
%\textsuperscript{22}
\citet{HindleEtAl1975} cite an instance of this situation with regard to the sentences in \REF{ex:3:13}, which contain \textit{anymore}, although they only present group data.\is{anymore, positive use of@\textit{anymore}, positive use of}

\ea \label{ex:3:13}
\ea They've scared us out of eating fish anymore. 
\ex It's dangerous to eat fish anymore.
\ex All we eat anymore is fish.
\z
\z

\noindent
Twenty-two such sentences were presented to 36 subjects, who were asked to compare them and then give each a grammaticality rating on a 5-point scale.\footnote{These data are not quite equivalent to ranked comparisons, since a maximum of five distinctions could be made.}
%\textsuperscript{23}
 It was determined for each subject which of a given pair of sentences he or she had rated more grammatical, or whether the pair had been rated equally grammatical, and subjects' ratings were tallied on this basis. Hindle \& Sag found that while more subjects preferred (\ref{ex:3:13}a) over (\ref{ex:3:13}b) than vice versa, and more preferred
%\originalpage{80} %  Chapter Three
(\ref{ex:3:13}b) over (\ref{ex:3:13}c), more preferred (\ref{ex:3:13}c) over (\ref{ex:3:13}a).\footnote{The differences in ratings were quite small, with many subjects rating the pairs as equally grammatical, which is not surprising given the small size of the rating scale compared to the number of sentences.}
%\textsuperscript{24}
 They conclude that their comparison data are spurious, because they involve an apples-and-oranges comparison: the sentences are too structurally diverse and hence their acceptability might be affected by different determining factors. \citet{DanksEtAl1970} encountered similar circular triads on an individual level, and take them as a measure of a subject's inconsistency.\is{consistency (between and within subjects)} While a detailed examination of this issue would take us too deeply into psychometric theory, my purpose is merely to point out that such methodological problems will have to be dealt with if a paradigm involving relative judgments is followed. (See \citet{Gardner1974} for a discussion of \isi{nontransitive paradox} in various domains, and the argument that these \textit{can} be rational if the pairwise comparisons involve different criteria. This could easily happen in the case of relative grammaticality judgments; see \citet{Watt1975} for this view. \citet{Einhorn1982} notes similar phenomena under the name of ``intransitive choices''\is{nontransitive paradox} and shows how they can easily occur in everyday situations.)

\is{acceptability!number of levels distinguishable}It is also an open question what to make of discrepancies between absolute ratings and rank-orderings\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)} given by the same subjects, as have been found by \citet{SnowEtAl1977} (see \sectref{sec:4.2})
and others. Even if we can establish that the discrepancies are due to context or contrast effects from neighboring sentences, this does not determine which kind of judgment is closer to the truth. \citet{GreenbaumEtAl1970} also examined the question of intra- and intersubject consistency,\is{consistency (between and within subjects)} and this rating-ranking contrast in particular, using tests of evaluation versus performance. Their evaluation test involved a rating on a 3-point scale: ``perfectly natural and normal,'' ``wholly unnatural and abnormal,'' or ``somewhere between.'' Their performance test involved the presentation of multiple variants of a sentence together, and required subjects to rank them as well as to rate each sentence individually (my summary is necessarily imprecise, since these researchers describe in great detail numerous experiments with minor variations). Greenbaum \& Quirk typically used groups of 20\textendash{}30 subjects and found that cross-group consistency was quite high, with very few significant differences on judgments (and other kinds of metalinguistic tasks). Also, their design allowed for several sentences to be judged a second time. Most sentences showed 90\textendash{}95 percent consistency (measured as the number of subjects giving the same judgment both times a sentence was presented), but consistency for some sentences
% Judging Grammaticality  81
was as low as 54\%. A very few sentences were both rated and ranked. The two measures generally correlated with each other, but sometimes sentences that were rated equally grammatical were ranked differently, even  though  tied  rankings were allowed. This might mean that the 3-point scale was too limiting, not allowing enough room for the distinctions subjects wanted to make.

\is{acceptability!number of levels distinguishable}Yet another study comparing rating and ranking was conducted by \citet{Mohan1977}. Ratings were on a scale of 1 (``completely well-formed'') to 10 (``completely ill-formed'') that was anchored by an example sentence for each of the extremes (probably a very good idea). There were 11 sentences to be ranked; procedure was a within-subjects variable, the two tasks being separated by a 2-week interval. Unfortunately, the instructions seem a bit too usage-oriented: ``Consider each of the sentences and decide if it would be possible that you would say this in conversation.'' The study was actually concerned in part with establishing whether individual speakers can do ordinal scaling of sentences, or whether such scaling only emerges by pooling multiple speakers' dichotomous judgments, where speakers might have different thresholds of acceptability and no differentiations within the good and bad sentence groups. Nonparametric statistical analysis showed that the cross-speaker agreement in rankings was much higher than would be expected under the latter interpretation. Mohan also found some evidence for a yea-saying factor, a tendency to favor acquiescence, i.e., accepting some sentences regardless of their grammatical status, by correlating the number accepted by each individual on two unrelated sets of sentences; there was a small but significant positive correlation. As for rating versus ranking, correlating the number of acceptances under the two procedures again gave a highly significant result,\footnote{Sentences rated 1\textendash{}5 were treated as acceptances; subjects drew a threshold line in their rank orderings, which allowed the comparison.}
%\textsuperscript{25}
 although the correlation itself was modest (.57).

\section{The Judgment Process}\label{sec:3.4}

In this section I will consider what people might actually be doing when judging the grammaticality of a sentence. Just about the only thing we know for sure is that we do not know what they are doing. What follows is some considered speculation. Many researchers want to relate this question to another unanswered question, namely, what happens in the ordinary processing of a sentence that one performs  during the course of  a conversation  or while  reading? There are two
%\originalpage{82} %  Chapter Three
extreme positions one can take on the relation between these two processes:\is{parsing!versus judgment} they might be identical, or they might be totally different. In the first case, some might argue (this is perhaps the null hypothesis) that the only difference between processing for judgment and processing for conversation is that in the former case the reply consists of a ``yes'' or ``no'' (or a numeric rating, or whatever), instead of a pragmatically related utterance. Obviously, the decision between the possible judgments has to come from somewhere, but on this view the processing of the sentence itself is identical. The differences come in deciding on a rating versus deciding what to say next, both of which are separate from the parsing, semantic analysis, etc., that go into decoding the incoming utterance. At the other extreme, one might say that judging is nothing at all like understanding and involves none of the same cognitive mechanisms. If you are told you will have to judge a sentence, you route it to the sentence-judging processor in the mind, rather than the sentence-comprehending processor. These two modules are entirely separate and might differ in arbitrary ways. (If this were put forward as a serious proposal, one would have to address the question of how and why such a separation would come to exist in the mind.) As with most interesting psychological questions, many researchers suspect that the answer lies somewhere in the middle. We hope reality is not like the second position, but fear it is not like the first either. Let us consider which positions the major researchers in this field have espoused, the extent to which these positions have empirical support, and what their implications are for investigating grammar. I present my own speculation on this issue in detail in \sectref{sec:6.2}.

I have already reviewed one line of thinking about the judgment process in \sectref{sec:2.4}, namely, that it has something in common with \isi{introspection}, which might introduce some artifactual phenomena. But grammaticality judgments\linebreak seem to have much more in common with other psychological judgments.\linebreak Graeme Hirst (personal communication)\ia{Hirst, Graeme} has suggested the following analogy to food tasting.\is{grammaticality judgments!parallels to tasting} If someone asks you what you remember about last night's dinner, chances are you will not have much to say. Unless there was something strikingly good or strikingly awful about the food, you will likely have only a general impression that it was OK, if no particular attention was drawn to it at the time you ate it. On the other hand, if someone offers you some food and asks you for your impressions \textit{before} you taste it, you will pay particular attention to the flavors, textures, aromas, etc.; perhaps you will chew more slowly; and you might be able to give much more detailed comments, concerning, e.g., particular herbs you detect, how
% Judging Grammaticality  83
tender the meat is, and so on. Your host could ask you more detailed questions, too, such as whether you think there is too much garlic in the tomato sauce. Intuitively, it seems at least plausible that the taste stimuli are being processed in a different way, or to a different degree, than if no attention were being drawn to them, and the same might hold for sentence tasting.\footnote{ This argument has been made for other metalinguistic tasks as well. For instance, \citet{KessEtAl1983} suggest that in an ambiguity detection situation, looking for ambiguity puts subjects in a different mode from that used in a paraphrase task where the stimulus just happens to be ambiguous, so different processing can be expected, with different results.}
%\textsuperscript{26}
 Hirst\ia{Hirst, Graeme} also suggests a third, hybrid scenario, in which the opinion is solicited immediately \textit{after} the tasting. If the question is unexpected, then tasting will have proceeded as usual (as in the first situation), but since no time has elapsed we might have access to information that will later be lost or forgotten, impressions that were induced by the stimulus but ignored because they were irrelevant. To the extent that processing for prewarned judgment\is{grammaticality judgments!unexpected} differs from regular processing, this last scenario could provide the best of both worlds: regular processing, but access to additional information, which Hirst\ia{Hirst, Graeme} refers to as the traces of processing. (See also \sectref{sec:4.4.1} on parallels to wine tasting, and \sectref{sec:5.2.7} on speed of judgment.)

If the reader has not wandered off to the fridge by now, let us apply these ideas more directly to linguistic judgments (see also \citet[202\textendash{}203]{Birdsong1989}). In the worst case, we could imagine that expected judgment causes people to revert to conscious reasoning\is{conscious reasoning!versus judgment} \textit{about} sentences, rather than processing \textit{of} them. Consciously known rules could be applied in this way to decide grammaticality, but the only rules about language that most nonlinguists have conscious access to are those learned in grade school, which tend to be of the prescriptive\is{prescriptive rules} variety. Thus, subjects might reason that a sentence is ungrammatical because it ends with a preposition, since they remember a rule stating that this is a bad thing. \citet{SchmidtEtAl1977} showed that many people are clearly aware of prescriptive standards even if these are not reflected in their spontaneous speech. These researchers also found strong discrepancies between subjects' production on performance tests similar to \citegenp{QuirkEtAl1966} and their choice of which forms were correct, so it seems that, at least in some cases, subjects \textit{can} distinguish their linguistic intuitions from their prescriptive knowledge, but it is not yet clear whether we can induce them to exclude prescriptive knowledge from their judgments. Because prescriptive grammar does not necessarily have any relation to descriptive reality, judgments involving prescriptive knowledge are of no use to us. But if we
avoid the generally well-circumscribed prescriptive cases, can we not then expect to avoid conscious processing? Hirst\ia{Hirst, Graeme} argues in the negative. In general, people seem to be able to invent spurious rules or principles as post hoc rationalizations of behavior \citep{NisbettEtAl1977}, including language behavior. In \chapref{sec:5}, I report on studies in which respondents who had to justify their grammaticality choices gave (by linguistic standards) quite outrageous answers. Alternatively, even if people sense their true intuitions about a sentence, they might not express them if they cannot fabricate a justification. Thus, conscious reasoning/parsing by subjects is most undesirable.\is{conscious reasoning!reasons for avoiding} But does conscious reasoning ever occur? As drastic and ad hoc as it seemingly must be, would it not result in judgments so far from what we know about actual usage\is{grammaticality judgments!versus language use} that the discrepancies would be strikingly obvious? Hirst\ia{Hirst, Graeme} argues that such discrepancies might well exist. Perhaps there really \textit{is} a huge shift, comparable to the difference between written and spoken language, which also might not be obvious until systematically studied. This is all the more likely, given that judgments typically involve such rarely occurring forms anyway: the usage data with which to compare them are extremely sparse.

There is suggestive experimental evidence for differences between judgments and usage. \citet{Nagata1990a} wanted to examine the extent to which ungrammaticality affects our initial parsing of a sentence, as opposed to our post hoc evaluation of it. To do this, he measured reaction times\is{acceptability!and reaction time} of subjects who were asked to judge the grammaticality of sentences quickly on a good-bad scale, and plotted them against their grammaticality rating on a scale from 1 to 7 (where 1 = grammatical and 2\textendash{}7 represent increasing degrees of ungrammaticality), which was elicited after the initial judgment and was not speeded. To control for the length of the sentences involved, each sentence was presented in two parts, with the subject pressing a button to expose the second part and start the timed trial. Stimulus sentences were paired such that the identical target strings could be used as the second parts of two different sentences. The sentences were designed so that the target string completed one sentence grammatically, but completed the other ungrammatically, thus matching the length of the timed portion exactly. Nagata's initial hypothesis was that highly ungrammatical sentences would show longer reaction times than mildly bad ones, because minor violations could go unnoticed whereas major ones would disrupt parsing. His findings showed something quite different, however. When reaction time is plotted against mean grammaticality rating, the result is an inverted U-shaped curve. Sentences of intermediate ungrammaticality took more time to judge than very good or very bad ones. We note that this differs
% Judging Grammaticality  85
from the data that \citet{Moore1972} reported (see \sectref{sec:3.3.2}): he found reaction time inversely related to severity of violation. We must keep in mind, however, that Moore was looking only at three very specific types of violation, which might not have encompassed the full range of possible severity. Thus, his results might all come from the higher end of Nagata's spectrum, with which they are consistent. Nagata's data do confirm Moore's finding that completely grammatical sentences take somewhat longer to judge than the worst violations, presumably because the latter do not require the whole sentence to be read.

There are many possible interpretations of such a general finding, but here are some speculations. Judging perfectly good sentences and very bad sentences occurs quickly because their status as good or bad is immediately obvious. Marginal sentences, on the other hand, do not fall clearly into one class or the other; hence more time is required to make decisions about them. Severe ungrammaticality did not slow down parsing because subjects were not trying to analyze or comprehend the sentence in any normal manner. As soon as a violation was detected, the decision could be made, perhaps without even considering the remainder of the string. If this interpretation is correct, then Nagata's\ia{Nagata, Hiroshi} study really did not get at the on-line nature of grammaticality as it affects normal parsing. Since subjects knew they would be timed on judgments, they went into ``quick judging mode,'' which might be quite different from normal parsing for comprehension. Nagata's purpose would be better served by not eliciting judgments at all, but rather by assessing processing speed while subjects are engaged in reading for comprehension, as proposed below.

One possible course of action at this stage would be to look for more evidence of drastic differences between judgments and actual use, by employing corpus-based analysis,\is{corpus data} for instance (but see \citet[55]{Hirst1981}, for problems with real-world texts, such as the fact that one can generate bad sentences in writing without realizing it). But if such differences are found, we will not be any closer to a general method for discovering the linguistic knowledge that underlies regular performance. So let us move on to how we \textit{would} like the judgment process to work, and see whether we can make it happen. In the abstract, it would be nice if the language processor could run as usual, but a homunculus could be allowed to inspect the process and then report back on what he has seen. He could then observe not only the fact that, say, the parser had failed to parse a sentence, but exactly where in the sentence this occurred and why. Unfortunately, there is little evidence to suggest that people can introspect\is{introspection} on the language mechanism in this
way. If that is not possible, then at least the homunculus should be allowed to inspect the state of the processor when it is finished, although, being a rather robust device, it might have managed to get through the sentence somehow and left little trace of a problem. This latter method, the interpretation of the ``trace of execution,'' is what we might hope to achieve through postpresentation testing. Speed will be of the essence, because much research in psycholinguistics has shown that our memory for the form of an utterance decays extremely quickly as compared to our memory for its content (see, e.g., \citet{Sachs1967} and many subsequent studies). Others have reasoned along similar lines:

\enlargethispage{\baselineskip}
There is very little evidence in the literature that people \textit{are} conscious of many of their own mental processes. Awareness seems to be restricted to the outcome or results of such processes, and if people do report on processes, this is\schdash{}\citet{NisbettEtAl1977} contend\schdash{}usually a logical reconstruction of how such a result might have come about (often in the form of a motivation) rather than a memory trace of the process itself  \citep[7]{LeveltEtAl1978}.

Thus, extreme caution in interpretation is called for. Nisbett \& Wilson warn that ``people sometimes make assertions about mental events to which they may have no access and these assertions may bear little resemblance to the actual events'' (p. 247). Thus, our hopes for the homunculus might be unattainable in principle. Any introspective\is{introspection} access we might have is insufficient to produce generally correct or reliable reports on how we reach decisions. People base their reports of thought processes on their theories about what is likely to have influenced them, and thus even when they are correct, this is not due to direct introspective awareness. Nisbett \& Wilson also make the interesting point that certain types of factor will  rarely occur to us as possible influences in a judgment, because their effects seem implausible. Among these factors are many manipulations that have been clearly shown to affect grammaticality judgments, such as serial order effects and contrast effects. Linguists beware: we might feel certain that we are not subject to such effects, but we are.

With the above caveats, let us go on to consider how a postpresentation meth\-od could conceivably be used in linguistic judgment. The obvious problem is going to be that before too long, the subject will be on to us, i.e., will realize that we are going to ask for judgments,\is{grammaticality judgments!unexpected} and so might revert to ``judging mode'' on any
% Judging Grammaticality  87
sentence after the first. (It is not difficult to imagine bogus tasks that would keep the subject in the dark until after the first sentence was presented.) This seems to require interspersing judgment trials at a low concentration among nonjudgment trials, or at the very least making the distractor task sufficiently engaging or realistic that the subjects do not have an opportunity to reflect on the purpose of the study. For instance, we might present sentences in the guise of a text that has been translated from a foreign language (say, a play or television show), and ask the subjects to point out places where the translation is bad English (or whatever language) while keeping track of the plot for a later recall test, which forces them to keep processing for content.\footnote{This idea arose from a suggestion by Bill Poser (personal communication).}
%\textsuperscript{27}
 The alternative is to try to deduce judgments from some nonintrusive measure,\is{nonintrusive measures of grammaticality}\is{grammaticality!nonintrusive measures} so that the subject is never aware that grammaticality is at issue. For instance, we can simply ask subjects to read a passage for content while taking some standard measure of reading speed\is{reading speed, as evidence of (un)grammaticality} and location (e.g., \isi{eye tracking} or \isi{self-paced reading}). It is reasonable to predict that when unexpected ungrammaticality is encountered, a delay in reading will result; we might even learn something about where in the course of processing the error was detected. (\citet{KutasEtAl1983} review some other on-line measures of this type.) We could also use event-related brain\is{brain, as source of grammaticality data} potential ERP measurements in this way, or look for people to balk or do a double take \citep{Newmeyer1983}. Of course, there are other variables that affect reading speed (and ERPs)\is{ERPs (Event-Related Potentials)} that will have to be factored out, the sensitivity of these measures to structural violations might not be terribly high, and the concentration of ungrammatical sentences should still be kept reasonably low. Any of these methods is probably best used as corroboration for data derived by other means.

I conclude this section by briefly describing the work of \citet{BialystokEtAl1985} (see also \citealt{RyanEtAl1984} and \citealt{Bialystok1986}), 
who have proposed a high-level model of language skill that encompasses many of the metalinguistic (and linguistic) tasks\is{metalinguistic tasks!skills involved in} we have discussed so far and attempts to unify their cognitive requirements in terms of the demands they place on two fundamental dimensions of language proficiency. The first, which they dub \textit{analyzed knowledge},\is{analyzed knowledge, as component of language skill} consists of explicit, structured knowledge about language that is accessible to conscious reasoning and can be manipulated in solving problems, e.g., explaining errors in bad sentences. While regular language production and comprehension
% \textsubscript{88 } Chapter Three
make relatively little use of analyzed knowledge, metalinguistic tasks like judging grammaticality require considerably more of such knowledge. This type of knowledge would include the \isi{prescriptive rules} alluded to above. Bialystok \& Ryan's second dimension is labeled \textit{cognitive control}.\is{cognitive control, as component of language skill} This is a skill required for focusing one's attention on particular information and attending simultaneously to multiple facets of a stimulus, e.g., its form, meaning, and context, and coordinating them within time constraints imposed by the task. Behaviors that have become automatic, such as attending to the meaning of a conversational utterance, require very little cognitive control, whereas moving one's focus away from meaning and onto form (decentering, in Piagetian\ia{Piaget, Jean} terminology), as in making judgments, requires considerably more cognitive control. This might be a large part of what happens when we go into ``judging mode.'' Thus, on both counts metalinguistic tasks are more demanding than conversation. Also, since the two dimensions are theoretically orthogonal (although in practice there is a correlation across the tasks people actually perform), we might expect that people's proficiency can vary along them independently and each could be subject to improvement through training or experience.\is{metalinguistic performance (skills)!improvement through training and experience} (For instance, as will be argued in \sectref{sec:4.4}, schooling and literacy might contribute to such improvement;\footnote{\citet{Bialystok1986} claims that schooling contributes most to development of the control dimension, whereas literacy increases analyzed linguistic knowledge.
}
%\textsuperscript{28}
 experience as a newspaper editor will increase one's ability to detect errors in written text; linguistic training might also be expected to improve one's abilities, but the matter is not nearly so simple\schdash{}see \sectref{sec:4.4.1}.) Also, particular tasks and particular stimuli within those tasks will vary in the demands they make on the two dimensions. For example, more salient errors require less cognitive control\is{cognitive control, as component of language skill} in order to be detected; more analyzed knowledge\is{analyzed knowledge, as component of language skill} is needed in the absence of a supporting context. Bialystok \& Ryan propose that grammaticality tasks can be ordered as follows, by increasing amount of analyzed knowledge required: grammaticality judgment, locating ungrammaticality, correcting ungrammaticality, explaining ungrammaticality, and stating a rule that is violated. The sort of evidence they use to demonstrate such claims is that \isi{second-language learners} differ significantly on their ability to perform the various tasks even when precisely the same grammatical phenomena are involved in all of them. If it is true that (at least) these two types of skills are involved in making judgments, we must examine the nature of the interface between metalinguistic behaviors and competence grammar.

% Judging Grammaticality  89

\section{The Interpretation of Judgments with Respect to Competence}\label{sec:3.5}

Many researchers have been convinced that there must be some differences between linguistic knowledge as revealed by judgments and that which underlies language use (e.g., \citet{CardenEtAl1981}).\is{grammaticality judgments!versus language use} The question for those who accept this assumption then becomes whether and to what extent judgment data can be used as evidence of competence.\is{grammaticality judgments!relation to competence} If they are not pure reflections of that competence (as argued eloquently by \citet[vol. 3: 5\textendash{}7]{Levelt1974}), if they have no special epistemological status vis--vis the grammar \citep{LeveltEtAl1978}, then how can the impurities be removed? In this section I look at the views of a number of researchers who have made the further argument, in various ways, that judgments are somehow special or abnormal, unique among language behaviors and built on a different competence base. I examine whether there is any evidence to support these claims, and whether they lead to any substantive proposals on how to make the best use of judgment data.

Bever\ia{Bever, Thomas G.} has been the most widely cited proponent of the view that many of the properties that linguists attribute to the grammar, i.e., to a process-independent competence, really do not belong there at all. They are in actuality properties of the \textit{particular} behavioral process through which the data were obtained, be it intuitive judgments, production, or some other kind of data:

\begin{quote}
Even if our linguistic intuitions are consistent, there is no reason to believe that they are \textit{direct} behavioral reflections of linguistic knowledge. The behavior of having linguistic intuitions may introduce its own properties. ... A linguistic grammar may have formal properties that reflect the study of selected subparts of speech behavior (for example, having intuitions about sentences), but which are not reflected in \textit{any} other kind of speech behavior. \citep[343\textendash{}344]{Bever1970a}
\end{quote}

\noindent
A major tenet of the current investigation is that, if such properties in fact are not part of linguistic competence, they might be part of more general nonlinguistic cognitive systems, in which case we could expect them to be apparent in other tasks besides evaluating sentences (this proposal was discussed in \sectref{sec:1.4}). Bever\ia{Bever, Thomas G.} goes on to make a distinction between properties of the linguistic processing mechanism\is{parsing!versus grammar} and properties of the introspective\is{introspection} process, neither of which should be reflected in the grammar, but both of which have played a role in grammar
%\originalpage{90} %  Chapter Three
construction in actual practice. Thus, we might be constructing \textit{two} different ``contaminated''  grammars.

\begin{quote}
The relationship between linguistic grammar based on intuition and that based on the description of other kinds of explicit language performance may not just be ``abstract'' ... but may be \textit{nonexistent} in some cases.\is{grammar!of intuition versus use} First, apparently ``linguistic'' intuitions about the relative acceptability of sequences may themselves be functions of one of the systems of speech behavior (for instance, perception) rather than of the system of structurally relevant intuitions. Second, the behavior of producing linguistically relevant intuitions may introduce some properties which are \textit{sui generis}\is{metalinguistic performance (skills)!artifacts of} and which appear in \textit{no} other kind of language behavior. \citep[345]{Bever1970a}
\end{quote}

\noindent
Thus, one of our general goals in this area should be to sort out which properties are attributable to which performance procedures, so that we can treat data from each type of task most appropriately, rather than trying to identify \textit{general} performance artifacts that might actually not apply across the board.

Let us now consider some specific properties that judgment data have been claimed to exhibit, in contrast with usage data. Several suggestions come from work by the Gleitmans and their colleagues:

\begin{quote}
We take judgments about language to be manifestations of an executive, or metalinguistic, skill that has psychological interest in its own right.\is{metalinguistic performance (skills)!versus primary linguistic performance} The metalinguistic capacity shows more individual and population differences than the linguistic capacity; it appears relatively late in development; and it is sensitive to linguistic levels. Specifically, the more ``surface'' aspects of language are more difficult to access for the sake of giving judgments than are the ``deeper'' or more meaningful aspects. This distinction in performance may reflect  differences in decay rates for less and more highly processed linguistic material. \citep[99]{HirshPasekEtAl1978}.

[Generative] grammars reflect the judgmental (``metalinguistic'') as\-pects of language knowledge more directly than they do knowledge of language itself. ... Whatever differences exist between these organizations may derive from the fact that the ``executive'' thinking capacities have properties of their own, which enter into the form of the grammars they construct. ... Differences in tacit knowledge are small in comparison to differences in the ability to make such knowledge explicit  \citep[121]{GleitmanEtAl1979}.\footnote{See \citet{VanKleeck1982} for a critique of this paper.}

\end{quote}
%\textsuperscript{29}

\noindent
Let us consider the suggested properties one at a time.\footnote{I defer discussion of the developmental argument until I have reviewed some of the relevant experiments below.}
%\textsuperscript{30}


First, it is claimed that metalinguistic abilities exhibit more individual differences than other linguistic abilities,\is{metalinguistic performance (skills)!extent of individual differences in} and that different people's grammars are more similar than our externalizations about them would suggest.\footnote{See  \citet{VanKleeck1982} for a review of studies that find strong correlations between primary linguistic abilities and metalinguistic abilities, and some methodological problems that they share with \citeauthor{GleitmanEtAl1979}'s work.}
%\textsuperscript{31}
 (For instance, Gleitman \& Gleitman\ia{Gleitman, Henry}\ia{Gleitman, Lila R.} argue that there is more variation in learning to read than in learning to talk, because the former requires additional metalinguistic skills that the latter does not.) I suspect that this impression arises because metalinguistic tasks are typically used to probe areas of linguistic knowledge that rarely occur in regular speech and that therefore likely do exhibit more interspeaker variation than the most common sentence structures, but it remains to be shown whether differing judgments result from grammars or from differences in the intuitional mechanism\schdash{}this must be determined empirically.

Another claim of Gleitman \& Gleitman\ia{Gleitman, Henry}\ia{Gleitman, Lila R.} is that low-level properties are harder to make intuitions about than high-level (i.e., meaning-related) properties and that intuitions about the latter show less variability. They paraphrase this by saying that ``fully processed'' forms of language are easier to judge than only partially processed ones, such as syntactic forms without their semantics. Now, it is certainly true that meaning is the property of language we deal with and use on a conscious level most frequently, and so one might expect that meaning-related tasks such as paraphrase or ambiguity judgment would come more naturally than structural well-formedness judgments. But the actual evidence provided by \citeauthor{HirshPasekEtAl1978} 
is not general enough to warrant their conclusion, since it all comes from the phonological domain. They show that children's word detection abilities are superior to their syllable identification, which in turn is better than their segment differentiation. Since the authors consider the word level to be ``deeper'' (more basic) than the syllable and segment levels, they draw the more general conclusion, but in fact meaning versus form is not the relevant contrast.



The actual generalization is that  the difficulty of such detection or monitoring tasks depends on the size or level of unit one is searching for relative to the level of the units among which one is searching, with no target level being easier than another in any absolute sense \citep{McNeillEtAl1973}. At another point, Gleitman \& Gleitman argue that giving judgments is more difficult than participating in conversation, by virtue of requiring self-consciousness, i.e., taking a prior cognitive process as the object of a higher process.  \citet{FillmoreEtAl1979b}
agree that metalinguistic performance requires more skills than regular language use. But while the ``objectification of cognitive processing'' view has a certain analytic appeal, and might even seem intuitively right, we have no solid evidence that anything of the kind is actually going on; our impressions might be epiphenomenal. In all these cases, then, the claims are unsupported. This is not to say that they are false, but one can envisage much more direct experimental ways of verifying or falsifying them, which would be a worthwhile undertaking.

These authors also go on to make specific suggestions as to where we should look for the source of properties that are special to metalinguistic behavior. They propose viewing it as an instance of the class of metacognitive behaviors.\is{metalinguistic performance (skills)!as metacognition}
\begin{quote}
 
There need be no formal resemblance between metacognition and the cognitive processes it sometimes guides and organizes. Rather, one might expect to find resemblances among the higher-order processes themselves.\is{metacognitive behaviors, commonalities among} On this view, judgments (and therefore grammars) have little direct relevance to speech and comprehension, but rather to reasoning. Whatever resemblance exists between language processing strategies and grammars may derive from the fact that the human builds his grammar out of his observation of regularities in his speech and comprehension. Whatever differences exist between these organizations may derive from the fact that the reflective capacities have   properties of their own, which enter into the form of the grammars they construct  \citep[128]{HirshPasekEtAl1978}
\end{quote} 

   
\noindent   
(Bialystok\ia{Bialystok, Ellen} \& Ryan derive the same prediction from their model.) For the hypothesis that there are resemblances among higher-order processes to be of any use, we must find some other metacognitive tasks to compare grammaticality judgments to. Unfortunately, very few have been studied. In the domain of memory, recollection (i.e., knowing that you remember something) could be considered metamemory  (see \citealt{RyanEtAl1984} for a literature review),  and as a
% Judging Grammaticality  93
special case, the tip-of-the-tongue phenomenon involves metamemory in the (temporary) absence of memory itself \citep{GleitmanEtAl1972}. The authors propose that intentional learning, or learning how to learn through deliberate memorization strategies or other means, constitutes another type of metacognitive activity. But no one has yet illustrated how comparisons with such processes can shed any light on the nature of linguistic intuitions. (See \citealt{VanKleeck1982}, \citealt{Goldman1982}, and \citealt{Gombert1992} for more on this topic.)

The arguments that we have seen so far for the secondary nature of grammatical intuitions\is{intuition!secondary nature of} have been based on comparisons between fully developed linguistic versus metalinguistic abilities in adults. Another major set of arguments about the nature of linguistic intuition comes from developmental work on the acquisition of metalinguistic abilities.\is{metalinguistic performance (skills)!development of} This is a huge area in its own right, to which I cannot hope to do justice here; see \citet{Chaudron1983}, \citet{RyanEtAl1984}, \citet{Birdsong1989}, and \citet{Gombert1992} for literature reviews. Instead, I will concentrate mainly on one research project that makes a particularly provocative suggestion about how metalinguistic abilities develop\schdash{}the work of \citet{Hakes1980}. His thesis, written within a Piagetian\ia{Piaget, Jean} framework, starts from the observation that judgments and explanations of syntactic well-formedness emerge developmentally at about the same time as the ability to explain judgments of space and number and to develop intentional memorization strategies, which is considerably later than corresponding production and comprehension abilities (which seem to appear in the preoperational period). He suggests that these are all forms of concrete operational\is{grammaticality judgments!as concrete operations (Piaget)} thought, since they all involve controlled processes, whereas sentence comprehension and casual memory are automatic processes. (See  \citealt{VanKleeck1982} and \citealt{RyanEtAl1984} for more on this approach.)

To test this idea, Hakes\ia{Hakes, David T.} presented children\is{children, eliciting judgments from} aged 4 to 8 with various metalinguistic tasks (comprehension, judgments of synonymy and acceptability, phonemic segmentation), as well as other cognitive tasks (e.g., conservation tests).\is{children, eliciting judgments from} His finding was not only that performance on these tasks shows improvement strongly correlated with age, but also that the nature of the improvement was similar, in the direction of objectifying or ``decentering'' (using controlled processing to stand back from and evaluate a situation), a process that Piaget\ia{Piaget, Jean} attributed to the period of middle childhood. Hakes\ia{Hakes, David T.} thus argues that a \textit{general} metalinguistic ability underlies successful performance in all these tasks. (Another task that fits this trend, according to \citet{RyanEtAl1984}, is reading\schdash{}performance on grammaticality
judgments correlates widely with reading ability.) For instance, Hakes\ia{Hakes, David T.} found that synonymy judgments were based on superficial form in the youngest children, but on meaning and form together at a later stage. Acceptability for the youngest children\is{children, eliciting judgments from} was determined by whether they understood the sentence.\footnote{There is obviously a great deal of variation in the ages at which particular abilities emerge. Certainly it would be incorrect to say that children under the age of 4 cannot assess grammaticality. \citet{GleitmanEtAl1972} showed that 2\textonehalf-year-olds can detect and correct certain grammatical errors in simple imperatives (but see \citet{Gombert1992} for a critique), although it was rare for them to correct just syntax, and that 6-to-8-year-olds could correctly explain a wide variety of grammatical errors.}


%\textsuperscript{32}
 At a later stage acceptability was based on the truth or desirability of the situation described in the sentence, its moral correctness, etc.\footnote{Such factors are not entirely abandoned in adulthood; see several studies reported in \chapref{sec:4}, notably \citet{Hill1961} and \citet{VetterEtAl1979}.}
%\textsuperscript{33}
 Still older children generally based acceptability judgments on linguistic form,\is{children, eliciting judgments from} although even some 8-year-olds labeled sentences unacceptable due to falseness of  content.\is{grammaticality judgments!developmental changes in} (\citet{RyanEtAl1984} take their own data to show that until about the age of 8, children's reactions to ungrammatical sentences are just unsystematic.) Another general trend was  that fewer bad sentences were judged good as the child grew older, which Hakes\ia{Hakes, David T.} interprets as indicating that more grammatical rules were being learned.\footnote{However, the procedure that Hakes\ia{Hakes, David T.} used could have been subject to a \isi{response bias}, since he asked the children to explain their reasons for rejection\is{explaining one's judgments} but not for acceptance (see \sectref{sec:6.3.2}).}
(He additionally provides an interesting discussion of the methodological problems in getting linguistic judgments from young children,\is{children, eliciting judgments from} which must be much harder again than getting them from adults.)

The claim that controlled processing is a crucial developmental factor is supported by the fact that children seem to have the necessary skills to perform concrete operations earlier than the operations actually  emerge.  Children  have been known to display metalinguistic behavior  spontaneously  in  conversation, and can make use of deliberate memorization strategies when so instructed, but until a certain stage do not seem to be able to choose the appropriate routines to fit a situation. To follow up a point deferred earlier, \citeauthor{HirshPasekEtAl1978} use data such as that obtained by Hakes\ia{Hakes, David T.} to argue that metalinguistic ability emerges late in development, and therefore must differ in important ways from language use. They also report that children have been known to judge bad sentences as grammatical,\is{children, eliciting judgments from} even though they have demonstrably mastered the relevant grammatical form in their own speech. But if Hakes\ia{Hakes, David T.} is on the right track in pointing
to objectification as the crucial skill that must be added to comprehension processing to allow judgment, then it does not necessarily follow that this objectification distorts the data that it provides, and we certainly cannot conclude on this basis that there is a \textit{separate} knowledge base underlying intuitions.

It must be noted that there is a great deal of disagreement concerning how early children can provide useful grammaticality judgments.\is{children, eliciting judgments from} \citet{McDanielEtAl1990} find that if one undertakes a training session first, children as young as 4 can make grammaticality judgments. They compared child judgments of sentences with their responses to the same sentences in an act-out task, and found that while there were few actual conflicts between the two measures, act-out responses failed to reveal the full range of possible readings of the sentence. For example, a child would act out a sentence in only one particular way and yet judge it grammatical for other meanings as well, for instance by allowing multiple possible referents for a pronoun. The reader may consult their work for methodological details.

Besides adult native speakers and children, data from a third group, adult \isi{second-language learners}, have been used in exploring the relationship between judgments and competence. \citet{Coppieters1987} attempted an experimental demonstration that syntactic intuitions do not improve as speaking ability in the second language increases. Specifically, he wanted to show that native and near-native speakers could have identical linguistic performance but radically different intuitions,\is{grammar!of intuition versus use} and then take this to support the indirectness of the link between language use and linguistic intuitions as ``a particularly striking illustration of the relatively independent status of two linguistic planes: language use and language form.'' He began his procedure by finding nonnative speakers of \isi{French} who could not be clearly distinguished from native speakers in interviews that he conducted and who were considered to have native proficiency by their colleagues or friends; many of these subjects were linguists. He also interviewed a group of native speakers in the same way. He then proceeded with informal interview elicitations of judgments on a number of sentence types (requiring judgments of subtleties of \isi{French} syntax such as adjective placement, choice of past tenses, etc., usually with two alternatives) that were rated as ``correct or good,'' ``uncertain or problematic,'' or ``incorrect or bad.'' Subjects were also asked to explain meaning differences between pairs of minimally distinct sentences. The average ratings of the native speakers were used as a norm against which to evaluate individuals from both groups. Native speakers differed from their norm on 5\textendash{}16\% of the sentences,
while near-natives disagreed on 23\textendash{}49\% of the judgments. Qualitatively, Coppieters\ia{Coppieters, Ren\'{e}} reports that near-natives had strikingly different feelings about how sentences differed and the contexts where they could be used, and showed much variation in their explanations, whereas the native speakers where quite homogeneous in their answers. But do these results  really show intuitional  differences in the face of identical performance? The fact is the two groups were never compared on their \textit{use} of the crucial constructions tested in the judgment task (e.g., by injecting the constructions surreptitiously in casual conversation),  so it is equally possible (and seemingly more likely) that the same differences would be found in performance as well.\footnote{Coppieters\ia{Coppieters, Ren\'{e}} himself admits this as a likely possibility.}
%\textsuperscript{35}
 There might be no differential effect of judgment whatsoever in this case. (A related experiment by \citet{SnowEtAl1977} is reported in conjunction with a discussion of their other experiments in \sectref{sec:4.4.3}.) Thus, it seems that in ordinary language use the more subtle points of grammar can be avoided or go unnoticed, a state of affairs that many computer programs employing natural language exploit in order to engage in reasonable dialogues with humans using only rudimentary  grammars.

Other authors have followed the same approach to argue that the degree of individual differences in metalinguistic ability\is{metalinguistic performance (skills)!development of} implies that such ability relies on skills beyond those required for language use. In trying to pin down these skills, \citet{MasnyEtAl1985} looked  at advanced students of English  as a Second Language for statistical relationships between second language (L2) grammaticality judgments and corrections\is{ungrammatical sentence, correction of} and selected cognitive and linguistic variables: L2 proficiency,\is{second-language learners} first language (L1) reading competence, reasoning (nonverbal intelligence), field (in)dependence\is{field (in)dependence} (a measure of cognitive style; see \sectref{sec:4.3.1}), and others. Using multiple regression analysis, they found that the best predictor of L2 metalinguistic ability was L2 proficiency. In apparent contradiction of Gleitman \& Gleitman's\ia{Gleitman, Henry}\ia{Gleitman, Lila R.} claim, they found no correlation between metalinguistic ability and reasoning ability or cognitive style. \citet{Birdsong1989} tries to make the same case on the basis of \citegen{ScribnerEtAl1981} study of \isi{Vai} speakers in \isi{Liberia}. Among these people, literacy and/or schooling seems to be a prerequisite for the ability to \textit{explain} grammaticality judgments, which leads to large individual differences, but not for the ability to \textit{make} them, which shows relatively little variation. I will discuss their findings further in \sectref{sec:4.4.2}. Regardless of the questionable effectiveness of this particular line of argumentation,
it is hard to dispute the general conclusion that metalinguistic behavior is not a direct reflection of linguistic competence. In fact, much of the remainder of this book will lend credence to that argument. Birdsong\ia{Birdsong, David} concludes, ``Inasmuch as metalinguistic performance reflects idiosyncratic skill parameters, which vary across tasks and across individuals, it cannot, in any rough-and-ready manner, reflect the grammar or linguistic competence presumably possessed by all speakers of a language'' (p. 61); ``the inference of grammatical competence from linguistic and metalinguistic performance requires convergent evidence from a variety of validated sources, as well as a profound understanding of the variables that determine the form of the evidence'' (p. 44).

\section{Conclusion}\label{sec:3.6}

I began this chapter by considering various ways to elicit subjects' impressions regarding the grammaticality of sentences, considering the pros and cons of several methods. These should be kept in mind when examining the studies that are reviewed in Chapters \ref{sec:4} and \ref{sec:5}. Along the way, I considered how judgments fit into the larger class of metalinguistic behaviors, a theme to which I return in \chapref{sec:6} in attempting to model the judgment process. I looked in detail at one heavily explored property of judgments, their scalability, and the methodological problems this property raises. I examined the much broader question of what really occurs during the judgment process and how we might manipulate that process to keep it more in line with language use. I then reviewed several kinds of evidence for just how different judgments seem to be from competence, the major determination being that the evidence is inconclusive. Following from the approach outlined thus far, the next two chapters attempt in part to show how the general features of judgments described in this chapter are the result of lower-level cognitive effects.
