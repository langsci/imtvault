\chapter{Subject-Related Factors in Grammaticality Judgments}\label{sec:4}

\epigraph{\itshape Speakers perversely  disagree among themselves about what is grammatical in their language; some of the principal  sources of suffering and dispute within generative  linguistics have been over ways of coming to terms with such realities.\\[-2\baselineskip]}{\citep{Fillmore1979}}

\section{Introduction}\label{sec:4.1}

Despite their common genetic makeup, humans exhibit individual differences in virtually every aspect of behavior. It should not be surprising to find that linguistic intuitions are no exception. The central question I address in this chapter is the extent to which differences in linguistic intuitions are systematically attributable to differences either in properties of the organism or in its life experiences. In some cases, there are some features on which people differ that contribute rather transparently to their grammaticality judgments, and to linguistic behavior generally, whereas in other cases the connection is surprising and still poorly understood. Throughout the chapter a major theme is consistency,\is{consistency (between and within subjects)} or the extent to which the same subject gives a sentence the same rating on different occasions, or different subjects give a sentence the same rating. In the former case, inconsistencies are liable to be the result of factors having nothing to do with subjects' linguistic representations, e.g., whether they are fresh or fatigued, uncooperative, attentive or distracted, etc. \citep{BradacEtAl1980}. In the latter case, interspeaker differences might be attributable to differences in deeper properties of the minds of the people in question, in their grammars or in some other module that affects grammaticality judgments. The implications of these various possibilities are taken up in \chapref{sec:6}.

% 98


I begin this chapter with three important studies that have looked quantitatively at individual differences in grammaticality judgments (\sectref{sec:4.2}). The amount of variation found there motivates a search for systematic factors that might account for some of it. In \sectref{sec:4.3}, I examine organismic factors in this regard. Two such factors have been studied extensively: field dependence, a concept from the personality literature (\sectref{sec:4.3.1}), and handedness,\is{handedness, effect on language} which seems to be an important indicator of linguistic structures in the brain (\sectref{sec:4.3.2}). Some other factors, such as age, sex, and general cognitive endowment, seem to be obvious candidates but have been given little or no attention in the literature, so I consider them only briefly in \sectref{sec:4.3.3}. \sectref{sec:4.4} turns to features of the person's experience. The most controversial and most discussed of these is linguistic training. Innumerable critics of the linguistic enterprise have made their case on the basis of linguists being their own speaker-consultants. I look at several studies that have tried to establish whether linguists are suitable sources of grammaticality judgment data (\sectref{sec:4.4.1}). A less-studied but very intriguing source of variation in judgment abilities might be the amount of literacy training and general schooling\is{education, effect on language skills} a person has received. Investigations with remote cultures are the major source of evidence on this topic (\sectref{sec:4.4.2}). I conclude the section with a discussion of a grab bag of miscellaneous experiential factors, such as the amount of exposure one has had to a language (for instance, as a near-native speaker versus a native speaker) and accumulated world knowledge (\sectref{sec:4.4.3}). \sectref{sec:4.5} concludes the chapter by summarizing the findings and using them to motivate the investigations of \chapref{sec:5}.

\section{Individual Differences: Three Representative Studies}\label{sec:4.2}

\epigraph{\itshape Note that, as usual, a given reader is not really expected to agree with a given writer's placement of asterisks.\\[-2\baselineskip]}{\citep{Neubauer1976}}

\noindent The term most often used for individual differences in language judgments is idiolectal\is{dialects (idiolects)} variation, although \citet{Heringer1970} is on the mark when he says, ``This term is chosen for want of a better one and is not intended to imply that groups of people do not show the same patterns of variation in acceptability judgments, at least with individual sentence types. To call this dialect variation, however, seems not to be appropriate since there do not appear to be geographical or
%\originalpage{100} %  Chapter Four
sociological correlates to this variation'' (p. 287). \citet{Carden1973} uses the term \textit{randomly distributed dialects} in order to emphasize his belief that these should have the same theoretical status as geographically and socially defined dialects.\is{dialects (idiolects)} The first set of experiments I review concerns the single most widely studied instance of individual differences: the interpretation of quantifier-negative\is{quantifier-negative sentences} combinations, as exemplified in (\ref{ex:4:1}a), which might be paraphrased as (\ref{ex:4:1}b) or (\ref{ex:4:1}c):

\ea \label{ex:4:1}
\ea All the boys didn't leave. 
\ex Not all the boys left.
\ex None of the boys left.
\z
\z

\noindent
(Note that the spoken intonation pattern of (\ref{ex:4:1}a) likely would be very different for the two readings, although no one appears to have studied this issue systematically; see \sectref{sec:5.2.6}.) In an early study, \citet{Carden1970b} claims that speakers fall into three categories with regard to their interpretation of sentences like (\ref{ex:4:1}a): some can only get the meaning of (\ref{ex:4:1}b), some can only get the meaning of (\ref{ex:4:1}c), and some find the sentence ambiguous.\footnote{While these three categories represent the major dialects,\is{dialects (idiolects)} Carden\ia{Carden, Guy} admits that he found many subdialects. He also reports anecdotally that some speakers who originally could only get the (\ref{ex:4:1}b) reading started accepting both readings after repeated exposure\is{repetition, effect on grammaticality judgments} to sentences that forced the (\ref{ex:4:1}c) reading. A similar finding is reported by \citet{Neubauer1976} regarding individual differences in uses of the word \textit{pretend}: subjects moved toward a more liberal dialect when pushed.}
%\textsuperscript{1}
 He, along with many other researchers of the day (e.g., \citealt{ElliotEtAl1969}), argued that there are important theoretical insights to be gained by examining the full range of dialects,\is{dialects (idiolects)} rather than accounting for one and ignoring the others. Carden\ia{Carden, Guy} was particularly interested in finding implicational relations among dialect differences. In a follow-up study that attempted to elicit judgments on these sentences, \citet{Heringer1970} was faced with ``the problem of asking naive informants to judge the acceptability of ambiguous sentences on specific readings,''\is{ambiguous sentence!judging grammaticality of} a problem we have also encountered with regard to adjunct \textit{wh}-movement (see \sectref{sec:2.3.2}). When a sentence is uncontroversially good under one reading, one's initial impression is that it sounds fine. This undoubtedly biases ratings of other readings. Therefore, Heringer\ia{Heringer, James T.} constructed a situational context in which only one of the readings was possible, either in the form of a scenario of which the target sentence formed the conclusion, or a prose description of the kind of situation where the sentence might occur. These two types of context are illustrated in \REF{ex:4:2} and \REF{ex:4:3}, respectively:

 \ea \label{ex:4:2}
 All the students didn't pass the test, did they? [Professor Unrat believes he finally has succeeded in making up a midterm which every single one of
his students would fail miserably. However, he doesn't know the test results yet, since his poor overworked teaching assistant Stanley has just this moment finished grading them. Unrat asks Stanley this question in order to confirm his belief.]
\z

\ea\label{ex:4:3}
      All the treasure seekers didn't find the chest of gold. [Used in the situation where none of them found it.] (p. 294)    
\z

\noindent
Heringer's instructions stated that acceptability should only be considered  in the context of the material in square brackets. Unfortunately, acceptability was not defined for the subjects (a complaint made by \citet{Carden1970a} as well) and they did not receive any training on practice sentences.

At any rate, several interesting results are found in this study. One is the ability of context to prompt subjects to see potential acceptability where there otherwise is none,\is{context effects!making a sentence acceptable} a result that I discuss in \sectref{sec:5.3.1}. Another interesting finding is that, while there were very few speakers who accepted only the (\ref{ex:4:1}c) reading, there were many more who accepted neither reading. In Carden's\ia{Carden, Guy} study  this  pattern does not show up at all. In general, the results of the two studies differ quite substantially, leading Heringer\ia{Heringer, James T.} to speculate on why this should be so. First, the mode of presentation was different in the two studies. Carden\ia{Carden, Guy} presented sentences orally in interviews, whereas Heringer\ia{Heringer, James T.} used a written questionnaire.\is{questionnaire!versus interview}\is{speech versus writing, effect on grammaticality judgments} A second possibility, which I discuss more fully in \sectref{sec:6.3}, is that interviews of the sort Carden\ia{Carden, Guy} conducted are more susceptible to \isi{experimenter bias}. A third potential problem, mentioned by \citet{Carden1970a}, is that Heringer\ia{Heringer, James T.} used only one stimulus sentence for each reading in most of the constructions, so it is worth asking whether peculiarities of the sentences chosen could be responsible for some of the results. Nonetheless, Heringer's\ia{Heringer, James T.} data apparently refute \citegen{Newmeyer1983} claim that people differ only on their bias of interpretation on these \isi{quantifier-negative sentences} (i.e., which reading they think of first),but that everyone \textit{can} get both readings. Even when context forced a particular reading, many of Heringer's\ia{Heringer, James T.} subjects did not accept that reading, so subjects seem to differ on something deeper than processing preferences.\footnote{Newmeyer\ia{Newmeyer, Frederick J.} cites a paper by \citet{Baltin1977} to support his claim that everyone can get both readings, but in fact Baltin found nothing of the kind. He found the three dialects\is{dialects (idiolects)} that Carden\ia{Carden, Guy} had reported, using question answering rather than judgments as his primary source. (He also found a significant correlation between subjects' preferences on quantifier-negative constructions\is{quantifier-negative sentences} and their interpretation of prenominal modifiers as restrictive versus nonrestrictive.) However, \citet{Labov1975}
does report results along the lines described by Newmeyer,\ia{Newmeyer, Frederick J.} where nonlinguistic tasks were used to force one reading or the other, with almost complete success across subjects.}
%\textsuperscript{2}
 (See \citet{Labov1972a} for a survey of work on quantifier-negative dialects.)\is{dialects (idiolects)}


%\originalpage{102} %  Chapter Four

\citet{Stokes1974} performed  a  follow-up  to  Carden's  work,  starting  from the criticism that the interview\is{questionnaire!versus interview} technique is subject to experimenter bias. Stokes used a questionnaire, and determined which readings of \isi{quantifier-negative sentences} were grammatical by using judgments of synonymy rath\-er than of grammaticality, with the hope that the former would be less likely to tap prescriptive feelings. He too found ``extraordinary variation'' in the results, a much wider range of response patterns  than  the  three  dialects\is{dialects (idiolects)}  Carden\ia{Carden, Guy}  discussed.  Among his 48 subjects, there were 17 different patterns of responses to the stimulus sentences.

\enlargethispage{\baselineskip}
The second study I review is by \citet{SnowEtAl1977}, who performed three experiments to substantiate their claim about the secondary nature of syntactic intuitions\is{intuition!secondary nature of} and language data, which corresponds in many respects to the position presented in \sectref{sec:3.5}.\footnote{They argue that syntactic intuitions are developmentally secondary, as evidenced by studies such as \citet{Hakes1980}; pragmatically secondary, because their function is not communicative; and methodologically secondary, as demonstrated by their experiments reported in this chapter.}
%\textsuperscript{3}
 (The second and third experiments will be discussed in subsequent sections.) Their first experiment used as subjects native speakers of \isi{Dutch} who were studying linguistics but had not taken any courses in syntactic theory. We might expect them to show somewhat more sophistication than truly naive subjects. Their materials all involved issues of word order,\is{word order violations, effect on grammaticality judgments} so multiple arrangements of each set of words were constructed. There were two conditions, absolute judgments and rank-ordering. In the former condition, each of 24 sentences appeared on a separate page and the instructions\is{instructions to subjects!examples of} stated, ``Will you please read the sentence, then indicate whether you think it is a good Dutch sentence (by `good' we mean `acceptable in spoken language' and not `grammatically correct'). Write + if the sentence is good, \textminus~if it isn't good,
and ? if it is in-between or if you don't know.'' In the rank-ordering condition, the sentences were divided across four pages of six sentences each, and the instructions read in part, ``Will you please rank these sentences within the groups of six by rewriting them at the bottom of the page with those sentences which are good Dutch, or the best Dutch, at the top and those sentences which are the worst Dutch at the bottom. Sentences which are equally good or bad can be written on one line.'' Immediately we see a potential confound, since the rank-ordering subjects were not told to rank by spoken acceptability as opposed to grammatical correctness (of course, we do not know whether this terminology was understood in a uniform way by the first group either). Snow \& Meijer decided to make this a within-subjects
factor, administering the two kinds of tests a week apart to the same subjects, and found no effects of the order of test types, but the instructions could still confound any differences between the two types of task.

The results were first analyzed for between- and within-subjects consistency\is{consistency (between and within subjects)} in the two conditions. The between-subjects consensus on rankings\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)} was significant for all sets of sentences, as measured by Kendall's coefficient of concordance, but was not extremely high (ranging from .466 to .670 on a potential range of 0\textendash{}1). The most agreed-upon sentence, which the authors claim is perfectly normal, showed disagreement by 3 of 25 subjects, and all other sentences showed at least 7 disagreements as compared to their mean rank. The absolute ratings similarly showed no total unanimity, although there was one sentence type on which 24 of the 25 subjects agreed.\footnote{In the absolute condition, subjects could indicate that they were unsure, which the 25th subject did here; therefore, this constitutes only a weak disagreement.}
%\textsuperscript{4}
 On the other hand, five sentence types showed disagreements, i.e., at least one subject rated them bad both times while another rated them good both times, and two of these represented almost equal splits of the subjects. Within-subject consistency was 70.8\% for the absolute judgments, where two identical ratings for two structurally identical variants counted as consistent, even if they were both marked ``?''. The majority of inconsistencies involved one ``?'' rating rather than strictly opposed judgments. One subject out of the 25 was consistent on all 10 sentence types, while the two least consistent subjects were consistent on only 5. Snow \& Meijer correctly advise caution in interpreting this as a good level of consistency, however, because many of their
subjects showed strong response biases\is{response bias} toward a ``+'' response or toward a ``\textminus''
response. In the extreme case, someone labeling all sentences as good would be 100\% consistent. (Since we are not told the normative status of the stimulus sentences, we do not know what an unbiased distribution of responses might look like.) The authors devised a complex scoring system to assess within-subject consistency between rank-orderings and absolute ratings, which ranged on average from perfect consistency to about three out-of-sequence rankings in a set of six sentences. There was no significant correlation between this cross-conditions consistency score for a given subject and his or her consistency within absolute judgments. Even when judgments are pooled across all the subjects, the absolute ratings do not agree entirely with the rank-orderings. There was at least one reversal
of position for each set of six sentences. On the basis of these results, it is hard to
argue with the authors that ``testing even a relatively large group of subjects, all of
%\originalpage{104} %  Chapter Four
them relatively intelligent and language-conscious, does not assure internally consistent judgments concerning the relative acceptability of sentences'' (p. 172). 

The third of our example studies is perhaps the most widely cited study on individual differences in grammaticality judgments, that of \citet{Ross1979}. Ross\ia{Ross, John Robert} asked 30 subjects to rate the grammaticality of 12 sentences on a scale from 1 to 4, and elicited their perceptions about these judgments.\footnote{There were actually 13 sentences in his questionnaire, one of which was geared to the semantics of \textit{barely} and \textit{scarcely} and did not yield results comparable to those for the other sentences.}
%\textsuperscript{5}
 Specifically, the subjects were asked to state how certain they were of each judgment (pretty sure, middling, or pretty unsure), and how they thought that judgment compared to the judgments of most speakers (liberal, conservative, or middle-of-the-road). Since I am particularly concerned with the design of instructions\is{instructions to subjects!examples of} for such experiments, I present Ross's\ia{Ross, John Robert} description of the rating scale as it appeared on his questionnaire:

\begin{enumerate}
\item  The sentence sounds perfect. You would use it without hesitation.
\item   The sentence is less than perfect\schdash{}something in it just doesn't feel comfortable. Maybe lots of people could say it, but you
 never feel quite comfortable with it.
\item  Worse than 2, but not completely impossible. Maybe somebody might use the sentence, but certainly not you. The sentence is almost beyond hope.
\item  The sentence is absolutely out. Impossible to understand, nobody would say it. Un-English. (p. 161)
\end{enumerate}

\noindent
Note the reference to comprehensibility in item 4. In general, the instructions are quite explicit regarding differentiation of the levels, but give little indication of what counts as a criterion for grammaticality.

By his own admission, Ross intended this experiment only as a pilot study. As he acknowledges, his presentation of the results shows no knowledge of statistical  whatsoever. Instead, he invents his own numerical measures to assess variability, covariation, etc., and gives numerous large tables of raw data.\footnote{Another potential problem of interpretation is that 8 of his 30 subjects were nonnative speakers of English.}
%\textsuperscript{6}
 While these shortcomings make the paper tedious to read and the results hard to interpret, at least his raw data could be used to do proper statistical analyses. I will report only the more obvious results, with the understanding that none of them should be taken as firm. First, I present the sentences employed in the questionnaire, with their mean ratings on the 1\textendash{}4 scale. (Ross did not calculate mean
ratings, but computed an overall score by weighting the numbers of subjects who gave each of the four responses, in effect treating the scale as centered about a zero point. Since his formula is arbitrary and unjustified, I use the standard computation instead. Thus, in his ordered list, the third and fourth sentences are transposed.)\footnote{The general problem of how to come up with a single rating for a sentence on the basis of multiple judgments on a graded scale has arisen in many other studies as well. Standard deviations should probably be reported.}\bigskip
%\textsuperscript{7}


%$\left.\begin{array}{lS}
%\widearray{The doctor is sure that there will be no problems.} & 1.07 \\
%\widearray{Under no circumstances would I accept that offer.} & 1.23 \\
%\end{array}\right] \text{\itshape Core}$
%
%$\left.\begin{array}{lS}
%\widearray{We don't believe the claim that Jimson ever had any money.} & 1.63 \\
%\widearray{That is a frequently talked about proposal.} & 1.70 \\
%\widearray{The fact he wasn't in the store shouldn't be forgotten.} & 1.80 \\
%\widearray{The idea he wasn't in the store is preposterous.} & 2.03 \\
%\widearray{I urge that anything he touch be burned.} & 2.03 \\
%\widearray{Nobody is here who I get along with who I want to talk to.} & 2.60 \\
%\widearray{All the further we got was to Sudbury.} & 2.77 \\
%\widearray{Nobody who I get along with is here who I want to talk to.} & 2.83 \\
%\end{array}\right] \text{\itshape Bog}$
%
%$\left.\begin{array}{lS}
%\widearray{Such formulas should be writable down.} & 3.07 \\
%\widearray{What will the grandfather clock stand between the bed and?} & 3.30\\
%\end{array}\right] \text{\itshape Fringe}$


\resizebox{\textwidth}{!}{\noindent\begin{tabular}{ll@{ }S@{\hspace{1em}}l}

\multirow{2}{*}{}& The doctor is sure that there will be no problems. &          1.07 & \rdelim]{2}{2cm}[\textit{Core}]  \\
& Under no circumstances would I accept that offer. &           1.23 &        \\
\multirow{8}{*}{} & We don't believe the claim that Jimson ever had any money. &  1.63 & \rdelim]{8}{2cm}[\textit{Bog}]   \\
& That is a frequently talked about proposal. &                 1.70 &         \\
& The fact he wasn't in the store shouldn't be forgotten.  &    1.80 &         \\
& The idea he wasn't in the store is preposterous. &            2.03 &         \\
& I urge that anything he touch be burned. &                    2.03 &         \\
& Nobody is here who I get along with who I want to talk to.  & 2.60 &         \\
& All the further we got was to Sudbury. &                      2.77 &         \\
& Nobody who I get along with is here who I want to talk to.  & 2.83 &         \\
\multirow{2}{*}{} & Such formulas should be writable down. &                      3.07 &  \rdelim]{2}{2cm}[\textit{Fringe}] \\
& What will the grandfather clock stand between the bed and?  & 3.30 &         \\
\end{tabular}}\bigskip


The designations \textit{core, bog}, and \textit{fringe} are used by Ross to refer to the range of good, marginal, and bad sentences, respectively. These divisions are made by eyeballing, not by any formulaic procedure.\footnote{Ross\ia{Ross, John Robert} does not commit as to exactly where the divisions should be drawn for the sentences he studied, so I have placed the boundaries arbitrarily within his suggested ranges.}
%\textsuperscript{8}
 He found three variables that correlated with this distinction in the order core-fringe-bog (i.e., variables that changed monotonically such that good sentences were at one extreme and mar\-ginal ones at the other): increasing variability among subjects,\is{interspeaker variation!greater for marginal sentences} decreasing confidence in their judgments,\is{confidence of subjects in their judgments} and increasing self-rating as conservative. The finding about variability jibes with Barsalou's results reported in \sectref{sec:3.3.1} for conceptual typicality judgments. The pattern of confidence agrees with the findings of \citet[52, fig. 9]{QuirkEtAl1966}, based on the number of subjects choosing the ``marginal or dubious'' rating on their 3-point scale; they dub this phenomenon the ``query bulge.'' At an intuitive level, these results are not surprising, but the only explanation Ross{Ross, John Robert} adduces, namely that ``the mind sags in the middle,'' does not add much insight.\footnote{This quotation is attributed to George Miller.\ia{Miller, George A.}}
%\textsuperscript{9}
 While an additional goal of the questionnaire was to assess whether people know where their judgments stand in relation to those of the rest
% 106  \textsuperscript{Chapter} \textsuperscript{Four}
of the population, the data were not interpretable due to apparent misunderstandings of the liberality scale.\footnote{Ross\ia{Ross, John Robert} suggests that a better way to get at this information is simply to ask subjects directly what ratings they think most other people would give.}
%\textsuperscript{10}
 Interestingly, Ross found no cases of strongly polarized judgments, i.e., sentences that some people rated 1 and the rest rated 4, with no one in between. In all cases, the two most frequent ratings were adjacent on the scale, that is, there were no bimodal distributions. He suggests that this might be an artifact of the particular sentences chosen; if one deliberately chose known dialectal peculiarities,\is{dialects (idiolects)} bimodality might still appear. However, as a measure of just how different people are,\is{interspeaker variation!degree of} no 2 of the 30 subjects agreed on their ratings for more than 7 of the 12 sentences on the 4-point scale. In fact, Ross\ia{Ross, John Robert} did not try all combinations of sentences, so it might even require fewer than 7 sentences to differentiate all of the subjects. (By way of comparison, \citet{QuirkEtAl1966} (see \sectref{sec:3.2})
 reported that with 76 subjects judging  50 sentences on a 3-point scale, only two sentences were unanimously rejected, and only two accepted.) These sorts of striking results lead Ross\ia{Ross, John Robert} to ask, ``Where's English?'' (his proposed answer is discussed below). One experiential factor that contributed to variability among Ross's\ia{Ross, John Robert} subjects was that some of his subjects were linguists while others were not. He found systematic differences between the two groups, which I discuss in \sectref{sec:4.4.1}.

Most linguists acknowledge that no two people will agree on even binary judgments of a large collection of sentences, let alone ordinal rankings.\footnote{Newmeyer\ia{Newmeyer, Frederick J.} appears to be the exception, claiming that ``there is good reason to think that idiosyncratic (i.e., nongeographical and nonsocial) dialects\is{dialects (idiolects)} are nothing but artifacts of the now-abandoned view that grammaticality is dependent on context'' \citep[57]{Newmeyer1983}. However, he only cites one case as evidence for this very broad generalization, that of quantifier-negative sentences, and the facts there are still controversial, as discussed above.}
%\textsuperscript{11}
 What, if anything, does this tell us about people's grammars? Ross's\ia{Ross, John Robert} data prompted him to take a very pessimistic view. He proposed in dismay that a language might be defined only as an \textit{n}-dimensional space for some \textit{n} in the thousands, where each point is a sentence and each dimension an implicationally ordered axis such that acceptance of a sentence on a given axis implies acceptance of all sentences closer to the origin along that axis. Then each person's idiolect\is{dialects (idiolects)} is an \textit{n}-dimensional vector specifying that person's acceptance threshold for each axis. Most linguists find this an appallingly messy and uninteresting view of language.\footnote{This view seems to have originated in Ross's\ia{Ross, John Robert} earlier proposal of the concept of a \isi{squish} (see \sectref{sec:3.3.1}). A squish is a two-dimensional matrix where the cells represent judgments. On one axis are forms graded by some property, e.g., increasing volitionality. On the other are environments where the forms might occur, graded by the extent to which they demand that property. One can make claims about how orderly the implicational pattern in the matrix should be across speakers. Unfortunately, after some research in this paradigm it started to look like both hierarchies could vary across speakers, or even that this pattern could be violated by a single speaker through the syntactic analog of statistical interactions: the effect of one dimension on grammaticality depended on the level of the other.
} 
I discuss some alternative positions in \chapref{sec:6}. The reader is referred to \citet{FillmoreEtAl1979a} for a very wide-ranging discussion of individual differences in language behavior. Let us now consider the potential sources of these differences.\is{interspeaker variation!sources of}

\section{Organismic Factors}\label{sec:4.3}
\subsection{Field Dependence} \label{sec:4.3.1}

Field dependence/independence\is{field (in)dependence} is a concept that originated in the personality assessment literature in psychology. It is meant to diagnose how people perceive and think, specifically the extent to which they perform \textit{cognitive differentiation}, the process of distinguishing stimuli along different dimensions. \citet{Nagata1989b} investigated whether field (in)dependence would influence grammaticality judgments. A field dependent (FD) person fuses aspects of the world and experiences it globally, whereas a field independent (FI) person is analytical, differentiating information and experiences into components. These are seen as more or less permanent traits of individuals \citep{WeinerEtAl1977}. There are a number of diagnostic tests for field (in)dependence that have been shown by psychologists to be very well correlated. One of these is the tilting-room-tilting-chair test, which involves an apparatus consisting of a small box-shaped room containing a chair, mounted on mechanical devices such that each can be rotated independently in two dimensions. Subjects seated on the chair cannot see outside the room, and are required to judge whether they are seated upright or on a tilt relative to the outside world. FD individuals tend to believe that they are on a tilt if the orientation of the room makes it appear so, i.e., they have trouble distinguishing visual cues from kinesthetic/vestibular ones, whereas FI individuals have less trouble. A simpler test to perform, used by Nagata to divide up his subjects, is the embedded figures test. In this test subjects must rapidly pick out simple geometric figures embedded in larger, more complex ones. FDs have more difficulty with this than FIs. We might expect that these differences in cognitive style could show linguistic side effects. FI individuals show an impersonal orientation and have well-developed cognitive restructuring skills, while FD individuals show more interpersonal competencies. For
example, they recall social words better than FIs and use them more often in free association tasks. Thus, we could anticipate that FDs would use strategies\is{grammaticality judgments!strategies for} involving the enrichment of stimulus sentences with context when judging them, while FIs would be more prone to employ structural differentiation. (The nature of these strategies is described in more detail in Sections \ref{sec:5.2.4} and \ref{sec:5.2.5},
in conjunction with discussion of Nagata's other experiments.) However, as reported in \sectref{sec:3.5}, \citet{MasnyEtAl1985} found field dependence had no discernible effect on L2\is{second-language learners} judgment ability. They also review numerous other studies attempting to relate it to language ability, the results of which were mixed. An additional facet of this distinction is that FDs are more prone to changing their opinions under external influence, since they pay greater heed to others, so we should look for differential reactions to knowledge of other people's judgments.

Nagata's\ia{Nagata, Hiroshi} experiment involved repeated presentation of sentences.\is{repetition, effect on grammaticality judgments} After rating the grammaticality of a number of sentences (on a scale of 1 to 7), subjects were exposed to each sentence 10 times for 3 seconds per repetition, during which time they were told to think of the grammaticality of the sentence. After the tenth repetition, they rated each sentence a second time. Then they were told that their judgments differed from those of the average college student (which Nagata considered negative reinforcement), and were asked to think about the grammaticality of each sentence again and rate it a third time. Other experiments have shown that for a general population, the repetition treatment makes judgments significantly more stringent (i.e., sentences are rated less grammatical after repetition); see \sectref{sec:5.2.3} for details. In Nagata's experiments, the judgments of FIs did become more stringent after repetition, but those of FDs showed no significant change.\is{field (in)dependence} After the negative reinforcement, both groups' ratings became more lenient (the FDs' nonsignificantly more so). Nagata concludes that FDs approach the task of judging grammaticality differently from FIs, since they resist the usual repetition effect. One might have expected their judgments to become more lenient with repetition, as they considered more potential contexts for the sentences, but this trend was not found either. Apparently it is much harder to make sentences get better than to make them get worse (again, see \chapref{sec:5} for more on this point). The idea that FDs would be more responsive to negative reinforcement was not substantiated. In summary, we can say that field dependence is a factor that can induce variability among subjects on grammaticality judgment tasks, just as it does in other domains. For instance, \citet{LefeverEtAl1976} found a moderately positive correlation between field independence and the ability 
%% Subject-Related Factors  109
to detect several kinds of ambiguity in sentences.\is{metalinguistic tasks!ambiguity detection} They propose that the common features among the various tasks involve restructuring a stimulus pattern, overcoming the influence of context, and shifting mental set.

\subsection{Handedness}\label{sec:4.3.2}

There is already considerable evidence that handedness\is{handedness, effect on language} correlates with differences in language processing, for instance in the review by \citet{HardyckEtAl1979}. Recently, some preliminary studies have been done on possible correlations between handedness and grammaticality judgment strategies. Work by \citet{BeverEtAl1987} was the first to suggest that such differences might be found. The purpose of their study was to show that the assumption that the basic mechanisms of sentence processing are the same for everyone is a severe oversimplification. Specifically, they demonstrated how right-handers from families with at least one closely related left-hander (``mixed background right-handers'') show different processing patterns from right-handers with no familial history of left-handedness (``pure background right-handers''). The former group tend to process in a more structure-independent way than the latter, that is, they attend less to syntactic and semantic structures of language and more to conceptual and lexico-pragmatic features. These differences were found despite the matching of subject groups on several other variables, including age, sex, native language (English), and verbal SAT score.\footnote{These studies do not use left-handed subjects because they are harder to find and to match on these dimensions.}
%\textsuperscript{13}
 In one study the authors used the classic tone location\is{tone location task}\is{metalinguistic tasks!tone location} paradigm, wherein a subject hears a tone while listening to a sentence and must subsequently identify at which point in the sentence it occurred. They demonstrated that mixed-background subjects did not show a superiority effect for clause boundary location of the tone, that is, they did \textit{not} locate the tone more accurately when it occurred exactly between two clauses, while pure-background subjects did. A second experiment showed that mixed-background subjects respond more quickly in a word recognition task (supposedly because they ``make more use of the reference of individual words in their processing'') and are insensitive to the position of the target word in the clause, unlike their structure-dependent counterparts, who showed serial order effects. Pure-background righthanders also performed more slowly on word-by-word reading tasks. These results support the authors' general conclusion that pure-background people depend
more on aspects of sentence \textit{structure}, mixed-backgrounders more on lexical and conceptual knowledge.\is{general knowledge, effect on grammaticality judgments}\footnote{It is important to note that there were no instances in which the two groups showed reverse effects; either they showed the same trend to different degrees, or else one group showed no effect.}
%\textsuperscript{14}
 There is some neurological evidence to corroborate this proposal. Familial sinistrality seems to be correlated with a less localized, more widespread language module in the brain, which \citet{BeverEtAl1987} suggest leads to more contact between language and other kinds of knowledge. Whatever the eventual explanations of these differences, it would not be surprising to find that the different processing strategies are also reflected in different judgment strategies between such groups. In fact, the two types of strategies proposed by Bever et al. are not so dissimilar from those proposed by Nagata\ia{Nagata, Hiroshi} for field dependents versus independents. A replication of his procedure with mixed-background subjects could prove fruitful. See \citet{BeverEtAl1989} and \citet{Bever1992} for more studies of language differences correlated with familial handedness.

\citet{Cowart1989} conducted the first study to look explicitly for the effects of familial sinistrality differences in a judgment task. The experiment involved a written questionnaire using a 4-point scale, the extremes of which were designated ``OK'' and ``odd'' (since the details of the procedure are not reported, we cannot assess the extent to which subjects were instructed on how to evaluate sentences in terms of these labels). The sentences in question followed the paradigm in \REF{ex:4:4}:


\ea\label{ex:4:4}
\ea What did the scientist criticize Max's proof of? 
\ex What did the scientist criticize a proof of?
\ex What did the scientist criticize the proof of?
\ex Why did the scientist criticize Max's proof of the theorem?
\z
\z
   
\noindent
Example (\ref{ex:4:4}a) has traditionally been called a violation of the \isi{Specified Subject Condition}, while (\ref{ex:4:4}b) and (\ref{ex:4:4}c) are considered good in some theories and claimed to violate only the lesser constraint of Subjacency\is{Subjacency violation} by others; (\ref{ex:4:4}d) is an uncontroversial control sentence. It was hypothesized that since the violations  in (4a\textendash{}c) are all of a purely structural nature, mixed-background subjects would be less sensitive to them and therefore rate them more grammatical than their pure-background counterparts. This prediction was borne out. For cases like (4a\textendash{}c) the ratings of the latter subjects were significantly lower than those of the former, but
% Subject-Related Factors  111
no difference was found for grammatical control sentences 
like (\ref{ex:4:4}d).\footnote{Another result was that cases like (\ref{ex:4:4}b) and (\ref{ex:4:4}c) were rated significantly worse than (\ref{ex:4:4}d), suggesting that they might indeed constitute Subjacency violations (but see the caveats in \sectref{sec:2.3}).}
%\textsuperscript{15}
 If this insensitivity to structural violations is found throughout the syntax, it could constitute an explanation for a significant amount of intersubject variation in judgments. (See \sectref{sec:7.2} for the possibility that Subjacency\is{Subjacency violation} is really a parsing constraint and not a grammatical constraint.)

\subsection{Other Organismic Factors}\label{sec:4.3.3}

In this subsection I suggest some other organismic factors that might induce systematic differences in grammaticality judgments. First, let us consider two of the most obvious factors: age and sex.\is{age, effect on grammaticality judgments}\is{sex, effect on grammaticality judgments} \citet{Ross1979} suggests that, in general, more contact with a language leads to higher grammaticality ratings for it, an idea inspired by the fact (reported in \sectref{sec:4.4.1}) that linguists rated sentences higher on average than nonlinguists in his questionnaire experiment, which obviously has other possible explanations. If Ross\ia{Ross, John Robert} is right, we would expect increasing age to be correlated with increasing tolerance in judgments. His own data do not bear this out, but they were not even based on accurate ages, just his guesses, so there is certainly room for more investigation here. \citegen{Greenbaum1977c} review of the literature cites age as a factor that correlates with difference in acceptability judgments, but he does not provide details. As for sex differences,\is{sex, effect on grammaticality judgments} \citet{Chaudron1983} states in his wide-ranging survey of metalinguistic research that sex has rarely been experimentally analyzed and ``does not appear to be a relevant factor,'' but if the former is true then how do we know the latter for certain? R. \citet{Lakoff1977}, while dealing with what she calls acceptability differences between men's and women's speech, makes it clear that such differences are conditioned by situational and social factors (i.e., \textit{when} a particular kind of utterance is appropriate), and not differences in grammars. For instance, she has found no instances of syntactic rules that only one sex possesses, at least not in English. However, \citet{Bever1992}
\textit{has} found preliminary evidence for sex differences\is{sex, effect on grammaticality judgments} in methods of language processing, which presumably could be reflected in judgments as well. He argues that there is a spectrum of ``abduction strategies'' or possible ways one can develop abstract representations (linguistic or otherwise), whose extremes are hypothesis refinement (using new data to refine an existing hypothesis) and hypothesis competition (using it to choose between alternative hypotheses). In one of Bever's\ia{Bever, Thomas G.} experiments, the tasks involved producing, comprehending, and judging sentences in an artificial language. Under learning conditions that are supposed to support hypothesis competition, men do significantly better than women on the judgment task, while the opposite is true with hypothesis refinement. While there is as yet no conclusive basis for deciding whether these differences are biologically or socially caused, it is intriguing that similar sex differences surface in spatial learning tasks, which leads Bever\ia{Bever, Thomas G.} to suggest that there might be a general abduction mechanism implicated in both activities. However, it does not necessarily follow that any sex differences we might find in judgments\is{sex, effect on grammaticality judgments} of one's native language would be attributable to the same mechanism. One can imagine that differences in conversational strategy could lead, say, to women judging fewer sentences ungrammatical than men because they are more supportive in conversation. (See \citet[ch. 13]{Wardhaugh1988} for a brief review of the literature on sex differences in language and their social correlates.) The attribution of sex differences to biological versus psychological causes is notoriously tricky, and is the subject of much ongoing research; see \citet{Halpern1992} for an excellent review, and \citet{PhilipsEtAl1987} on the possible relevance of sex differences in the brain to language. It appears that no one has yet looked for sex differences in the processing of individual sentences, as opposed to overall skill level on verbal tasks.

The second direction we might explore while looking for organismic factors involves general cognitive differences that we suspect are implicated in the task of judging grammaticality. For instance, we will see evidence in \sectref{sec:5.3.5} that part of this process involves imagining\is{imagining situations, and grammaticality judgments} a situation to which a sentence could be applied. Therefore, the ability to imagine situations, i.e., some form of creativity,\is{creativity, effect on grammaticality judgments} is a dimension on which people undoubtedly vary and one that could correlate with judgments. Various perceptual strategies\is{perceptual strategies, and grammaticality judgments} have been implicated in language processing, and hence also (somewhat controversially) in the generation of judgments. Subjects might differ in their ability to use these strategies \citep{Botha1973}. Similarly, a number of extragrammatical factors often implicated in acceptability (as distinct from grammaticality) might be subject to inherent differences, such as working memory capacity, ability to reason by analogy, and so on. At a more general level, intelligence and cognitive development might be pertinent, at least up to a certain ceiling. \citet{Hakes1980} (reported in \sectref{sec:3.5}) attempts to show that qualitative changes in children's ability to make grammaticality judgments\is{children, eliciting judgments from} are correlated with Piagetian\ia{Piaget, Jean} stages of development, and \citet{MasnyEtAl1985}, mentioned in \sectref{sec:3.5}, looked for correlations between IQ and judgments
% Subject-Related Factors  113
of second-language learners, although they failed to find any significant patterns. Finally, \citet{BialystokEtAl1985} propose a model of (meta)linguistic ability as factored into two major dimensions, analyzed knowledge\is{analyzed knowledge, as component of language skill} and cognitive control\is{cognitive control, as component of language skill} (see \sectref{sec:3.4}). Each is the product of underlying cognitive abilities on which people might differ. Analyzed knowledge is related to intelligence and logical deduction abilities, while cognitive control depends on reflective and impulsive tendencies, as well as field dependence, discussed in \sectref{sec:4.3.1}. The authors do not provide specific evidence for these interdependencies, however. In general, demographic variables are hard to study rigorously in this context, because their effects seem to be small relative to stimulus factors and can often interact, which demands large samples of subjects in order to detect the effects reliably.

\section{Experiential Factors}\label{sec:4.4}

\subsection{Linguistic Training} \label{sec:4.4.1}

\epigraph{\textit{It is well-known among linguists that intuitions about the acceptability of utterances tend to be vague and inconsistent, depending on what you had for breakfast}\footnotemark\textit{and which judgment  would best suit your own pet theory.}\footnotemark\\[-2\baselineskip]}{\citep{Dahl1979}}

\footnotetext[16]{Since it is not clear whether what one had for breakfast should be treated as a between- or a within-subjects factor, it will not be discussed further.}
\footnotetext{Jim McCawley (personal communication)\ia{McCawley, James D.} points out that the relevant factor is actually which judgment linguists \textit{believe} would suit their theories,\is{linguist!effect of own theory on judgments} because their beliefs about the consequences of their own theories may turn out to be erroneous.}

\epigraph{\textit{Only the most sophisticated  speakers can supply the exquisite judgments  required for  writing a grammar.}\\[-2\baselineskip]}{\citep{GleitmanEtAl1970}}



\noindent One of the most frequent criticisms of generative grammar has been the fact that, to paraphrase Labov,\ia{Labov, William} the theories that linguists develop are based on data that they themselves create, a situation that constitutes an intolerable conflict of interest and seriously undermines the external validity of the findings. In this subsection I enumerate some of the specific reasons why it has been suggested that linguists' intuitions differ from those of naive native speakers\is{linguist/nonlinguist differences} and thus should not be used as linguistic data. I then turn to experimental attempts to establish whether such differences actually exist, of which there have been surprisingly few. It must be kept in mind throughout that finding differences in the way linguists
and nonlinguists judge sentences does not inherently count as a strike against using data from the former group. We must examine each difference to see what the potential benefits and drawbacks are for linguistic investigation.

The following passage from \citet[968]{BradacEtAl1980} is typical of the views expressed by many outside the generative enterprise: ``as a result of their special training, linguists may tend to judge strings differently from nonlinguists. Training in linguistics may produce beliefs or attitudes which are not shared by those who have not received such training. This suggests that the knowledge produced by linguists may become increasingly artifactual; it may fail increasingly to model natural language.''\is{naive versus expert judgments} While the authors' premise of differing beliefs is almost certainly true, it does not follow that linguists' judgments are artifactual in the sense that they are influenced by factors that are not relevant to the grammars of naive speakers. A priori it is equally possible that their training allows them to factor out various irrelevant factors that \textit{do} influence naive judgments, but actually reflect cognitive factors \textit{other than} the grammar that is the object of study \citep{Levelt1974}. However, there are legitimate reasons to suggest that this ability of linguists might have come at the price of a loss of objectivity. \citet{Labov1972a} argues that linguists have become removed from everyday language experience. \citet{Greenbaum1976a,Greenbaum1977c} believes that linguists are bound to be unreliable subjects, for at least three reasons. First, after long exposure to closely related sentences their judgments tend to become blurred.\is{linguist!loss of intuitions by} A famous quotation from \citet[178]{Fraser1971}, exemplifies the point: ``I think this issue is fairly clear. It will be resolved by speakers whose intuitions about the sentences in question are sharper than mine, which have been blunted by frequent worrying about these cases.'' Even Chomsky\ia{Chomsky, Noam} himself has experienced this phenomenon: ``I had worried so much over whether \textit{very} could occur with \textit{surprised}, that I no longer had a firm opinion about it'' \citep[172]{Chomsky1962}. Haj Ross\ia{Ross, John Robert} coined the term \textit{scanted out}\is{scanted out@\textit{scanted out}} in the early 1970s to describe this state.\footnote{The term apparently originates from Ross's\ia{Ross, John Robert} feeling that just trying to produce any judgments on sentences containing the word \textit{scant} was sufficient to induce a loss of intuitions in short order.} 
Second, linguists are liable to be unconsciously prejudiced by their own theoretical positions,\is{linguist!effect of own theory on judgments} tending to judge in accordance with the predictions of their particular version of grammar.\footnote{Elan Dresher (personal communication)\ia{Dresher, B. Elan} suggests that the reputed argumentativeness of linguists and the existence of multiple competing theories would guard against such bias. However, in the first place, Wayne Cowart (personal communication)\ia{Cowart, Wayne} points out that it is almost impossible to get 
an article published if all one has to offer is disagreement with some other linguist's judgments. Furthermore, even if one has a theory to go with new judgments, this will only help the field if one's theory is of interest to the linguist in question. If the source of bias is an uncontroversial assumption within GB,\is{Government-Binding} say, but that assumption is disputed by proponents of \isi{Lexical-Functional Grammar}, the bias will be difficult to discover, because the two camps rarely interact.}
%\textsuperscript{19}
 \citet{Botha1973}, \citet{Derwing1973}, \citet{Sampson1975}
 and \citet{Ringen1979}, among many other
critics, also express this view. Additionally, \citet{Levelt1974} suggests that hypercritical linguists might be biased \textit{away from} the judgments predicted by the theory they are working on. \citet{CardenEtAl1981} speculate on the subconscious process by which this could arise in a particular case. Greenbaum's third source of linguists' unreliability is that they look for reasons behind their acceptance or rejection of a sentence, which takes away spontaneity and makes their judgment processes different from those of naive subjects,\is{naive versus expert judgments}\is{expert versus naive judgments} who presumably have neither the inclination nor the knowledge necessary to perform this analysis. On the issue of whether this is actually less desirable, see the discussion in \sectref{sec:5.2.7} on the
relative merits of spontaneous versus reasoned judgments. Nonetheless, I agree with Greenbaum that this constitutes an additional difference between the two groups. Let us now see whether any of the above hypotheses have been borne out empirically.

I begin with a summary of differences found by Ross\ia{Ross, John Robert} in the study mentioned in \sectref{sec:4.2}. The summary is brief because the study's methodological shortcomings make its results suspect at best. On average, his linguists were more unsure than his nonlinguists (i.e., they had less confidence in their ratings), perhaps because thinking about language makes you realize how little you know about it and shatters your confidence in your own judgments\schdash{}``Doing syntax rots the brain.''\footnote{Ross\ia{Ross, John Robert} attributes this adage to John Lawler\ia{Lawler, John} without providing a reference.}
%\textsuperscript{20}
 Nonlinguists rated themselves more conservative, were tougher graders (i.e., they rated sentences less grammatical overall), and made fewer distinctions between levels of grammaticality (i.e., they tended not to use the whole scale). We will find a counterexample to the relative stringency finding in another study.

The most widely cited work on linguist/nonlinguist differences is that of \citet{Spencer1973}. The paper is perhaps more important for the many issues it raises than for Spencer's experimental results. She starts from the position that:

\begin{quote}
it is possible that the behavior of producing linguistically relevant intuitions has developed into a specialized skill, no longer directly related to the language behavior of the speech community (Bever [\citeyear{Bever1970a}]).
The linguist views language in a highly specialized way, and perhaps is influenced by a perceptual set. The resulting description may not be an ideal representation of linguistic structure. It may be an artifactual system which reflects the accretion of conceptual organization by linguists. (p. 87)
\end{quote}

\noindent
Spencer's experiment used two groups of subjects: the naive subjects were students of introductory psychology, while the nonnaive subjects were graduate students who had taken at least one course in generative grammar.\is{naive versus expert judgments}\is{expert versus naive judgments}\footnote{Apparently the nonnaive subjects did not possess a uniform amount of linguistic background, however, since some were graduate students in linguistics, while others were psychology or speech students. The latter groups might have watered down the linguistic biases of the first group.}
%\textsuperscript{21}
 She states that \citegen{Chomsky1961} definition of grammaticality and examples were used as the basis for the instructions in her experiment, but all she actually tells us about these instructions is the following:  ``Each [subject] was read the same instructions\schdash{}he would
be asked to make a decision on each statement as to whether it was complete and well-formed or not. There were a series of guidelines and examples as to what the [experimenter] meant. ... After the instructions had been read, the [subject] was asked to tell the [experimenter] what he had understood his instructions to be, and any confusions or omissions were corrected'' (p. 91). Apparently Spencer (or her editors) did not consider it important to describe the details of these instructions, but they are crucial for interpreting the results. If they did not correspond to the concept of grammaticality that linguists use, then we have a confounding  variable.\footnote{\citet{Newmeyer1983} makes this criticism as well.}
The stimulus sentences were drawn from six linguistic articles, and had all been labeled unequivocally good or bad by the original  author. Unfortunately, none of the sentences are reported in the paper. \citet{Newmeyer1983} surmises, on the basis of the source articles, that many of them were pragmatically very odd and required an unusual context to sound acceptable. Spencer's design was intended to draw out two possible results that would undermine linguists' use of their own intuitions: intersubject variation by naive subjects on allegedly clear cases, and naive subject consensus that conflicted with a linguist's judgment. There was also a check for consistency:\is{consistency (between and within subjects)!quantifying} six randomly chosen sentences were resubmitted for judgment at the end of the experimental session, and subjects who contradicted themselves on three or more of these had all their results discarded.

The first result was that an average of 81.4\% of the 150 sentences were considered  clear cases, as defined by the degree of consensus  among  subjects. At
least 65\% in each group gave the same rating (either good or bad, there were no other available answers). That is, the division between accepters and rejecters had to be at least 15\% from an even split. But this is not a particularly strong consensus; 35\% of the subjects could still have disagreed. If a 75\% criterion had been set, the percentage of clear cases would have been lower. Spencer does not provide figures from which we can calculate it exactly. She acknowledges that her choice of cut-off is arbitrary. (For comparison, \citet{SnowEtAl1977} report 20\% of their sentences as unclear cases among naive native speakers. Their definition of unclear is that a sentence received approximately equal numbers of acceptances and rejections.) As for whether naive and nonnaive subjects differed in their responses,\is{naive versus expert judgments} it is impossible to be certain on the basis of Spencer's reported figures, for two reasons. First, while she shows that the proportion of sentences accepted by the two groups differs by 6\%, she reports no statistical test of significance for this difference. Second, this comparison would not reveal a situation where the groups differed on \textit{which} sentences were accepted, but total \textit{numbers} of acceptances happened to come out roughly the same. Spencer merely states that there were ``no noticeable differences in the distribution of exemplars found unacceptable, unclear, and acceptable.''\footnote{For Spencer, an unclear sentence is one on which the subjects did not show consensus by the measure defined above.}
%\textsuperscript{23}


As for comparing the subjects to the linguist authors, 73 of the 150 sentences showed disagreement, defined by the subjects' pooled rating being either unclear or opposite to that of the linguist. \tabref{tab:1} (from \citet{Spencer1973}) gives a breakdown of the results. Of the disagreements, 81\% were unanimous across the subject groups, and in the majority of the remaining cases it was the naive subjects\is{naive versus expert judgments} who disagreed with the linguists while the nonnaive subjects agreed, but again this difference is not analyzed for significance. We must keep in mind, however, that this 50\% disagreement rate is made up by comparing the pooled judgments of 65 subjects with that of an individual linguist, a point that many subsequent articles have emphasized. Thus, while we can certainly conclude that the published judgments  did not show a good correspondence with the population as a whole, we crucially cannot conclude that linguists \textit{as a group} have systematically different judgments from nonlinguists. A comparison with any single randomly chosen naive subject could well have shown just as much disagreement. Nevertheless, Spencer concludes that linguists should not trust their intuitions: ``It is reasonable to state that the judgments  of the linguists used are representative  of many linguists as a group,'' since there had not been any published rebuttals in the 4\textendash{}5 years since the original articles appeared. But there are many possible alternative explanations for that state of affairs. As for the direction of the disagreements, the table shows that on 42 sentences nonlinguists were more accepting, while on 17 they were more stringent and on 14 they were mixed. This pattern, though not overwhelming, contradicts Ross's\ia{Ross, John Robert} findings that linguists are more accepting on average.\footnote{If we expect that linguists should be more aware of their actual speech tendencies than untrained speakers, then this result also contradicts the general recommendation  of \citet{HindleEtAl1975} to trust ``OK'' judgments more than stars.}
 Thus, the only firm recommendation we can draw from this study is that a reasonable sample size be used in determining the representativeness of judgments; we cannot conclude that this sample should not consist of linguists.


%%please move \begin{table} just above \begin{tabular
\begin{table}
\caption{Comparison of Linguists' and Nonlinguists' Acceptability Judgments \citep{Spencer1973}}
\label{tab:1}
\resizebox{\textwidth}{!}{
\begin{tabular}{S[table-number-alignment = center]cccS}
 \lsptoprule
 & \multicolumn{4}{c}{Judgment (+ = acceptable; \textminus\xspace = unacceptable; \textpm\xspace = unclear case)} \\
 \cmidrule{2-5}
\multicolumn{1}{l}{Number of sentences} &  
\parbox{3cm}{\centering Linguist\\\centering (as published)} & 
% \multirow{3}{*}
\parbox{2cm}{~\\\centering Naive group} & 
% \multirow{3}{*}
\parbox{3cm}{~\\\centering Nonnaive group} &  
% \multirow{3}{*}
\parbox{2cm}{~\\\centering Total}
\\% \multicolumn{1}{c}{\multirow{3}u{*}{Total}}\\
 \midrule
\multicolumn{1}{l}{Consensual Agreement} \\
51  &  +  & +  & + &  \\
26 & \textminus\xspace & \textminus\xspace & \textminus\xspace & 77\\
\multicolumn{1}{l}{Consensual Disagreement}\\
17 & + & \textminus\xspace or \textpm & \textminus\xspace or \textpm & \\
42 & \textminus\xspace & + or \textpm & + or \textpm & 59\\
\multicolumn{1}{l}{Judgments Mixed} \\
3 & + & + & \textminus\xspace or \textpm & 3 \\
4 & + & \textminus\xspace or \textpm & + &\\
7& \textminus\xspace & + or \textpm &  \textminus\xspace & 11 \\
\lspbottomrule
\end{tabular}
}
\end{table}

%\todo{text of the commented line  needs to be a spanner over columns 2-5 and The Consensual Judgments entries need to be LEFT-justified, not right. I made some changes to the table. Is this OK?}
%\todo{definitely better, but would still like to make a couple of tweaks: can the first column of numbers be moved leftward to roughly the end of the word "Mixed", and can the rightmost column of numbers be centered under "Total"}
%\todo{Please move the column of numbers 51, 26, ...7 a bit further right, maybe right-aligned with the end of "Mixed"}

Despite the less-than-convincing nature of her findings, Spencer goes on to make the familiar point that linguists who use only their own intuitions as data are really no different from trained introspectionists, whose intuitions ended up being totally removed from the layman's experiences (see \sectref{sec:2.4} for a discussion of  of introspectionism in psychology). In addition to the possibility that linguists' theoretical perspectives influence their judgments, she suggests that working with many sentences revolving around a given issue might also contribute to context biases in their judgments. That is, \isi{satiation} first leads to a loss of symbol meaning, then illusory changes occur in the form and meaning of the sentences, constrained by the context (e.g., one's theory).\is{linguist!effect of own theory on judgments}\footnote{This notion of the effects of \isi{satiation} derives from experiments such as those of \citet{TaylorEtAl1963}. They used a tape loop of a short phrase or sentence repeated for 15 minutes. When the instructions suggested that the stimulus would change, subjects perceived illusory changes. Furthermore, the number of non-English forms they perceived among these changes was heavily increased when they were told to expect non-English forms. Thus, the context constrained illusory variation.
}
%\textsuperscript{25}
 Thus, the linguist can reperceive and reorganize a sentence after repeated consideration, taking into account the theoretical constructs that it bears on. Finally, Spencer addresses the question of whether \isi{linguist/nonlinguist differences} might not in fact be a good thing:

 \largerpage[-2]
 \begin{quote}
It might be claimed that any difference between linguists and naive speakers\is{naive versus expert judgments}\is{naive subjects (nonlinguists)} found in this experiment is due to the increased awareness and sophistication in language that linguists have developed through their study. Perhaps linguists are simply more sensitive to language and therefore are able to detect finer differentiations than naive speakers in intuitions concerning natural language, rather than creating differentiations which do not exist within the natural language. If linguists are dealing with artifacts, however, nonnaive speakers, who have studied modern linguistics, should perform in a manner similar to naive speakers. Thus, to anticipate this criticism, nonnaive speakers also participated in the experiment. (p. 90)
 \end{quote}

\noindent
Of course there is a certain Catch-22 quality to this last point. One could always counter that, however much linguistic training these nonnaive subjects had, it did not raise them to the same level of linguistic sophistication as practicing linguists,\is{naive versus expert judgments} and so the latter's judgments might still be valid. Conversely, if the nonnaive subjects behave more like linguists than like naive subjects, one could maintain that linguists' judgments were artifactual and that the nonnaive subjects had too much linguistic training, such that they were exhibiting the same biases as linguists. Thus, subjects with some knowledge of linguistics can never be used to decide this issue definitively. What is needed is truly naive subjects who nonetheless have been given a very good understanding of what is meant by grammaticality.\footnote{I am aware of only two paradigms that have systematically addressed the issue of training naive subjects. \citet{RyanEtAl1984} found that explicit training on how to perform a grammaticality judgment task did not improve the performance of their kindergarten-age subjects, while \citet{McDanielEtAl1990} found that training did help even their 4-year-old subjects.}
%\textsuperscript{26}
 (One might, however, question whether this is possible even in principle.)


At least three other studies have compared linguist and nonlinguist judgments directly.\footnote{The only other empirical basis we have for comparing linguists and nonlinguists would have to come from separate studies that use the same procedure but with different kinds of subjects. For example, a study by  \citet{ElliotEtAl1969} used mostly linguists, whereas \citegen{Greenbaum1973} replication, described in \sectref{sec:5.2.2}, used all nonlinguists and got different results, but Greenbaum tried to eliminate other procedural problems with the design of \citet{ElliotEtAl1969}, so the studies are no longer directly comparable. This is the only such instance I am aware of.
}
%\textsuperscript{27}
 One of these was an informal experiment conducted by \citet[93, fn. 4]{Greenbaum1988} that was similar to Spencer's and found similar results. Another, reported in a very brief article, is by \citet{Rose1973}. Rose also took his stimulus items from linguistic articles, asking subjects to classify them as acceptable or unacceptable (details of the method are not given). Half of the subjects were told to play the role of an editorial assistant working for a strict editor, while the other half had to play the role of a person attempting to help a foreign friend speak properly. Rose states that, overall, subjects agreed with the linguist authors 89\% of the time. I assume this is a percentage of the total individual judgments, rather than a pooled scheme like Spencer used. This number is not nearly as informative as Spencer's, since it could represent a variety of scenarios, such as each sentence showing strong agreement, or most showing uniform agreement and some showing uniform disagreement. A chi-square analysis showed that linguist judgments and subject judgments were significantly related, but we have no indication as to which direction the disagreements took. There was no difference between the two roles played by subjects.

\citegenp{SnowEtAl1977} second experiment repeated the procedures of the first, as reported in \sectref{sec:4.2}, but used eight linguists as subjects, allowing direct comparison with the results of their nonlinguist group. The linguists showed significantly greater within-subject consistency\is{consistency (between and within subjects)} than the nonlinguists in the first experiment: 94.3\% on the absolute judgments. In part this might be attributable to a bias towards ``\textminus'' responses, which exceeded that of nonlinguists. (The authors do not report sentence-by-sentence comparisons, so we cannot say with certainty how often linguists were more stringent than nonlinguists; there is no basis for comparison with Ross\ia{Ross, John Robert} or Spencer\ia{Spencer, Nancy J.} on this issue.) Linguists' consistency between absolute ratings and rank-orderings\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)} was also significantly higher, and they showed greater between-subjects agreement, with Kendall coefficients of between .581 and .844. As for whether the linguists' judgments differed from those of the nonlinguists, the mean rankings of sentences by the two groups
showed a high correlation (Spearman {$\rho$} = .89), as did the absolute ratings ({$\rho$} = .84). While this is a higher rate of agreement than Spencer found, we must consider that Snow \& Meijer use the mean ratings of a group of linguists, rather than a single linguist's judgments. Also, as they themselves point out, Spencer counted as disagreements any cases where nonlinguists showed disagreement among themselves; this was not taken account of in Snow \& Meijer's study. Thus, the two ratings are not directly comparable. The authors draw a number of methodological conclusions, including the interesting suggestion that while comparing absolute judgments with rank-orderings\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)} provides a useful check of judgmental consistency, the fact that a sentence is judged inconsistently might say more about the sentence than about the quality of the judges, for instance that it has some shifty properties. With regard to the implications of linguists' higher consistency of judgment, they suggest two alternative interpretations. Either linguists have learned to ignore minor irrelevant differences among sentences, such as their semantic plausibility, or they have learned to apply their theory to unclear cases. The extent to which each of these turns out to be right will obviously determine whether this improved consistency is a desirable property.

\largerpage[-1]
\citet{Valian1982} has explored in some detail the parallels between linguists' use of their own judgments and expert judgment\is{expert versus naive judgments} in other fields.\is{naive versus expert judgments} She argues that linguists giving judgments are in relevant respects just like experts judging wine, tea, or cheese,\is{grammaticality judgments!parallels to tasting} so to the extent that the latter have proven to be useful, in fact essential (e.g., in maintaining uniform taste of a product year after year), the former could also. It is instructive to enumerate these parallels. Tasters, like linguists, are fallible, but their errors are within acceptable limits, and they know their task well enough to be able to take systematic steps to reduce the likelihood of error. For example, they arrange their samples in a particular order, not tasting a heavy-bodied wine before a light-bodied one. Linguists are similarly aware that order of judgment can affect their intuitions. Tasters have a priori biases, e.g., by being Bordeaux lovers rather than burgundy lovers, which makes them differentially sensitive to certain tastes. Similarly, linguists clearly have a priori biases. Tasters also come at their task with prior information about the samples they are tasting, e.g., what region a wine is from. Linguists' theories similarly provide a classification of sentences that are judged. In both cases, this additional information can allow finer judgments to be made and can focus attention on particular aspects of a sample. Valian argues that to have a completely open mind about the material at hand is to lack any experience with it, which results in the inability to
%Chapter Four
make consistent or fine discriminations. In the case of wine, things may all taste the same. Some people excel at different kinds of judgments than others do. In general, while all kinds of judgments are in some sense subjective, this does not mean they cannot be reliable and valid, especially when we acknowledge that there are strategies we can adopt for making them so.

\subsection{Literacy and Education}\label{sec:4.4.2}

\citet[31\textendash{}44]{Birdsong1989}, \citet{BialystokEtAl1985}, and \citet{MasnyEtAl1985} provide extensive reviews of research examining the relationship between literacy, education, and metalinguistic skills, including grammaticality judgments, and comment on the debate over which one(s) might be prerequisite(s) for the other(s). \citet{Bialystok1986} suggests that schooling\is{education, effect on language skills} contributes to her dimension of linguistic control, implicated in the ability to objectify language for judging purposes, while literacy adds to one's analyzed knowledge.\is{analyzed knowledge, as component of language skill} (See \sectref{sec:6.2.1} for more discussion of this model.) I present here a few studies from this field.

The largest and most fascinating project on this topic was conducted by \citet{ScribnerEtAl1981}, who did several years of field work among the \isi{Vai} people of \isi{Liberia}. These people have invented their own syllabic writing system, which is taught to some children in the home. Formal schooling,\is{education, effect on language skills} for those who manage to get it, is conducted in English; some \isi{Vai} also know \isi{Arabic}. Scribner \& Cole were interested in teasing apart the effects of schooling and literacy,\is{literacy, effect on language skills} and so the fact that there were \isi{Vai} monoliterates\is{literate speakers} who had no formal schooling was crucial.\footnote{ I should point out that theirs was a huge anthropological and psychological study, of which the metalinguistic tasks reported here constituted a tiny part.}
%\textsuperscript{28}
 It was their hypothesis that writing contributes to the objectification of language, independent of any general cognitive advantages it might entail. (In fact, they found very little evidence that literacy in either \isi{Vai} or \isi{Arabic} produces advantages for problem solving or other cognitive tasks.) More specifically, they believed that deliberate written composition in one's native language increases one's understanding of its formal properties, an idea that dates back to Vygotsky.\ia{Vygotsky, Lev}
 
 Scribner\ia{Scribner, Sylvia} \& Cole\ia{Cole, Michael} used three kinds of metalinguistic task to test this theory. The first involved orally presenting paired sentences, one good and one bad, and asking subjects to choose the good one and explain\is{explaining one's judgments} why the other one was bad.
Examples \REF{ex:4:5} and \REF{ex:4:6} below give rough English equivalents of the type of structures involved:

\ea\label{ex:4:5}
\ea He shot me at the gun.
\ex  He shot the gun at me.
\z
\z


\ea\label{ex:4:6}
\ea These children, what is its name? 
\ex These children, what are their names?
\z
\z

\noindent
The second task called for subjects to explicitly identify some grammatical principle of \isi{Vai}. This is illustrated in \REF{ex:4:7}, where the relevant distinction is alienable versus inalienable possession.

\ea%7
    \label{ex:4:7}
    
	  People say ``my (\textit{{\ng}}) father,'' but ``my (\textit{na}) book''; they say ``my (\textit{{\ng}}) sibling,'' but ``my (\textit{na}) wife.'' Why do people sometimes say \textit{{\ng}} and sometimes say \textit{na}?
    


    \z

\noindent
(Apparently a wife is viewed as an acquired possession rather than a relative.) Subjects' explanations on these two tasks were scored on a scale of 0\textendash{}7. Zero denoted irrelevant answers, such as ``The old people say it like that,'' ``Bad \isi{Vai},'' and ``Not a good \isi{Vai} speaker.'' A score of 1 was given to responses that claimed the sentence was semantically inappropriate, and higher scores denoted increasing degrees of grammatical relevance. While all groups were able to identify the bad sentence in the first task, their explanation abilities on the two tasks differed according to literacy\is{literacy, effect on language skills} and education.\is{education, effect on language skills} On one survey, the average explanation scores were 3.9 for \isi{illiterate speakers}, 4.6 for \isi{Vai} \isi{literate speakers}, and 5.6 for Vai-Arabic\is{Vai}\is{Arabic} \isi{biliterate speakers}. A replication found scores of 2.3, 2.9, and 3.2, respectively. Multiple regression analysis showed that, of all the demographic data that were available about the subjects, \isi{Vai} literacy was the only factor that predicted these differences.\footnote{Interestingly, similar differences were found by \citet{LilesEtAl1977} when comparing the judgments of children with language disorders\is{child language disorders} versus unaffected children. They found that children with language disorders not only make fewer accurate judgments on certain types of syntactic errors, but they can recognize some errors without being able to correct them,\is{ungrammatical sentence, correction of} whereas unaffected children have almost no trouble correcting detected errors. In this case, however, the authors suggest that inferior production skills might be responsible, although their reasoning is quite speculative.}
%\textsuperscript{29}


The third task involved correcting errors\is{ungrammatical sentence, correction of} of various types (shown in \REF{ex:4:8}) and explaining what was wrong with an ungrammatical sentence.\is{explaining one's judgments}

\ea\label{ex:4:8}
\ea My child is crying yesterday.
\ex This house is fine very.
\ex I don't want to bother you (plural) because you (singular) are working.
\ex This is the chief's child first.
\ex These men, where is he going?
\ex They have planting the oranges.
\z
\z

\noindent
On this task explanations were scored on a scale of 0\textendash{}5. The authors provide \tabref{tab:2}, summarizing the number of errors fixed correctly and the total of the explanation scores on the six sentences. Here the regression analysis showed that schooling\is{education, effect on language skills} was the biggest contributor to explanation\is{explaining one's judgments} scores, and Vai literacy\is{literacy, effect on language skills} was also a factor. It is important to note that literate\is{literate speakers} and \is{illiterate speakers} performed equally well on other tasks examining their ability to explain things, so the effect seen in this experiment is specific to the linguistic content of the problem. We can conclude from this work that literacy and schooling have little effect on the ability to identify ungrammaticality, and hence to make grammaticality judgments in the narrow sense, but both factors appear to affect explicit grammatical knowledge, and hence will confound many other metalinguistic tasks.\footnote{A similar result in another domain is reported by \citet{ReedEtAl1979}, also based on work in \isi{Liberia}. These authors examined the arithmetic abilities of \isi{Vai} and \isi{Gola} tailors to assess the contribution of formal Western education\is{education, effect on language skills} as compared to traditional apprenticeship. Their findings suggest that these abilities can be very domain-specific: the same problem framed in terms of monetary units may be more difficult than when framed in terms of numbers of buttons to be sewn on pants, for instance. They also found that the types of errors made differ systematically between the two groups with different types of education,\is{education, effect on language skills} and seem to reflect the different ways in which arithmetic is taught in school versus on the job. The general result is that skill in applying knowledge to a particular domain does not always imply the ability to use that knowledge in the abstract.}
%\textsuperscript{30}

\begin{table}
\caption{Comparison of Vai Error Correction and Explanation as a Function of Literacy \citep{ScribnerEtAl1981}}
\label{tab:2}

\resizebox{\textwidth}{!}{\begin{tabular}{lSSSSS}
\lsptoprule	
& \multicolumn{1}{c}{Maximum} & & \multicolumn{1}{c}{Arabic} & \multicolumn{1}{c}{Vai} & \multicolumn{1}{c}{Schooled}\\
& \multicolumn{1}{c}{possible score} & \multicolumn{1}{c}{Nonliterate} & \multicolumn{1}{c}{monoliterate} & \multicolumn{1}{c}{monoliterate} & \multicolumn{1}{c}{literate}\\

\midrule
Number correct & 6 & 5.1 &  4.5 & 5.0 & 5.6\\
Explanation score & 30 & 6.9 & 8.1 & 9.9 & 15.7\\
\lspbottomrule
\end{tabular}}
\end{table}


Other researchers of literacy\is{literacy, effect on language skills} effects include \citet{Scholes1987},
who studied 10 English-speaking illiterate\is{illiterate speakers} adults and found that they seem to process sentences without making use of all the syntactic information available. For instance, they report anecdotally that a spoken sentence like \textit{The window in the room with the chair was broken} is taken to mean that the chair got broken.\footnote{One might suspect the presence of some third, pathological factor affecting both ability to acquire literacy skills and ability to comprehend sentences, but Scholes \& Willis's very brief description gives no indication of such a factor.}
%\textsuperscript{31}
\citet{Birdsong1989} cites other work by these authors suggesting that \isi{illiterate speakers} are insensitive to passive morphology, and that they judge grammaticality according to pragmatic validity and moral correctness or desirability. Scholes \& Willis conclude that \isi{illiterate speakers} have vastly different grammars from \isi{literate speakers}, but Birdsong\ia{Birdsong, David} counters that their judgments might be based on different criteria, without the underlying grammars necessarily differing. \citet{Heeschen1978} had similar experiences with the \isi{Eipo}, an illiterate,\is{illiterate speakers} neolithic horticultural people of West \isi{New Guinea}. He states that they are ``uneasy and unsuccessful'' in trying to objectify language, and concludes that 90\% of their grammaticality judgments of possible but rarely occurring verbal affix combinations were simply wrong.\footnote{Heeschen does not explain how he determined what the correct forms actually were.}
%\textsuperscript{32}
 However, their judgments on word order\is{word order violations, effect on grammaticality judgments} were ``absolutely correct.'' Heeschen suggests why this difference should be found: some affix combinations are rare and hence hard to see as correct out of context, whereas word order is a feature of every utterance that cannot be avoided. This hypothesis is supported by the fact that in \textit{natural} situations (e.g., when native speakers corrected him in conversation), as opposed to structured judgment tasks, ``their judgments as native speakers proved to be perfectly reliable'' (p. 177). Thus, at least for this culture, it seems that illiteracy\is{illiterate speakers} does not imply the inability to make accurate judgments, but just makes it hard to do so in an abstract context.

\subsection{ Other Experiential Factors} \label{sec:4.4.3}

As in the previous section, I conclude with a collection of remarks on other types of experience that might systematically affect judgments of grammaticality. The most obvious would be the amount of experience with the language in question. There have been numerous studies of metalinguistic skill in nonnative learners of a second language,\is{second-language learners} as part of the second-language teaching literature, which is beyond the scope of this investigation (see \citet{Ellis1991} for a review). Clearly, one would expect nonnative speakers to differ from their native counterparts in judgments as well as in language use, but the results of a third experiment
in \citegen{SnowEtAl1977} study (see also Sections \ref{sec:4.2} and \ref{sec:4.4.1})
suggest that native intuitions may be acquired independently of native skill in language use.

This experiment involved the same procedure as was used in Snow \& Meijer's first and second studies, this time with nonnative speakers\is{second-language learners} of \isi{Dutch} as subjects. Their within-subject consistency\is{consistency (between and within subjects)} was at least as good as that of native speakers, but predictably they showed more between-subject disagreements, since their degree of familiarity with Dutch was not matched. Nonetheless, their pooled judgments agreed somewhat better with the native speaker group than those of the linguists did. And, surprisingly, the three virtually bilingual non-natives did not match the native group better than the remaining poorer Dutch speakers (as measured by correlations in rank-ordering). The authors interpret this to mean that one's skill in speaking a language can improve without one's syntactic intuitions becoming more nativelike.\is{grammaticality judgments!versus language use}\footnote{\citet{Chaudron1983} points out that there were only eight nonnative subjects in this experiment altogether, so due caution is advised in interpreting the results.}
%\textsuperscript{33}
 Conversely, they suggest that classics scholars, for instance, show the opposite: they develop strong intuitions without being able to speak the language. Together with the large amount of variation in judgments among native speakers found in the first two experiments, Snow \& Meijer's results lead them to conclude that speaking and understanding involve a different language faculty from judging, since skill in one is not a good predictor of skill in the other. On the other hand, \citet{Coppieters1987} claims that his subjects appeared to have achieved native levels of production and comprehension, and yet their judgments were significantly different from those of native speakers. But, as discussed in \sectref{sec:3.5}, Coppieters's study had not actually shown that the two groups were identical in their \textit{use} of the crucial forms, but only on unrelated general measures of fluency, mastery of various constructions, and so forth. Thus, we have no basis for concluding that nonnative speakers display differences unique to their judgments. More likely, their grammars simply differ from those of natives on the points investigated, and this would show up in everyday use as well if these constructions occurred. It has also been proposed that experience in \textit{another} language (e.g., bilingualism) leads to differences in metalinguistic ability (\citealt{VanKleeck1982}; \citealt{Bialystok1986}; see \sectref{sec:5.3.2}).

One would expect certain types of nonlinguistic experience to influence judgments as well, for example, factual world knowledge, and cultural and social
% Subject-Related Factors  127
experiences and beliefs. \citegenp{Greenbaum1977c} review
cites correlations between judgments and occupation or socioeconomic class, without elaborating. \citet{SvartvikEtAl1977} found differences on judgments by 14-to-17-year-olds concerning the use of \textit{ought} correlated with the different academic standing of three groups of English schools\is{education, effect on language skills} they attended. I am not aware of any studies showing that these variables can affect \textit{structural} judgments. A purported example of how world knowledge\is{general knowledge, effect on grammaticality judgments} is relevant to grammaticality is provided by \citet{Belletti1988}. According to her, the following two sentences involving subject postposing contrast in grammaticality in Italian:

\ea%9
    \label{ex:4:9}
    \ea[\hspaceThis{*}]{
    \gll \hspace*{-.7mm} stato rubato il portafoglio a Maria. \\
       \hspace*{-.7mm}has been stolen the wallet to Maria\\}
    \ex[*]{
     \gll \hspace*{-.7mm} stata rubata la pianta a Maria. \\
     \hspace*{-.7mm}(has been stolen the plant to Maria) \\}
    \z
\z


\noindent
The crucial difference here is claimed to be that we can assume people normally own only one wallet, but the same is not true for a plant. If this is true, someone from a different culture presumably would not show this distinction. Unfortunately, according to one native speaker I consulted (Mirco Ghini, personal communication), while (\ref{ex:4:9}b) does require the presupposition of a unique plant that the speaker is referring to, it is structurally fine. In fact, it represents the unmarked word order for expressing this idea, and is clearly better than other starred examples given by Belletti that do seem to violate structural constraints. Evidently, a systematic investigation of this point is called for. G. \citet{Lakoff1971}
has argued that the well-formedness of a sentence can \textit{never} be assessed without reference to a set of presuppositions about the nature of the world,\is{presuppositions about the world, effect on grammaticality judgments} and cites numerous sentences where people differ in this regard. For example, whether \textit{My cat enjoys tormenting me} is grammatical depends on whether one believes cats to have minds. In cultures where events are believed to have this property, the equivalent of \textit{My birth enjoys tormenting me} is perfectly normal. Similarly, Lakoff has argued that grammaticality judgments of \textit{John called Mary a Republican and then \textsc{she} insulted \textsc{him}} 
depend on the speaker's beliefs, and perhaps even on John's and Mary's. \citet{Chomsky1972} argues instead that such sentences should be considered grammatical regardless of anyone's beliefs, and that it should be left to the semantic component of the grammar to specify the presuppositions they require. (See also \citet{BarHillel1971}, who argues against those who feel ``obliged to force a clearly pragmatic matter into a syntactico-semantic straitjacket.'')

\section{Conclusion} \label{sec:4.5}

The studies reviewed in this chapter show that a considerable proportion of individual differences in grammaticality judgments can be attributed to specific linguistically relevant features of the person, be they inborn or the result of experience. Nonetheless, we can be fairly certain that there remains much variation that we cannot factor out in this way. In this regard grammaticality judgments are like most other forms of behavior, including other metalinguistic tasks such as ambiguity detection \citep{KessEtAl1983}. A common genetic endowment provides for a certain degree of commonality, and certain gross parameters of variation, but beyond  that differences abound. This state of affairs, however immutable, presents frustrating problems once we acknowledge that the study of grammar, while in principle a study of each individual's mental structures, must appeal to the judgments of many individuals. However, before we resign ourselves completely, we should consider that not all the variation that shows up within and across experiments is attributable to real differences between subjects. Subtle differences in procedures or in the sentences themselves can add error to the actual variation. In the next chapter I turn my attention to such confounding sources.
