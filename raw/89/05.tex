\chapter{Task-Related Factors in Grammaticality Judgments}\label{sec:5}

\textsc{Meander} (a linguist): I have a theory that everybody's eyes are colourless.

{\leftskip=10pt\parindent -10pt
\textsc{Simplon} (a psychologist):  But, Meander, everybody's eyes look brown, blue or green to me.

\textsc{Meander}: That's because they are actually wearing contact lenses to color
their eyes.

\textsc{Simplon}: But, Meander, I know that I don't wear contact lenses, and when I look in the mirror my eyes look blue to me.

\parindent 0em\textsc{Meander}: Ah: but then, there's a lot we don't know about mirrors.
}\begin{flushright}\citep{Bever1974}\footnote{Tom Bever\ia{Bever, Thomas G.} (personal communication) states that this is a dialogue version of a joke attributed to Haj Ross.\ia{Ross, John Robert}}\end{flushright}


\section{Introduction}\label{sec:5.1}

By now it should not be a surprise to find that grammaticality judgments may vary depending upon the procedure by which they are obtained and properties of the stimulus items that are presented. In fact, the latter assertion might seem tautologous. Obviously, if judgments are to be of any value they must vary depending on the sentences being judged. My focus here, therefore, will be on variation caused by factors that are \textit{irrelevant} to the concept that we are trying to access through grammaticality judgments, namely grammaticality. Clearly there is room for disagreement here, since what should count towards grammaticality is a matter of theoretical assumption or fiat. Similarly, whether an experimental procedure interferes with grammaticality judgments depends on one's view of how best to obtain them. For the most part, the variables I examine in this chapter would be uncontroversially labeled as confounds by the majority of linguists.

% 129


%\originalpage{130} %  Chapter Five

Even where there is disagreement, for instance, as to whether context is a nuisance or an integral part of the grammaticality of a sentence, systematic study should lead to a better understanding of the phenomenon, and thus improve the linguist's chances of designing effective elicitation procedures. The recommendations I make on the basis of the research reviewed here reflect my own point of view on the nature of grammaticality.

This chapter is essentially a top-down survey of the experimental literature. \sectref{sec:5.2} covers features of the elicitation process as a whole, beginning with what subjects are asked to do, that is, how the procedure of judging grammaticality is explained to them (\sectref{sec:5.2.1}).\footnote{I do not concern myself here with the much larger question of the range of tasks one might use to elicit information about acceptability. This was discussed to some degree in \sectref{sec:3.2}; further exploration is beyond the scope of this book, since my focus is on judgments.} This issue will pervade the entire chapter, since differences in instructions could be largely to blame for the staggering discrepancies among experiments, and much of the existing literature is undermined because vague instructions make many of the results virtually uninterpretable. 
\footnote{One feature of the task instructions not covered explicitly in this chapter is the type of judgment required: good/bad or numeric rating or relative ranking. This issue is discussed in \sectref{sec:3.3.4}. I also omit mention of certain standard confounding effects that psychologists typically seek to avoid but that do not seem to have any special impact in the domain of language judgments. Some of these are mentioned in conjunction with the methodological proposals in \sectref{sec:6.3}.}
%\textsuperscript{3}
 Then I examine the effects of the order in which sentences are presented for judgment (\sectref{sec:5.2.2}). The next three subsections largely follow the research program of one experimenter, Hiroshi Nagata, whose initial work looked at the effects of repeated exposure to the same sentences (\sectref{sec:5.2.3}). This also raises the issue of intrasubject consistency, which was a subsidiary concern of several other experimenters mentioned in this chapter. Later work by Nagata\ia{Nagata, Hiroshi} and others brought in mental state manipulations and their interaction with repetition (\sectref{sec:5.2.4}), and sought support for his hypothesized explanations by correlation with subjects who were explicitly told to use certain judgment strategies (\sectref{sec:5.2.5}). The subsequent subsection explores the least-studied procedural variable, which nonetheless could arguably have the greatest impact on judgments\schdash{}namely, the presentation modality (spoken versus written). Closely tied up with this is the matter of register,\is{register, effect on grammaticality judgments} since together these two factors define to a large degree the nature of the discourse situation, and hence how grammatically strict or permissive we are liable to be as listeners (\sectref{sec:5.2.6}). Finally, I take a brief look at speed of judgment (\sectref{sec:5.2.7}).


\sectref{sec:5.3} takes a closer look at the properties of stimulus materials themselves. I begin with the role of the context in which the sentence is situated. I restrict the term \textit{context} to the purely linguistic context, ignoring social factors that obviously influence acceptability in the broader sense (see \citet{vanDijk1977} for a discussion of social factors). Nevertheless, the term \textit{context} is used in at least four different ways (\sectref{sec:5.3.1}). My next concern is the extent to which the meaning of a sentence, or the apparent lack of meaning, affects people's judgments of grammaticality, in cases where (we assume) it is an orthogonal issue (\sectref{sec:5.3.2}). I then ask the same question about how easily a sentence is parsed (\sectref{sec:5.3.3}) and the (perceived) frequency of occurrence of sentences of the same type (\sectref{sec:5.3.4}). The final two subsections concern the level of individual words: what happens when one word is replaced by another that is grammatically equivalent (\sectref{sec:5.3.5}), or with one that is grammatically identical (\sectref{sec:5.3.6}). Some potential stimulus variables do not have separate headings devoted to them in this chapter. Intonation is mentioned briefly in conjunction with modality in \sectref{sec:5.2.6}. Its written counterpart, punctuation, does not appear to have been studied for its effects on grammaticality judgments\is{punctuation!effect on grammaticality judgments} in general (but see \citet{Levelt1974} for some discussion of its possible effects), although it is occasionally mentioned anecdotally in other types of psycholinguistic studies. The most detailed work I am aware of on the linguistic significance of punctuation is by \citet{Steegar1975}, who analyzes its relation to prosody. Finally, \sectref{sec:5.4} summarizes the major implications of the reviewed research.

\section{Procedural Factors}\label{sec:5.2}

\subsection{Instructions}\label{sec:5.2.1}

\citet{Hill1961} performed some of the earliest investigations into the nature of grammaticality judgments. He used 10 subjects, of which 3 were linguists and several others were English professors, which should immediately lead us to suspect that his results will not generalize to the population at large. They were instructed\is{instructions to subjects!effect on grammaticality judgments} to ``reject any sentences which were ungrammatical, and to accept those which were grammatical,'' but there was apparently no definition or explanation of these terms given, nor any examples of their application. The results and anecdotal comments he reports show  that subjects had no clear notion of the concept of grammaticality. For instance, while all 10 subjects rejected \textit{Those man left early}, 6 of them accepted \textit{The child seems sleeping}. Even more troubling is the
%\originalpage{132} %  Chapter Five
fact that two rejecters of the sentence \textit{I never heard a green horse smoke a dozen oranges} changed their judgments to accept it once it was pointed out to them that the sentence was true.\is{truth of sentence, effect on grammaticality judgments}\footnote{\citet{QuirkEtAl1966} respond to this particular finding by disparaging the whole paradigm: ``When the notion of what is grammatical is confounded with eternal verities, it is time to look for other techniques of investigation'' (p. 12).}
%\textsuperscript{4}
 Other subjects explained their acceptance of a sentence by saying that ``it sounds like poetry''\footnote{This and other irrelevant reactions are taken by \citet{Lees1976} as evidence that, contrary to Hill's conclusion, his subjects in fact demonstrated even greater knowledge of language than was attributed to them by Chomsky's\ia{Chomsky, Noam} claims, which Hill believed he had refuted.}
%\textsuperscript{5}
or rejected a sentence because it did not start with a capital letter.\is{capitalization, effect on grammaticality judgments} The conclusion to be drawn from all this should be obvious: even subjects who are supposedly experts on language cannot be expected to know what linguists mean by \textit{grammatical} (or \textit{acceptable}, for that matter).\footnote{Actually, it is not even clear that linguists agree among themselves as to what exactly is supposed to count towards grammaticality. As mentioned in \chapref{sec:2}, the concept changes as the theory evolves. At the very least, researchers must clarify this point in their own minds before trying to design a set of instructions.}
%\textsuperscript{6}
 If you do not explain to subjects what you want, each one takes his or her own interpretation and the results are meaningless. This criticism was made in the same journal volume by \citet{Chomsky1961}; see \citet{Lees1976} for another response to Hill, including an enlightening analogy to a chemistry experiment in which most informants fail to report that iron rusts in water, for various irrelevant reasons\schdash{}a demonstration of the pitfalls of a naive research strategy. We will see in \sectref{sec:5.3.2} that \citet{MaclayEtAl1960} encountered the same problem with linguistically naive subjects. \citet{Carden1976a} was able to avoid contaminating his data with such cases because he used face-to-face interviews.\is{questionnaire!versus interview} He discovered that one of his subjects rejected all imperative sentences because he would have added \textit{please} to them! In a very widely cited passage, \citet{Carden1970a} states, ``You must define `grammatical' or `acceptable,' words that naive informants use in widely varying ways. It is of no value to know that 13 informants consider a sentence acceptable unless you know that they mean the same thing by `acceptable'.'' \citet{BleyVromanEtAl1988} found that minimal instructions led to highly inconsistent responses in their pilot studies, while more detailed instructions with examples led to 90\% agreement among their experimental subjects. \citet{Coleman1965}, \citet{QuirkEtAl1966}, \citet{Schnitser1973}, \citet{Cohen1981}, \citet{Greenbaum1977c}, \citet{Newmeyer1983},
 and \citet{Botha1973} make similar points. \citet{Birdsong1989} suggests that the problem is particularly acute when the forms in question occur in speech but are proscribed in writing.\is{speech versus writing, effect on grammaticality judgments}

Unfortunately, as we have seen in previous chapters and will continue to see in this one, many studies have fallen into exactly the same trap. In fact, if we were to ignore all studies in which we believe the instructions\is{instructions to subjects!effect on grammaticality judgments} to subjects were inadequate to convey the subtlety of a linguistic definition, the remaining studies could likely be counted on one hand. Thus, I will continue my practice of describing the experimenter's instructions in considerable detail, in order that the usefulness of the results can be assessed. But in order to make any progress, we will have to assume that the major findings would hold up under more careful procedures. (Therefore, some of Hill's other results will be reported in subsequent sections.) This is not meant to condone the existing practice or deny the need for replication, but merely to accept the fact that somewhat confounded data are better than none at all. By way of ending on a positive note, I also occasionally report instances of very well designed instructions, and proposals for how to test their effectiveness. For instance, \citet{Chaudron1983} suggests asking subjects what they consider to be valid judgment criteria, and how they make use of these criteria in particular sentences. See \citet{GreenbaumEtAl1970} for an examination of the instructions surrounding performance tasks.

A recent experiment by \citep[55\textendash{}59]{Cowart1997}
suggests that as long as subjects are given \textit{some} explicit set of instructions,\is{instructions to subjects!effect on grammaticality judgments} the exact contents of those instructions might not matter a great deal, at least for some classes of sentence types. He contrasted the same judgment experiment (which involved \textit{that}-trace effects)\is{Comp-trace effect} run with two different sets of directions regarding how subjects were to decide on their responses. One set appealed to their prescriptive\is{prescriptive rules} sense by invoking English professors marking term papers, the other emphasized the absence of right or wrong answers and appealed to personal reactions. This manipulation turned out to have almost no effect on the pattern of responses. While such negative findings are notoriously hard to interpret, this may be an indication that when other factors are suitably controlled, instructions turn out to be fairly benign, perhaps because subjects really do not have multiple judgment routines they can invoke in such an experiment; regardless of the instructions, they will do the only kind of judging they know how to do. It is up to the experimenter to design stimuli that will not mislead them. My feeling is that due care is still advised in handling instructions, because Cowart's\ia{Cowart, Wayne} finding does not rule out the possibility that instructions could interact with the type of sentence being judged.

Another important factor, arguably part of the instructions\is{instructions to subjects!effect on grammaticality judgments} of a judgment task, is the response scale\is{rating scale!choice of} required (\citealt{VanKleeck1982}), i.e., how many choices the subjects have and how those choices are described. The former issue is addressed
at length in \sectref{sec:3.3}, where I show that little experimental work has looked directly at the differences induced by changes of response scale (but see \citet[67\textendash{}77]{Cowart1997} for a relevant experiment), and that graded behavior could be an artifact of the testing procedure. The issue of labeling the scale has received even less attention, so I attempt to bring it to the reader's attention whenever the details of an experimental response scale are published. Although some researchers have given advice on this topic (see \sectref{sec:6.3.2}), I am not aware of any research directed specifically at it. \citet{Bialystok1979} did find that \isi{response bias} among her subjects differed depending on the amount of detail required. When she asked for yes/no responses, subjects were biased toward saying ``yes,'' but when she asked for specific kinds of errors to be identified, they were biased toward finding some error, i.e., toward judging a sentence ungrammatical. Such differences are expected under her theory since the various types of response place different demands on the subjects' analyzed knowledge\is{analyzed knowledge, as component of language skill} and cognitive control\is{cognitive control, as component of language skill} (see \sectref{sec:3.4}).

\subsection{Order of Presentation}\label{sec:5.2.2}

\citet{Greenbaum1973,Greenbaum1976a} describes an experiment that looked at the effects of order of presentation of sentences on judgments.\is{order of presentation (of sentences)!effect on grammaticality judgments} It required nonlinguist subjects to rate sentences containing participial \textit{while} phrases attached in various places in a sentence:


\ea%1
    \label{ex:5:1}
    \ea Sophia Loren was seen by the people while enjoying herself.
    \ex The people saw Sophia Loren while enjoying themselves.
    \ex Judy was seen by the people while enjoying themselves. 
    \ex The people saw Karen while enjoying herself.
    \z
    \z

\noindent
Subjects had a choice of four responses to each sentence: ``acceptable,'' ``uncertain, but probably acceptable,'' ``uncertain, but probably unacceptable,'' and ``unacceptable.'' Two subjects were assigned to each possible ordering of the four sentences, and statistical analysis showed that the first sentence for each group was rated significantly lower than the others. No significant effect was associated with any other position in the list. Clearly, then, sentence order should be controlled for, either by randomization or counterbalancing. The study was essentially a replication of one by \citet{ElliotEtAl1969}, who apparently used the same order for all subjects, thus severely confounding their results. Problems remain with Greenbaum's procedure as well, however. First, he apparently gave his
subjects no explanation of the term \textit{acceptable}. Second, he ignored the standard psychological practice of using warm-up trials\is{practice trials} to get subjects comfortable with the procedure. If he had done so, the effect of first position might have been removed rather than just counterbalanced, thus reducing the amount of variability in the scores. See \citet[21]{Labov1975} for a review of these two studies and ensuing work. \citet{GreenbaumEtAl1970} also reported order effects in their test batteries, both for judgment and performance tasks. In one case they found a significant difference between the two orders (between-subjects groups) in the number of subjects giving ``grammatical'' ratings for 5 out of 51 sentences tested. Interestingly, relative rankings\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)} showed almost no changes as a result of varied orders.

Certain effects of presentation order that arise due to relationships among stimulus sentences will be treated as context effects in \sectref{sec:5.3.1}.

\subsection{Repetition}\label{sec:5.2.3}

\is{repetition, effect on grammaticality judgments}Nagata\ia{Nagata, Hiroshi} has performed a number of experiments investigating the effect of repeated exposure to sentences on judgments of their grammaticality, and the interaction of repetition with other manipulations. According to him, no previous experiments had examined this variable systematically (and I am not aware of any either), but it has important implications, because linguists, the most common producers of judgment data, often consider the grammaticality of sentences many times over the course of investigating some theoretical issue. (\citet{Spencer1973} 
also speculates on the effects of repeated exposure to sentences on linguists.) Thus, if we have reason to suspect that their judgments are not stable, by the time they draw their conclusions their judgments might be quite different from their first impressions. (This issue comes up again in \sectref{sec:5.2.7}.) Nagata suggests a priori two possible outcomes of a repetition treatment, to which I will add a third. He proposes that judgments might become more lenient (sentences might be considered more grammatical) because subjects would construct additional linguistic or situational contexts for sentences, eventually finding cases where even fairly bad sentences would be reasonably acceptable. This would accord with the general psychological phenomenon of habituation, whereby repeated exposure to the same stimulus has diminishing effect (e.g., the same painful prod will evoke less and less reaction). On the other hand, Nagata postulates, we might expect judgments to become more \textit{stringent} as people differentiate more syntactic or semantic properties of the sentence. That is, the more they look at a sentence, the more things they might find wrong with it. Graeme Hirst (personal communication)\ia{Hirst, Graeme} has suggested a third possible outcome, namely that repetition might just increase subjects' confidence in their original judgments. In that case, we would expect a polarization of judgments, i.e., good sentences would get better and bad sentences would get worse.

In his first study, \citet{Nagata1988} performed three experiments to examine the basic effect of repetition and its interaction with the presence of context. The procedure was essentially the same for many subsequent experiments as well. His stimulus materials were pairs of grammatical and ungrammatical sentences drawn from the Japanese linguistics literature, matched as closely as possible, plus pairs of filler sentences. Whether the target sentences were considered good or bad was determined on the basis of whether or not they received any question marks or stars in the original source articles. Thus, the number of good and bad sentences would be roughly equal; the total number of sentences was 48. Subjects were asked to rate the extent to which the sentences were grammatical; i.e., ``correctly expressed in Japanese,'' on a scale from 1 to 20. They were told that correct sentences should be rated as 1, while 2\textendash{}20 indicated increasing degrees of badness. Subjects were also told to make use of the full scale.\footnote{The only justification given by Nagata for the unusually large rating scale and its asymmetric division (as opposed to making the best sentences 1, the worst 20, and the remainder evenly spread in between) is that the same scheme was used by \citet{Moore1972}. But Moore\ia{Moore, Timothy E.} himself gives no justification for these choices. I can only speculate that they might have been inspired by the psychometric results mentioned in \sectref{sec:3.3}. I suggest that Nagata's\ia{Nagata, Hiroshi} results might profitably be replicated using a smaller, symmetrical rating scale, but it does not seem to me that his scale would have biased the results. If anything, the large scale should increase variability in the results and make it harder to find significant effects.} 
First, the sentences were presented one at a time in random order on a CRT and the subjects were asked to give their numeric judgments of each, to be used as the baseline measure. In the second part of the procedure, each sentence in turn was presented in a repetition phase, followed immediately by another judgment. In the repetition phase, the sentence was displayed nine times in a row for 3 seconds each time, with a 1-second pause between presentations. During these repetitions, the subject was told to think of the grammaticality of the sentence. Then, upon the tenth presentation the subject was asked once again to rate the sentence. (The order of sentences in this part of the procedure was again random.) The first, unsurprising, result was that the supposedly good sentences received significantly better ratings than the bad ones both before and after repetition, confirming that the a priori division was reasonable. Wayne Cowart (personal communication)\ia{Cowart, Wayne} points out that this means the \textit{pattern} of results, in terms
of relative acceptability of sentences, was not affected by this manipulation. As for the effects of repetition itself, the grammaticality ratings of both kinds of sentence decreased significantly after repetition (i.e., the rating numbers were higher), as compared to before. Nagata concludes that subjects were engaged in differentiation rather than enrichment\is{grammaticality judgments!strategies for} during the repetition phase. If this result is general, we must reexamine why the theory of mere exposure has been widely accepted in accounting for language change. It holds that as people hear a form more and more, they like it more, deem it more acceptable, etc.: ``familiarity breeds content.''\footnote{Attributed in \citet{BradacEtAl1980} to \citet{Walker1973}. Of course, in everyday situations, repeated exposure to a form is not accompanied by an instruction to ponder its grammaticality.}
% 8
To the extent that this is true in language change, why is it not true in Nagata's repetition paradigm? Is the time span involved too short, i.e., is repetition in quick succession different from repetition over a long period of time?\is{change in judgments over time} Is the problem that all the repetitions come from the same source?

In the first follow-up experiment, the same sentences were used but the final judgments were made with the sentence preceded by a context string.\footnote{Nagata\ia{Nagata, Hiroshi} provides translations of his target and context strings only for the grammatical sentences, of which I give two examples; the targets are italicized: (i) Look out of the window. \textit{It is raining.} (ii) What's the matter with you? \textit{If you don't eat, you'll be hungry.} Apparently the nature of the bad sentences was such that reasonable contexts could still be provided for them.}
%\textsuperscript{9}
 As compared to postrepetition\is{repetition, effect on grammaticality judgments!and context effect} ratings in the first experiment, the with-context condition showed that ungrammatical sentences were judged significantly more grammatical; they showed no significant change from the prerepetition ratings. Ratings for the grammatical sentences did not differ significantly from either the postrepetition ratings in Experiment 1 or the prerepetition ratings in Experiment 2. Nagata\ia{Nagata, Hiroshi} believes that this points to a change in encoding or organization of the bad sentences when embedded in context, somehow undoing the change induced by repetition. Apparently, context had some mitigating effect for the good sentences as well, since they failed to show the decrease in grammaticality found in the first experiment. A second follow-up, in which context preceded the target sentences before, during, and after repetition, confirmed the basic finding that context blocks the repetition effect, supposedly because it provides a stabilizing base for judgments.\footnote{\citet{Spencer1973} cites several relevant background studies on repetition effects in word recognition, among them one by \citet{TaylorEtAl1963} that reportedly shows a similar type of stabilizing effect: if subjects are told that they will hear only actual words, they do not report that some of the repetitions sound like nonsense syllables, whereas subjects who expect nonsense forms claim to hear them.}
%  10
The prerepetition ratings were also compared with those of the first experiment, allowing a direct analysis of the effect of context alone. No significant
differences were found, apparently contradicting numerous other studies that found that context raises grammaticality ratings. Nagata suggests that the effect of context was somewhat masked by a ceiling effect, i.e., the sentences were already rated about as high as they could get. See \sectref{sec:5.3.1} for further discussion of this point.

In two subsequent studies \citep{Nagata1987a,Nagata1987b}, two alternative accounts of the basic repetition finding were ruled out. First, one must consider the possibility that the subjects' use of the rating scale had changed,\is{rating scale!change over time in use of} independent of repetition, because the first set of ratings were made before all the sentences had been seen. Since subjects were told to use the full range of 20 values, and since they would only know which were the best and worst sentences after the first round of ratings, this is a distinct possibility. Thus, a new experiment was designed to seek out such a trend. Sentences were all judged once, then all judged a second time (in a different random order). Since no changes were found between first and second ratings,\is{change in judgments over time} a ``change in the modulus of judgmental scale'' account, as Nagata calls it, is ruled out.\footnote{Nagata does not discuss the possibility that subjects could have remembered their initial ratings and tried to be consistent by duplicating them the second time around. Since much less time intervened between first and second ratings as compared to conditions in the repetition experiment, the possibility is worth considering. However, given that there were 48 sentences and 20 possible scores for each, and the two presentations were in different orders, I doubt that accurate memory for one's ratings would be possible.}
%\textsuperscript{11}
 This result appears to contradict \citegen{Carden1976b} survey of a number of studies that examined the internal consistency of their data by seeking a second rating from subjects some time after the initial data collection. Many of these studies found the second rating to be highly inconsistent with the first.\is{change in judgments over time} However, Nagata\ia{Nagata, Hiroshi} was comparing \textit{mean} ratings of all the good sentences pooled and all the bad sentences pooled, not ratings for individual sentences\schdash{}a change could have been washed out by intersentence variability. A second potential confound is \isi{satiation}: prolonged repetition of symbols (e.g., words) has been shown to lead to temporary loss of their meanings and concomitant illusory changes in their perception (see \citet{Pynte1991} for some recent work and a review of the semantic satiation literature, and \sectref{sec:7.2} on recent satiation research by Snyder). If Nagata's subjects reached satiation for the stimulus materials, the results do not necessarily bear on normal judgments. Since satiation is a short-term phenomenon, this possibility was tested by looking for long-term maintenance of the changes induced by repetition. The subjects from the original experiment were retested on the same
sentences 4 months later. Their results were not significantly different from the original postrepetition judgments, and in most cases their ratings were still significantly higher than their original \textit{prerepetition} judgments. That is, whatever had changed in their approach to these sentences still held long after any satiation effect would have worn off. But had they encoded something \textit{specific} to these 48 sentences, something that was maintained in their minds for 4 months without reinforcement, or was it that their judgment process \textit{in general} had changed as a result of greater experience with the task? Nagata does not consider the latter possibility, yet it strikes me as somewhat more plausible, and could be easily tested. For instance, 4 months after the repetition treatment one could give the same subjects novel sentences, and compare their ratings to those of subjects who had never undergone repetition. If my interpretation is correct, the former group should show significantly more stringent ratings.

A fourth study \citep{Nagata1989d} was designed to assess the extent to which the repetition effect applies generally to sentence types other than those used earlier. Its first experiment factored out the differential effects of repetition on sentences marked with a question mark as opposed to a star in the original sources. Nagata's hypothesis was that the truly bad sentences could not get any worse through repetition, but in fact both groups of sentences were rated worse in postrepetition judgments.\is{change in judgments over time} The second experiment used new stimulus materials altogether, instances of the three types of violation\is{three levels/kinds of deviance (\textit{Aspects})!experiments on} identified by Chomsky\ia{Chomsky, Noam} (see \sectref{sec:3.3}):\ia{Ross, John Robert} incorrect lexical category, subcategorization violation, or selectional restriction violation. Here he found that repetition had no significant effect on any of the three types of badness. The latter two, in fact, did not show significant differences between them. His explanation is that these violations were all more blatant than those used in the earlier studies, which involved subtle uses of particles, reflexives, and honorifics. A more blatant violation might be easier for subjects to detect and explain, so they might tend to anchor more on initial judgments and resist change. Thus, at least for ungrammatical sentences, the repetition effect has limited external validity.

The only other study I am aware of that has involved repeated judgments of the same stimuli is one by \citet{Carroll1979}. The issue for Carroll was the extent to which complex compound nouns such as \textit{girl that irons her clothes doll} (referring to a doll that looks like a girl and that irons her clothes) are judged acceptable in a sentential context as a function of the syntactic structure of the elements making up the compound. He was cognizant of the potential for a change in use of the
(5-point) rating scale\is{rating scale!change over time in use of} on the basis of the range of stimuli he was presenting, especially since subjects might never have seen such complex compounds before, and so he asked his subjects to make a second pass through  the sentences, judging them again. While the mean ratings of several sentences did increase from the first to the second judgment, Carroll does not analyze the differences for statistical significance, so we cannot compare his results to those of Nagata.\ia{Nagata, Hiroshi} However, the statistical tests that \textit{were} performed show that there were fewer significant differences \textit{among} the 10 sentence types in the second set of judgments than in the first. Apparently, subjects see the range of sentences as more homogeneous the second time around.\is{change in judgments over time} This study can also be held up as a rare example of one that took care to ensure that subjects had a strong understanding of the basis on which they were to make their judgments. \is{instructions to subjects!examples of}Carroll gave example sentences with their ratings, discussed why the ratings had been chosen, and encouraged questions about the rating  system (see \citealt[874\textendash{}875]{Carroll1979}).

\subsection{Mental State}\label{sec:5.2.4}

The next step in Nagata's\ia{Nagata, Hiroshi} project was to investigate the interaction of repetition with mental state, specifically the effect of objective versus subjective self-awareness. Before describing his study, I digress briefly to explore the nature and history of this manipulation and its application to language. There is a standard operational technique from social psychology that is used to manipulate the introspective set of subjects, inspired by the \isi{social facilitation effect}: observation of yourself or others engaged in the same activity makes you do that activity more intensely. For example, people will ride a bike faster  if they see other people riding bikes. \citet{DuvalEtAl1972} brought together a large number of findings in this area and unified them under the theoretical distinction of subjective versus objective self-awareness, states of consciousness directed at the external environment or at oneself, respectively. By their definitions, \isi{subjective self-awareness (SSA)} is a state of consciousness in which attention is focused on events external to the individual's consciousness, personal history, or body; you are the \textit{subject} of consciousness directed outward, the source of perception and action, but are not aware of yourself as experiencer. Objective self-awareness (OSA)\is{objective self-awareness (OSA)} is exactly the opposite state: your consciousness is focused on yourself, your own conscious state, personal history, or body: you are the \textit{object} of your own consciousness, a state that often leads to self-evaluation and negative affect, by inducing self-comparison with external standards. SSA is humans' primary or default state; the environment normally draws your attention. OSA requires a reminder of your status as object in the world\schdash{}stimuli that cause a shift of attention to yourself, such as looking in a mirror\is{mirror-gazing, effect on self-awareness}, hearing your voice on tape, seeing a photograph of yourself, or having a TV camera pointed at you. Once you are in the OSA state, attention shifts to your relevant features, regardless of which sort of stimulus induced the state.

One experiment that \citeauthor{DuvalEtAl1972} used to demonstrate this manipulation went as follows. The experimenter described to the subject a hypothetical scenario involving him or her, such as a traffic accident. For each situation, subjects were asked to rate how responsible they were for the outcome, that is, how much of the causality was attributable to them. There were two conditions: the experimental room may have had a mirror in it, positioned so that subjects would see themselves in it (the OSA condition), or it may have had the nonreflective back of the mirror facing them (the SSA\is{subjective self-awareness (SSA)} condition). The result was that OSA\is{objective self-awareness (OSA)} subjects attributed significantly more causality to themselves than SSA subjects. In another experiment, subjects were given an intelligence test. They were then told that they scored below average on it, left alone in a room with a clock, and instructed that if no one returned, they could leave after a certain number of minutes had passed. Again, self-awareness was manipulated by the presence or absence of a mirror. The OSA subjects tended to leave the room significantly sooner than the SSA subjects, supposedly because the mirror leads to negative feelings: subjects were constantly reminded of their ``below-average intelligence.'' Note that in this case, unlike the previous experiment, there was no reporting involved. The manipulation affected the subjects' actions, not just their statements.

\citet{CarrollEtAl1981} conducted the first study I am aware of that applied self-awareness manipulations to linguistic intuitions. Their premise was quite similar to mine: since intuitions are produced by performance mechanisms, they wanted to control and study these mechanisms, specifically by manipulating mental state. They had a quasi-theoretical goal as well, which was to show that different mental states could produce intuitions that correspond to two competing theories of the relation between syntax and semantics, namely autonomous syntax and abstract syntax. Therefore, it was not a case of choosing one theory over another. Rather, both theories were correct, and they simply
accounted for different kinds of intuitions. 


%Chapter Five

%%please move \begin{table} just above \begin{tabular
\begin{table}
\robustify\bfseries
\begin{tabular}{lS[detect-weight]S[detect-weight]}
\lsptoprule
 Sentence Type & \multicolumn{1}{c}{SSA Condition} &  \multicolumn{1}{c}{OSA Condition} \\
\midrule
 A house is a building & 9.55  & 9.60 \\
A garage is a building. & 7.60 & 8.60\\
\bfseries A lean-to is a building. & \bfseries 5.40 & \bfseries 7.35\\
A tent is a building. & 3.25 & 4.50\\
\textsc{overall} & 6.45 & 7.51\\
\lspbottomrule
\end{tabular}

\caption{Mean Truth Ratings of Sentences as a Function of Self-Awareness \nohyphens{\citep{CarrollEtAl1981}}.}
\label{tab:3}
\end{table}



Since this theoretical issue is not of concern to us here, and in fact is no longer much discussed, I will ignore the potential theoretical implications of the results and merely concern myself with the effects produced on judgments themselves. \citeauthor{CarrollEtAl1981} suggested that linguists rendering intuitions need to be in something like the OSA\is{objective self-awareness (OSA)} state. Unlike a regular speaker, who is subjectively preoccupied and will tend to produce speech errors and ambiguities without noticing them (as \citeauthor{DuvalEtAl1972} themselves suggest), linguists must cease being speaker-hearers to pause  and reflect on the linguistic signal, to ``objectify the sentence from all the specific potential functional contexts of its utterance.'' In a pilot study, they had subjects rate the truth of categorical statements like those listed in \tabref{tab:3} on a scale of 1 (least true) to 10 (most true). In one condition, subjects had to use an answer key that was stuck to a mirror\is{mirror-gazing, effect on self-awareness} to fill out the questionnaire, but were not otherwise instructed to look at the mirror; the other condition had no mirror. The mean ratings for the two conditions are shown in \tabref{tab:3} (from \citealt[372]{CarrollEtAl1981}). Overall, subjects in the OSA condition gave higher truth ratings. Furthermore, the greatest difference  between the groups occurred on sentences like the one highlighted in the table\schdash{}sentences that are technically true but pragmatically unlikely. The authors propose the explanation that OSA subjects consider more potential communicative situations than SSA\is{subjective self-awareness (SSA)} subjects, and this is most important for the marginal cases. The false sentences are pragmatically appropriate in very few situations, and the paradigmatic ones require no contextualization to establish their truth. The more general conclusion is that self-awareness manipulation does make itself felt in linguistic tasks, although it is worth noting that the \textit{relative} truth ratings were the same for both groups.

Thus, \citeauthor{CarrollEtAl1981} proceeded  to their central investigation. Since it does not concern grammaticality judgments,  my summary will be rather
brief, focusing on those aspects that are relevant to Nagata's\ia{Nagata, Hiroshi} study. The task was to rate the pair-wise similarity of sentences from the following sort of paradigm:\footnote{Subjects were not told what to use as a basis for measuring similarity, so once again we have the potential for widely varying interpretations.}\\
%\textsuperscript{12}

\begin{tabular}{ll}
\textit{Active:}         &  The morning sun dried the sweet raisins.            \\
\textit{Passive:}        &  The sweet raisins were dried by the morning sun.      \\
\textit{Inchoate:}       &  The sweet raisins dried in the morning sun.            \\
\textit{Were-Inchoate:}  &  The sweet raisins were dried in the morning sun.        \\
\textit{Cause:}          &  The morning sun caused the sweet raisins to dry.          \\
\textit{Because:}        &  The sweet raisins dried because of the morning sun. \\
\end{tabular}\\\\
\noindent
The relevant feature of this group of sentences is that they are semantically very close but syntactically quite different. The prediction was that OSA\is{objective self-awareness (OSA)} subjects, who are more aware of social interaction, would be more sensitive to communicative similarity, since they consider a wider range of potential situations for the utterances, and would thus differ from SSA\is{subjective self-awareness (SSA)} subjects, who would focus on the surface form of sentences. This prediction was borne out. OSA subjects gave higher similarity ratings overall; in addition, the multidimensional scaling plots come out quite different for the two groups. \citeauthor{CarrollEtAl1981} take their results to show that people might use different \textit{strategies for interpreting intuitions}, depending on the situation. Extrapolating from their statement, one could imagine that people have intuitions about \textit{both} the structural and communicative properties of sentences, but how these are weighted in coming to an overall similarity measure would depend on whether the situation prompted communicative versus sentential assessment.\footnote{If all that is involved is a communicative orientation, as opposed to seeing \textit{oneself} objectified, one might expect other procedures to have the same effect, e.g., showing someone a photograph of another person instead of the mirror. To my knowledge, such an experiment has not been done.}
%\textsuperscript{13}


Let us now return to the realm of grammaticality judgments, and specifically to the experiments reported by \citet{Nagata1989a}, which investigated the effects of self-awareness\is{objective self-awareness (OSA)}\is{subjective self-awareness (SSA)} and its interaction with the repetition\is{repetition, effect on grammaticality judgments!and introspective set} manipulation previously described. Nagata\ia{Nagata, Hiroshi} started from the assumption that in his earlier repetition studies, subjects were in an SSA\is{subjective self-awareness (SSA)} state (since there was nothing to trigger OSA\is{objective self-awareness (OSA)}), and hence used sentential strategies like \citeauthor{CarrollEtAl1981}'s SSA subjects. Perhaps repetition would have a different effect on OSA subjects: over multiple repetitions they might consider more potential situations or contexts for the
%\originalpage{144} %  Chapter Five ,
sentences  and thus rate them more grammatical  (recall this idea from Nagata's original experiment). The first test of this hypothesis involved the same repetition paradigm as before, except that in the OSA condition there were mirrors on either side of the CRT where sentences appeared, and the subjects were told to look at themselves in the mirror\is{mirror-gazing, effect on self-awareness} while making judgments  and while thinking of the grammaticality  of sentences during repetition. The SSA subjects showed a worsening of ratings, as in previous studies, but OSA subjects showed no change of ratings after repetition. Thus, it seems that the mirror manipulation  did negate the effects of repetition,  although it failed to induce greater leniency  in judgments.  Nagata was convinced that such a leniency effect should be demonstrable, and suggested that it was undermined by possible ceiling effects, unclear instructions, and overexposure to the mirror (that is, it might have begun to induce the communicative strategy on initial judgments,  leaving less room for measurable change after repetition). A follow-up experiment tried to solve these problems by using only intermediately  rated  sentences  (to avoid the ceiling, but  in the process  limiting the generality of the result), omitting mirrors from the initial judgment phase, and explicitly  telling  subjects to simultaneously  look at themselves  in the mirror and think about the sentences' grammaticality. Note that this is a much more explicit and forceful use of the mirror manipulation than the one used by \citeauthor{DuvalEtAl1972}  or \citeauthor{CarrollEtAl1981}.  Furthermore,  no significant effect of  self-awareness had been found for the before-repetition judgments  in the first experiment. Apparently this particular procedure is not as susceptible to self-awareness manipulations  as those others. This might be because judging  grammaticality  is more inherently  a structural task, as compared to judging  sentence similarity or truth. Despite  all this emphasis,  the OSA\is{objective self-awareness (OSA)} judgments  came out only marginally more lenient after repetition. A second follow-up experiment was done to rule out a potential confounding variable: it is possible that the division of subjects' attention between mirror watching and sentence pondering could have created ratings different from those of the SSA\is{subjective self-awareness (SSA)} subjects, independent of the fact that the competing activity was related  to self-awareness. Thus, Nagata\ia{Nagata, Hiroshi} gave subjects a simple arithmetic problem to solve as a distractor during the repetition phase, instead of mirror gazing, to see whether division of processing resources could account for the previous  finding. In this condition, there was no change in judgments  after repetition as compared to before, so division of attention \textit{can} nullify the repetition effect. However, there was no trend toward \textit{increasing} ratings, so to the extent that
such an effect is reliable, it cannot be explained by processing load alone: self-awareness must be considered.\footnote{This is not an airtight argument. Perhaps the arithmetic task, which involved subtracting 2 from an integer, was not as demanding as mirror gazing.}
%\textsuperscript{14}

\subsection{Judgment Strategy}\label{sec:5.2.5}

Nagata concludes from the preceding three experiments that, in judging grammaticality, SSA\is{subjective self-awareness (SSA)} subjects focus on syntactic and semantic structure, while OSA\is{objective self-awareness (OSA)} subjects look at pragmatic use. If this is so, then \citeauthor{CarrollEtAl1981}'s suggestion that linguists need to be in the OSA state seems misguided, at least for the purposes of judging grammaticality. But note that so far we have only circumstantial evidence concerning the actual strategies used. \citet{Nagata1989c} wanted to explore this by explicitly telling subjects what sort of strategy to use in making their judgments, rather than inducing a strategy indirectly with mirrors and such. If the two explicit strategies show the same respective effects as the mirror versus no-mirror conditions, we have suggestive (though not conclusive) evidence that the interpretation of those effects is on the right track. This experiment again used sentences of intermediate grammaticality, where the leniency effect of OSA had shown up. One group of subjects was told to ``analyze each sentential structure independently of sentential and/or situational contexts,'' and consider the parts of speech involved, during the repetition phase. The other group had to ``[supply] sentential and/or situational contexts to each sentence such that each sentence could be used in such contexts.''\footnote{It is not evident from Nagata's description whether these are exact translations of the instructions, or whether subjects were given more explanation. Even knowing the purpose of the experiment, I do not find this wording particularly clear.}
%\textsuperscript{15}
 The standard repetition paradigm was used, except that after the repetition phase subjects had to describe what they had been thinking, so the experimenter could be sure they followed the desired strategy. Those who did not had their results discarded. While the differentiation condition produced significantly more ungrammatical ratings after repetition, the enrichment group showed only a nonsignificant tendency toward leniency. Again, Nagata tries to explain why the expected trend did not reach significance: apparently the enrichment strategy is hard to use, and even the subjects who seemed to describe the appropriate thoughts might not have used it as
intended. But it is hard to see why subjects should use less of a strategy when explicitly told how to follow it than when it is induced indirectly by the mirror manipulation. This question casts some doubt on Nagata's interpretation of the OSA leniency effect. Perhaps the possibility that OSA\is{objective self-awareness (OSA)} affects reporting more than linguistic analysis is worth investigating further after all, if a more convincing demonstration of the change in judgment strategy cannot be made. As Bever's\ia{Bever, Thomas G.} epigraph at the beginning of this chapter suggests, there certainly is a lot we don't know about mirrors.

Nonetheless, some more general conclusions can be unequivocally drawn from Nagata's studies. First, it is clear that the details of the process of intuitive judgment cannot be ignored when using intuitions for theoretical purposes. On that point, I agree with \citeauthor{CarrollEtAl1981} as well as with \citeauthor{Nagata1989c}. More specifically, we can conclude that it is easy to make sentences get worse in people's judgments, but hard to make them get better. Given the stringency effect of repetition, we should expect linguists' judgments\is{linguist!as subject} to be more stringent than those of non-linguists,\is{linguist/nonlinguist differences} at least on sentences that they have studied in detail. I am not aware of any studies that have been done specifically on sentences that linguists have worked on extensively (but see \citet{Snyder1994}, discussed in \sectref{sec:7.2}). More general studies have differed as to whether linguists are more or less lenient than normals (see \sectref{sec:4.4.1}). I would still maintain that the influence of repetition is another valid reason why linguists' judgments should not be used as crucial theoretical evidence. With regard to where the effects of self-awareness come from, they seem to transcend language and thus fit the general description of a cognitive manipulation whose effects carry over into linguistic judgments. The repetition effect is more problematic in this regard, however. It runs contrary to basic habituation effects. In fact, I have not been able to find any parallel manipulations in other cognitive domains. If Nagata's suggestion is right, then the effects stem essentially from discerning more fine-grained properties of the stimulus through repeated considerations. If the effects are limited to the particular sentences used rather than to overall ratings, then this is \textit{not} a case of developing expertise, i.e., of increasing the ability to discriminate. Rather, a parallel effect would have to involve complex stimuli whose properties are not all apparent on first exposure, e.g., a complex geometric figure containing multiple subfigures that must be picked out. Finally, it is evident that psychological effects can interact in unpredictable ways, so that a complete understanding cannot be achieved merely by identifying each effect in isolation.

\subsection{Modality and Register}\label{sec:5.2.6}

\citet{VetterEtAl1979} were interested in the potential effects of modality of presentation\is{speech versus writing, effect on grammaticality judgments} and intonation\is{intonation!effect on processing and grammaticality judgments} on grammaticality judgments, although their main interest was with meaningfulness (see \sectref{sec:5.3.2}). They used five conditions for sentence presentation: visual presentation only, auditory presentation only, both presentations simultaneously, and the latter two modes with normal or monotone intonation. Interestingly, they found no overall effect of mode of presentation, although 16 of 60 particular conditions did show significant differences, which suggests to me that this variable is worth investigating more closely. But the basic result that intonation is not a factor echoes similar results in the domain of spoken surface-structure ambiguity resolution. Studies by \citet{Berkovits1981,Berkovits1982} have shown that intonation plays a very limited role in disambiguating such sentences, being easily overridden by the inherent bias of the sentence or the surrounding context unless a subject's attention is explicitly drawn to prosodic cues. (On the other hand, \citet{Hill1961} describes some cases where reading a sentence with normal intonation, as opposed to presenting it in written form, increased the number of acceptances. For reasons discussed in \sectref{sec:5.2.1}, his results should be taken very cautiously, however.)

The absence of any modality effect\is{speech versus writing, effect on grammaticality judgments} is at odds with the widely held belief that our judgment criteria are much stricter for written materials than for speech.\is{speech versus writing, effect on grammaticality judgments} (In line with this intuition, \citet{BialystokEtAl1985} argue that oral presentation stresses meaning, whereas written presentation more naturally elicits attention to structure.) However, the issue of register\is{register, effect on grammaticality judgments} is tied up in this as well. A formal\is{formality, effect on grammaticality judgments} speech would have to meet higher standards of grammaticality than a casual conversation. \citet{Greenbaum1977b} suggests that written questionnaires present a fairly formal\is{formality, effect on grammaticality judgments} context\is{questionnaire!formality of} for subjects, which might show up in sentence ratings  as a preference for the more formal of two alternatives if they are compared side by side. He also suggests \citep{Greenbaum1977c}
that the content of sentences could itself imply stylistic differences,\is{style, effect on grammaticality judgments} e.g., scientific versus literary, which could evoke differential treatment from subjects. Yet another confounding factor could be the degree of preparation.\is{spontaneous versus prepared production} Prepared text, whether spoken or written, can be freed of errors, whereas in spontaneous production speakers (or writers in certain circumstances) must be allowed some leeway in extricating themselves from grammatical culs-de-sac. \citet{Biber1986} has done an extensive factor analysis of dimensions along which various kinds of written and spoken language differ,\is{speech versus writing, effect on grammaticality judgments} by analyzing 545 text samples of 16
different types, ranging from telephone conversations to government documents. He arrives at three major factors that account for much of the variation on 41 linguistic features that have been suggested to reflect spoken/written differences. None of these factors correlates entirely with speech versus writing. The first factor, interactive versus edited text, separates texts with high personal involvement and real-time constraints from those that have highly explicit lexical content and where much editing is possible. The second factor, abstract versus situated content, reflects the degree to which the style\is{style, effect on grammaticality judgments} is detached and formal\is{formality, effect on grammaticality judgments} or concrete and colloquial. The third factor, reported versus immediate style, differentiates narrative about removed situations from present-tense description. Biber successfully uses these dimensions to reconcile the findings of numerous previous studies concerning spoken/written differences. One might approach the unraveling of these factors experimentally by using linked computer terminals that allow written communication with various speeds of transmission: instantaneous letter-by-letter, line-by-line, or complete messages (Graeme Hirst, personal communication).\ia{Hirst, Graeme} Whichever factor or factors determine one's degree of tolerance, we are then left with explaining how these various levels of grammaticality criteria are encoded in the mind: different grammars, different parsing rules, a reduced threshold on the same parsing rules, etc. I return to these issues in \chapref{sec:6}.

There are additional features of language that are related to register\is{register, effect on grammaticality judgments} to some extent and that \citet{Ross1979} speculates might have systematic effects on grammaticality judgments. These include clarity, awkwardness, slanginess, and floweriness. While these have likely been examined in a sociolinguistic context, I am not aware of any research looking for them as confounds where grammaticality was the property subjects were targeting. One might also expect that the modality of the subjects' response could show some effect of register. This idea was tested by \citet{DavyEtAl1969}, replicating some of \citegenp{QuirkEtAl1966} tests\isi{compliance tests} but using oral responses: subjects had to say the new version of the sentence, or answer judgment questions with ``yes,'' ``no,'' or ``can't decide.'' The results of the judgment tests closely paralleled those of Quirk \& Svartvik, with one notable exception. Davy \& Quirk's subjects gave many fewer middle responses. The authors suspect that this is not a register effect, but rather is due to the fact that ``can't decide'' has negative connotations, suggesting indecision on the subject's part, which the corresponding written response ``?'' lacked. Thus, it seems that response modality does not much influence judgments. However, a positive conclusion to come out of this study is that much information can be gained from verbal
responses. For instance, from the performance tasks the authors were able to gather data on subjects' hesitations, drawled segments, tempo, volume, pitch, and rhythm, which were useful in the analysis (although the interpretation is somewhat subjective), for instance, in finding the location of ungrammaticality within a sentence.\is{location of ungrammaticality!using subjects' intonation to determine}
 
\subsection{Speed of Judgment} \label{sec:5.2.7} 

\is{speed of judgment}Studies differ as to the amount of time subjects are given to make their judgments. In most cases, written questionnaires are self-paced, although they may also be speeded, i.e., subjects may be told to work quickly. Experiments using computer control (usually also measuring reaction time) may limit the amount of time a sentence is visible, and also limit the time available for judgment before the next sentence appears. This raises the issue of whether we want a subject's initial reactions to a sentence, or a carefully reasoned decision resulting from some amount of deliberation. Presumably these two kinds of judgments would differ, although the matter has not been much studied directly. \citet{Bialystok1979} found that changing the response time in a yes/no grammaticality judgment task from 3 seconds to 15 seconds did not affect the accuracy of responses by her nonnative learners of \isi{French}. \citet{Greenbaum1977c} cites unpublished work by  \citet{LegumEtAl1974} as finding that different judgments resulted from timed versus self-paced tasks, but gives no further details. A study by \citet{WarnerEtAl1987}, detailed in \sectref{sec:5.3.1}, found that context effects were attenuated by the delay in self-paced as opposed to on-line judgments. Also, I suggest in \sectref{sec:5.2.3} that prolonged consideration of a sentence might induce effects similar to those found in Nagata's repetition treatment.

Obviously, if our goal is to examine the on-line processing of grammaticality, its effects on parsing, and so forth, then first reactions will be most useful. But if it is the status of sentences that concerns us, it is not clear which should be preferred. One advantage to first impressions is that there is little time for the subject to consider (potentially irrelevant) extrasentential factors. In fact, subjects might be able to go into a mode in which they ignore such factors. \citet{Lachman1972} found this to be the case in judgments of meaningfulness. Specifically, she argues that subjects can reach a kind of understanding that falls short of full interpretation, involving only ``awareness of the potential for interpretation.'' In this mode, the time it takes subjects to give yes/no meaningfulness judgments does
%Chapter Five
not increase with ambiguous sentences, and is not reduced by supporting context, although these factors are known to affect the time subjects take when reading for comprehension. Quick judgments are also useful because, given enough time, subjects might find structural analyses that we would not want them to find. \citet{GleitmanEtAl1970} suggest an interpretation that someone with ingenuity could find for \citegen{MaclayEtAl1960} sentence \textit{Label break to be calmed about and} (see \sectref{sec:5.3.2}), which leads them to make a distinction between ``blithely accepts as grammatical'' versus ``after deep thought accepts as grammatical.'' In cases where initial reactions are desired, we need a methodology for getting them. The cost of computer-controlled experimentation can be prohibitive as compared to the cost of administering questionnaires, so some authors have tried to use the latter.\footnote{Jim McCawley (personal communication)\ia{McCawley, James D.} suggests that interesting effects might show up by using the inexpensive technology of videotape. His experience is that the discrepancies in time taken by different subjects to raise their hands in response to a sentence they are judging is large enough that frame-by-frame viewing would show clear differences.}
%\textsuperscript{16}
 (In fact, \citet{Greenbaum1977c} argues against the use of time-limited judgments anyway, since they fail to take account of individual differences in judgment speed.) For instance, the instructions in \citegen{Heringer1970} study (discussed in \sectref{sec:4.2}) told subjects to refrain from changing their response after the initial judgment or rereading sentences that had already been judged; \citet{Greenbaum1977b} told subjects not to turn back to previous pages in the questionnaire booklet, and to work as quickly as they could without being careless.

\section{Stimulus Factors} \label{sec:5.3}
\subsection{Context} \label{sec:5.3.1} 

\epigraph{\textit{Unhappily, the recurrent embarrassment of the generative grammarian is that his students and his critics are forever contriving situations in which the sentences he had needed to believe were ungrammatical turned out to be completely appropriate.}\\[-2\baselineskip]}{\citep{Fillmore1973}}

\noindent
\is{context effects}I agree wholeheartedly with \citet{Bever1970a} on the issue of context: ``A science of the influence of context on acceptability judgements is as necessary in linguistic research as in every other area of psychology'' (p. 347). First, however, we must set straight exactly what is meant by the term \textit{context}, which tends to be bandied about rather casually. While the common folklore holds that sentences usually sound better in context, we shall see that this really only applies to one of
the possible kinds of context. In this subsection I report on four types of context manipulation. First, I look at a few studies dealing with a context consisting of semantically or pragmatically related content. This is the most extensively studied of the four types, and I cannot hope to cover the entire literature here. One large subdomain that I systematically exclude is the area of discourse-dependent utterance forms such as ellipses, cross-sentential anaphora, etc. (see  \citet{vanDijk1977} for discussion). This seems a reasonable omission, because there do not appear to be too many interesting issues that bear on elicitation methodology. Obviously, if a sentence is dependent on prior sentences for coherence, they must be included when the sentence is judged. The second type of context I consider consists of paradigmatically related sentences; very little work has been done in this area. The same is true for the third type, which consists of the theoretical context under which linguists consider data. The fourth type of context, which seems to have the most insidious implications for grammaticality judging, is made up of structurally related sentences that can set up extraordinary contrasts or prepare us for later sentences.

\citet{Bolinger1968} prefaces his discussion of context effects by saying, ``it is worth a moment to consider how a normal sentence can come to be thought abnormal'' (p. 35; see also \citet{Bolinger1971}). By this he means that disembodying a sentence from its (semantico-pragmatic) context can make it appear unacceptable when in its original setting it was unexceptional. For the most part, the type of judgment he is concerned with is of semantic rather than syntactic well-formedness. For example, he assumes that \textit{I'm the soup} is ungrammatical in isolation. Nonetheless, some of his observations have implications for our study as well. For instance, a sentence heard out of context will tend to trigger dominant senses\is{lexical ambiguity, and context effects}\is{context effects!and lexical ambiguity} of the words it contains. Once a situation for the sentence as a whole is derived from these meanings, secondary senses are not likely to come to mind, even if they would make the sentence grammatical.\footnote{The example Bolinger gives is not a particularly good one. He claims that \textit{The girl was turned to} tends to be considered ungrammatical in isolation because the extended meaning of \textit{turn to} does not come to mind, but I do not have any trouble with this sentence.
}
%\textsuperscript{17}
 Situating sentences within a larger discourse (possibly by expanding a single sentence) also improves their acceptability by providing the motivation for marked constructions, such as the clefts in the following examples:

\ea[?]{It's a lawyer that he is.}
\z

\ea[ ]{It wasn't a lawyer that he wanted to be but a doctor.}
\z

%\originalpage{152} %  Chapter Five

\noindent
The low-bias reading of an ambiguous word\is{ambiguous word, and context effects}\is{lexical ambiguity, and context effects} or phrase can sound bad out of context, as in the following sentence when spoken:

\ea[?]{Never have too close friends.}
\z

\noindent
Along similar lines, \citet{BeverEtAl1976a} give the following example:
\ea
\ea[?]{The owner of the horse's steps were rapid.}
\ex[ ]{Because he was in a hurry to place a bet, the owner of the horse's steps were rapid.}
\z
\z

\noindent
See \sectref{sec:4.2} for the effect of this kind of context on quantifier-negative sentences.

This was the kind of context that \citet{Nagata1988} looked at as well (see \sectref{sec:5.2.3}). Recall that while it did cancel the effects of repetition, it made no significant difference to prerepetition judgments. He points out that, unlike his own materials, experimenters often specifically design their stimuli to be good only under a fairly obscure interpretation, which the context is then designed to bring out (see also \citet{GleitmanEtAl1970}). This assessment applies to some of the contexts used in \citegen{Heringer1970} study. For instance, he compared reactions to sentences like \REF{ex:5:6} with and without the bracketed context:

\ea\label{ex:5:6}
John left until 6 pm. [John left earlier and is going to come back at 6.]
\z

\noindent
While none of Heringer's 20 subjects accepted \REF{ex:5:6} without the context, 15 of 39 accepted it with context.\footnote{These numbers represent a pooling of subjects who answered ``acceptable'' or ``uncertain, but probably acceptable'' on the four-choice questionnaire. In explaining this analysis, Heringer\ia{Heringer, James T.} acknowledges that ``some people apparently use a stricter interpretation of acceptability than others, while what is of interest here is not absolute acceptability but relative acceptability with respect to other sentences'' (p. 291, fn. 5).\is{rating scale!interpretation of} There is also variability in the relative certainty of subjects, i.e., some will give many more ``uncertain'' responses than others. We must be extremely careful thinking about what information we are trying to extract from judgments, in choosing what to do with raw ratings.}
%\textsuperscript{18}
 It should not be surprising that context improves grammaticality under such conditions, but we cannot conclude from this that \textit{any} semantically coherent context\is{context effects!semantically related} will improve ratings. This was certainly not true for Nagata's contexts, which were appropriate to the target sentence but did not bring out any abnormal readings. Under these conditions, context apparently has no effect, perhaps because some default context is assumed when none is directly supplied \citep{DanksEtAl1971}.



\citet{Snow1975} refers to this type of context as paralinguistic context and suggests that it should always be supplied by the experimenter. We can reasonably expect that when subjects are asked to judge sentences in isolation, they might attempt to call up a suitable linguistic context. If we provide them with such a context instead of leaving them to their own devices, we will most likely find less variation in the resulting judgments. If we further assume that context cannot make a truly ungrammatical sentence seem acceptable (which is likely true for the vast majority of sentences), we are not biasing the outcome of the experiment by giving the sentence its best shot in this way (\citet{Householder1973} concurs). Furthermore, by testing the same sentence in multiple contexts, we can examine the grammatical and discourse factors that distinguish various readings.

\enlargethispage{\baselineskip}
Along the same lines, \citet{CrainSteedman1985} make the important point that a null context is not the same as a neutral context.\is{context effects!null versus neutral} Rather, the effect of not presenting subjects with an explicit context is that the actual context envisioned by them is not under the experimenter's control. They go on to argue that certain grammatical constructions, notably restrictive modification, are infelicitous in the
absence of context, and hence force subjects to do the work of constructing an appropriate context by adding necessary presuppositions to their discourse model in order to interpret the sentence. Their experiments involved a speeded grammaticality judgment task. One showed that reduced-relative garden path sentences\is{garden path sentence!effect on grammaticality judgments} are judged more grammatical when the subject is indefinite and hence (they argue) does not presuppose an already mentioned set from which certain members are being singled out. Sentences like (\ref{ex:5:7}b) below were judged grammatical significantly more often than their counterparts like (\ref{ex:5:7}a) in a yes/no task.

\ea\label{ex:5:7}
\ea The teachers taught by the Berlitz method passed the test.
\ex  Teachers taught by the Berlitz method passed the test.
\z
\z

\noindent
\citeauthor{CrainSteedman1985} also showed that the grammaticality rating of a particular sentence varied dramatically depending on whether a preceding context\is{garden path sentence!effect of context on}\is{context effects!semantically related} supported the presuppositions of the correct versus the incorrect parse. Either completion of a temporarily ambiguous sentence could be judged ungrammatical by at least half the subjects if the context favored the wrong reading. Example \REF{ex:5:8} illustrates the possible contexts and target sentences.

\ea\label{ex:5:8}
\ea       \textit{Complement-inducing  context}

A psychologist was counseling a married couple. One member of the pair was fighting with him but the other one was nice to him.
\ex  \textit{Relative-inducing  context}

A psychologist was counseling two married couples. One of the couples was fighting with him but the other one was nice to him.

\ex  \textit{Complement  target}

The psychologist told the wife that he was having trouble with her husband.

\ex \textit{Relative target}

The psychologist told the wife that he was having trouble with to leave her husband.
\z
\z


\citet{Pesetsky1987} demonstrates how context can interact with grammar in especially intricate and insidious ways. In particular, he shows that \isi{Superiority violation}s can be made to go away, or at least become less severe, if they are presented in a context that encourages the reader to interpret \textit{wh}-words as discourse-linked\is{discourse linking (D-linking)} (D-linked), that is, constrained by some previously established set of alternatives. Thus, although \textit{where} usually cannot follow \textit{what} in a double question, the following setup makes that possible:

\ea%9
    \label{ex:5:9}  
I know that we need to install transistor A, transistor B, and transistor C, and I know that these three holes are for transistors, but I'll be damned if I can figure out from the instructions \textit{where what} goes!
	 
\z

\noindent
In Pesetsky's account, D-linked \textit{wh}-words have different LF movement requirements than non-D-linked ones have. The relevant point for us is that the grammar is (argued to be) sensitive to a distinction in interpretation that can only be made relative to surrounding  context, so getting judgments to reflect the grammar in this respect requires careful control of context. Here, as with Crain\ia{Crain, Stephen} \& Steedman's examples, it is insufficient to control for or eliminate context effects on judgments.
We must consider the effects of particular types of context that the grammar is sensitive to. 


Let us turn now to paradigmatically related contexts,\is{context effects!paradigmatically related} by which I mean sentences that fill a parallel role in a paradigm. This can best be seen with an example. One finding of \citet{Hill1961} that probably would hold up under more controlled conditions is that a more structured design (as compared to individual sentence judgments) produces a reduction in interspeaker variation. Hill's experiment involved presenting several sentence groups following the same paradigm, as in \REF{ex:5:10} and \REF{ex:5:11}:

\ea\label{ex:5:10}
The plate is hot. The plate seems hot. The plate seems very hot.
\z

\ea\label{ex:5:11}
The child is sleeping. The child seems sleeping. The child seems very sleeping.
\z

\noindent
In this example, \textit{The child seems sleeping} would presumably be the target sentence of interest. It is surrounded in \REF{ex:5:11} by two sentences that are related to it in a way that is parallel to the relations among the sentences in \REF{ex:5:10}. This allows subjects  to see where the sentence came from by analogy to an unequivocally  good sentence. Apparently  this procedure helps them to focus on the relevant features of the sentence. This type of parallel analysis is certainly common in linguistic argumentation,  but  no one else seems to  have  used  it in studying the judgment process itself. In cases where it is feasible, it might prove to be a useful tool. (Recall a related finding by \citet{ScottEtAl1973}, reported in \sectref{sec:3.3.3}: viewing all the rearrangements  of a sentence together  increases grammaticality  ratings.)

\citet{Spencer1973} mentions a type of context made up of ``the set of rules for which [a] sentence is an exemplar.'' \citet{Snow1975} seems to mean something similar by the ``context of discourse,'' which she defines as the linguistic issue on which a sentence bears.\is{context effects!determined by theoretical issue} In both cases, such context is relevant only to linguists\is{linguist!effect of theoretical context on}, and might actually be entirely implicit, without mention in the materials themselves. For instance, certain examples become closely associated with particular theoretical proposals or disputes by virtue of repeated discussion or published citations, e.g., Chomsky's\ia{Chomsky, Noam} \textit{Colorless green ideas sleep furiously}. Spencer seems to suggest that when a linguist's initial intuitions about a sentence fail to conform to the context (presumably this means they contradict the theory), the sentence is reorganized to bring the intuition in line\is{linguist!effect of theoretical context on} (see \sectref{sec:4.4.1}). Unfortunately, her experimental results do not show this in any direct way, and it is in fact hard to imagine a conclusive demonstration of this effect, so it must remain as intriguing speculation for the time being.

Now let us focus on the effects of the fourth kind of context, namely the neighboring stimulus\is{context effects!surrounding stimuli} sentences displayed for judgment. It has been common folklore among linguists that marginal sentences can be made to seem more acceptable when preceded by much worse examples and less acceptable when preceded by much better ones (see, e.g., \citet{Snow1975}, who calls this the context of judgment, and \citet[vol. 3]{Levelt1974}). \citet{Bever1970a,Bever1974} might have been the first to make this explicit, in connection with the law of contrast\is{contrast effects} from psychology:

\begin{quote}
One's ``absolute'' judgement of a stimulus can be exaggerated by the difference between the stimulus and its context. This influence by contrast clearly can occur in ``intuitions'' about grammaticality. For example, [(\ref{ex:5:12}b)] preceded by [(\ref{ex:5:12}a)] may be judged ungrammatical, but contrasted with [(\ref{ex:5:12}c)] it will probably be judged as grammatical. \citep[346\textendash{}47]{Bever1970a}
\end{quote}

\ea \label{ex:5:12}
\ea
Who must telephone her? 
\ex Who need telephone her? 
\ex Who want telephone her?
\z
\z

\noindent
Bever describes an analogous effect in color perception:\is{grammaticality judgments!parallels to perception} a pale green spot might appear blue when surrounded by a yellow field, but appears green if surrounded by a red field. (Although the examples in \REF{ex:5:12} are very closed related, \isi{contrast effects} can be found with unrelated stimuli; see the discussion of \citet{Snow1975} below.) To test the hypothesis for linguistic context, Bever\ia{Bever, Thomas G.} proposes taking a number of sentences  from linguistics articles and presenting them in two different orders to two groups for judgment. One group would see them in their original order as they appeared in the source publications, while the other group w.ould see them in random order. Bever\ia{Bever, Thomas G.} predicts that the former group would come much closer to the published judgments than would the latter group. \citet{Spencer1973}, as part of the study described in \sectref{sec:4.4.1}, did exactly that. In one condition the order of sentences\is{order of presentation (of sentences)!effect on grammaticality judgments} was completely randomized, while in the other they appeared in their originally published order (the order of the articles was randomized). Unfortunately, the results are reported in the same vague manner as her comparison of naive and nonnaive subjects. We can see that the mean number of sentences accepted by the two groups differed by almost 6\%, but we know nothing of the significance of this difference or to what extent the distribution of good and bad ratings differed for the two groups.

\citet{Greenbaum1976a} performed an experiment that made the same point.
The crucial sentences exemplified various uses of the verb \textit{dare}:

\ea\label{ex:5:13} 
We didn't dare answer him back.
\z

\ea\label{ex:5:14} 
We dared not answer him back.
\z

\ea\label{ex:5:15} 
We didn't dare to answer him back.
\z

\noindent
Two of the three sentences appeared together on one page of the experimental booklet, and subjects were implicitly encouraged to compare the two by having to
rank which was better, in addition to rendering absolute judgments on the following scale: ``perfectly natural and normal''; ``wholly unnatural and abnormal''; ``somewhere between''; and ``not sure.'' Sentence \REF{ex:5:15} showed a significant change in absolute rating\is{absolute rating (of acceptability), versus relative ranking}\is{ranking versus absolute rating (of acceptability)} depending on which of the other two sentences it was paired with:\is{context effects!surrounding stimuli} it was judged much better alongside \REF{ex:5:14} than \REF{ex:5:13}. Among the latter two sentences, \REF{ex:5:13} was rated significantly better overall. That is, greater contrast\is{contrast effects} produced polarization of the results. Seeing the better alternative, subjects judged \REF{ex:5:15} even worse. This confirms the prediction made by \citet{Bever1970a}, although the results would be more convincing if they could be replicated without any explicit suggestion that subjects should compare the adjacent sentences. Greenbaum's conclusion is that closely related sentences should be presented for judgment as a group, with ordering counterbalanced across subjects, because he believes that in the absence of comparable sentences provided by the experimenter, subjects might try to think up their own related items, so that intersubject differences in ratings could be related to differences in their ability to make such inventions. (This parallels Bolinger's\ia{Bolinger, Dwight L.} point for semantic contexts.)

\citet{Snow1975} conducted an experiment that demonstrated \isi{contrast effects} with unrelated sentences. Her test consisted of alternating target and filler sentences. In one condition all the fillers were clearly grammatical, in the other they were clearly awful. Subjects judged acceptability on a yes/no basis. Although no statistical analysis of the raw data is reported, there was clearly a substantial shift in judgments between the two groups: 18 of the 20 target sentences were accepted by more subjects when surrounded by bad fillers, showing a mean increase of 11.7\% in the number of subjects who accepted them. The most dramatic example showed a 32\% increase. \citet{Nagata1992} reports a similar finding. As \citet{CardenEtAl1981} put it, ```ungrammatical' often should be interpreted as `clearly worse than the ``good'' examples [a sentence] is being compared to' (p. 589).
They describe a data disagreement\is{data disagreements} over \isi{backwards coreference}\is{Binding Theory!and interspeaker variation}\is{interspeaker variation!on Binding Theory} constructions such as \textit{I knew him when Harvey was a little boy}, where \textit{him} and \textit{Harvey} are taken as coreferential (see \sectref{sec:1.3}). A linguist who claims the sentence is bad pairs it with a clearly good example, and vice versa. Carden\ia{Carden, Guy} \& Dieterich\ia{Dieterich, Thomas} argue that both good and bad related sentences should be presented for subjects' consideration. Beyond an absolute shift in assigned grammaticality, Cowart (\citeyear{Cowart1994}, \citeyear[22--27]{Cowart1997}) designed a
set of experiments to explore the question of whether this kind of context manipulation would affect the \textit{relative} status of sentences. His two conditions involved interspersing among actual linguistically interesting examples a group of
filler sentences that were either all quite good or in which one-third of the sentences were awful. As in the previous studies, with bad fillers around subjects gave significantly higher ratings overall to the experimental sentences. However, the \textit{pattern} of results among these sentences was not affected at all by this manipulation. In particular, it was not true, as one might have expected, that those who saw very bad fillers would be less sensitive to subtle differences among the experimental sentences. Thus, if we limit ourselves to relative comparisons, the goodness or badness of filler sentences might not be very important.

The results of some experiments by \citet{WarnerEtAl1987} bear on the effects of context by both structural\is{context effects!structurally similar sentences} and semantic relatedness.\is{context effects!semantically related} Their main goal was to examine the processing of garden path sentences,\is{garden path sentence}\footnote{The authors use the term \textit{garden path}\is{garden path sentence} to refer to all sentences with temporary ambiguities, regardless of whether people actually tend to fail on their first parse of them.}
but what surfaces as well is a striking case of judgments not reflecting the underlying grammar, because a majority of subjects judged sentences bad that are uncontroversially grammatical. The authors' design allowed them to measure the  effects  of  two kinds of context sentence:\is{garden path sentence!effect of context on} those that were structurally similar to the target garden paths and those that were semantically related. Since garden path sentences can mislead the reader by virtue of temporary ambiguities, context sentences could either help or hinder their parsing, by priming either the correct or the misleading choice at the point of ambiguity. Where positive bias was induced, we find examples of the type Nagata\ia{Nagata, Hiroshi} mentioned: sentences that would probably be judged bad unless subjects were directed toward the necessary situation or structural analysis. Below are examples of the four possible relations between context and target. In each pair, the first (context) sentence is unambiguously parsable and grammatical, while the second (target) sentence is a garden path:

\largerpage

\ea\label{ex:5:16} 
\textit{Syntactically related, positive  bias:}
\ea  When the girl sleeps the cat eats.
\ex  When the boys strike the  dog kills.
\z
\z

 
\ea\label{ex:5:17} 
\textit{Syntactically  related, negative bias:}
\ea
If the girl pets the cat she sings.
\ex
When the boys strike the dog kills.
\z
\z

\ea\label{ex:5:18} 
 \textit{Semantically  related, positive  bias:}
\ea
The cat attacks because the boy harms the man.
\ex
While the boy kills the man the cat strikes.
\z
\z

\ea\label{ex:5:19} 
 \textit{Semantically  related, negative bias:}
\ea
The boy attacks when the man is hurt by the cat.
\ex
While the boy kills the man the cat strikes.
\z
\z

\noindent
Their first experiment elicited speeded grammaticality judgments\is{speed of judgment} and found\linebreak there was a significant main effect of context.\is{garden path sentence!effect of context on} Sentences preceded by positive-bias context received an average 87\% rating, while those with negative-bias context received only a 65\% grammaticality rating. There was no significant  difference between syntactic and semantic contexts. However, a subsequent self-paced judgment task showed no context effects in most cases. The authors suggest that this change is attributable to the relative speed of judging.\is{context effects!and speed of judgment} At their own pace, subjects would not be reaching final judgment decisions until much longer after reading the context sentences. Thus it appears that context-induced priming is a fleeting phenomenon, which might account for some of the discrepancies in the literature. Interestingly, in the absence of any biasing context, the class of garden paths that are hardest to process (namely, those requiring an intransitive reading of a transitive verb and with a delayed resolution of the ambiguity, such as \textit{Before the boy kills the man the dog bites strikes}, were judged grammatical 25\% of the time, or only as often as ungrammatical control sentences (e.g., \textit{Who is strong killed that strike men}).\is{garden path sentence!effect on grammaticality judgments}\footnote{Many of these potential garden path\is{garden path sentence} sentences normally require additional punctuation. Nonetheless, Warner \& Glass\ia{Warner, John}\ia{Glass, Arnold L.} did not include it in their materials.\is{punctuation!omission of} See \citet{FrazierEtAl1982} for an attempt to justify this common methodology. See \citet{MitchellEtAl1985} for evidence that adding the appropriate punctuation significantly changes the processing of such sentences. The latter result does not invalidate the conclusion that context can affect parsing (interacting with other cues), but we must be cautious in our conclusions about the status of an incorrectly punctuated sentence.
}
%\textsuperscript{20}
 Apparently, people either are not very persistent or not very creative in looking for alternative parses, because this result held up in the self-paced experiment as well.

\citet{Milne1982} presents both anecdotal and quantitative evidence corroborating this finding for other kinds of garden paths.\is{garden path sentence} For instance, when asked to judge whether \textit{The prime number few}  was a complete sentence or only a fragment, all 47 of his subjects thought it was a fragment. In a timed comprehension task, \textit{The horse raced past the barn fell} took an average of 10.13 seconds to read, with many   subjects still reporting they had not understood  it after that period. \citet{Bever1970b}   hypothesizes that such reduced-relative\is{garden path sentence!reduced relative}  sentences would be parsed
much more readily if an example pair consisting of full and reduced versions of a sentence were presented first,\is{garden path sentence!effect of context on} and \citet{Matthews1979} reports such a result on a judgment  task,  although  he  gives  no  quantitative  data. Thus,  methodological
caution is advised. If we suspect that the specific reading of a sentence that we want to test is hard for human parsers to arrive at,\is{parsing!effect on grammaticality judgments} independent of whether it is grammatical, we should make every effort to ensure that subjects think of the right reading. Otherwise, rejections on the basis of ungrammaticality are confounded with those based on never having ``found'' the sentence in question.\is{garden path sentence!failure to parse}

The main conclusion from these studies of context is that it does not make sense to speak of \textit{the} effect of context on judgments, because the type of context and its relation to the sentences in question must be considered. Context can be used to make sentences look better or worse than they appear in isolation; whether this is desirable will depend on the goals of particular investigations.

\subsection{Meaning}\label{sec:5.3.2} 


The earliest study that I am aware of that looked specifically at the nature of linguistic intuitions as expressed in judgments about sentences was done by \citet{MaclayEtAl1960}. They were specifically interested in the extent to which subjects could judge grammaticality independent of meaningful content\is{grammaticality judgments!versus judgments of meaning} and likelihood of occurrence,\is{grammaticality judgments!versus judgments of likelihood of occurrence} so they asked subjects whether each stimulus sentence was grammatical, meaningful, and ordinary.\is{meaning!effect on grammaticality judgments} (By the latter term they meant ``occurring with high frequency,'' so that this portion of the study might belong in \sectref{sec:5.3.4}, which deals with frequency; but since it is not clear whether their subjects interpreted it this way, I keep the main discussion together.) Unfortunately, they apparently did not give subjects any further explanation as to the intended meanings of these terms, and some of their results clearly show that at least some subjects did not take the desired interpretation. One good feature of this procedure, however, is that it allows subjects to voice opinions on these issues separately. If people feel a sentence is meaningless or has no chance of occurring in natural speech, they will want to convey this opinion. If they are not asked specifically for the information, they will likely allow it to affect their responses on other matters, such as grammaticality (Elizabeth Cowper, personal communication)\ia{Cowper, Elizabeth}. The experimenters had designed the sentences to represent various combinations of the three dimensions, e.g., grammatical but not meaningful and not ordinary. In addition, one group of grammatical sentences contained deliberate violations of ``grammar school'' rules, e.g., incorrect uses of \textit{I/me}, that do occur in casual speech and ought (according to Maclay \& Sleator) to be generated by a linguistic grammar.\is{meaning!effect on grammaticality judgments}


Sentences were presented orally with normal  intonation.\footnote{It is not clear to me how the strings of word salad could be read with normal intonation; a standard contour would have to be placed arbitrarily over the words.}
% \textsuperscript{21}  
For  sentences  that were intended to be grammatical but not meaningful or ordinary (e.g., \textit{Colorless green ideas sleep furiously}), significantly more subjects said ``yes'' to the grammaticality question than to the other two questions. Maclay \& Sleator take this as evidence that subjects were making the intended distinctions and judging grammaticality independent of the other two variables (but see below). Across all the sentence types and all three rating criteria, the relative ratings conformed to prior classifications. Positive instances got a greater percentage of ``yes'' responses than noninstances. However, the absolute numbers were less convincing. The aforementioned grammatical-nonmeaningful-nonordinary sentences received only  a 50\% grammatical rating, as did those that violated only the \isi{prescriptive rules}.\footnote{\citet{BradacEtAl1980} also looked at errors of ``school grammar,''\is{prescriptive rules} but found most subjects oblivious to them.}
%\textsuperscript{22}
 The other absolute numbers were similarly disappointing, often indicating approximately neutral ratings on average for all three criteria. From their lack of clear-cut outcomes, the authors conclude that there is no empirical basis on which to classify sentences as grammatical versus ungrammatical, or even into multiple discrete levels of grammaticality,\is{acceptability!number of levels distinguishable} and that we must be content with comparative rankings only. Why they discount the latter possibility without attempting to elicit multivalued ratings is not clear to me. But perhaps the most telling part of their conclusion is the admission that 3 of their 21 subjects said that \textit{Label  break  to calmed about and} was grammatical. Furthermore, \citet{QuirkEtAl1966} point
out that this 14\% acceptance rate compares with 19\% acceptance for \textit{Nor if I have anything to do with it}. Since these were all native speakers of English, they clearly were not applying grammaticality in the intended way, and so the experimental results do not represent a unitary phenomenon.

\citet{VetterEtAl1979} performed a follow-up to Maclay \& Sleator's experiment, because they felt that the latter authors did not have statistical justification for the claim that grammaticality was being judged independently of the other two variables. Their new experimental design allowed for the direct assessment of such claims. They used the same 36 stimulus sentences as
Maclay
and Sleator, but made a small attempt to improve the instructions. For instance, in one condition subjects were asked, ``Is this word sequence grammatical? In other words, is it acceptable English?'' These instructions still leave a lot of room for
interpretation and in this experiment we have direct evidence concerning how the
subjects tried to perform the various discriminations. But first, let us look at their results. As in the previous study, an ANOVA showed a significant effect of type of sentence\schdash{}grammatical versus meaningful versus ordinary\schdash{}but \citeauthor{VetterEtAl1979} correctly point out that such a finding is difficult to interpret because these do not represent values on a single dimension.\is{meaning!effect on grammaticality judgments} Pair-wise chi-square tests of independence showed that in some of the conditions grammaticality and ordinariness were significantly related, whereas in other conditions meaningfulness and ordinariness were related. Thus, this study contradicts the earlier claim and suggests that these factors do influence each other. Other results largely replicated those of Maclay\ia{Maclay, Howard} \& Sleator\ia{Sleator, Mary D.}. Sentence groups that were supposed to differ only on grammaticality did show a significant difference on that parameter, and similarly for the other variables. Once again, however, the most definite conclusion we can draw from this study is that much more work is needed on conveying\is{instructions to subjects} to all subjects the same notion of grammaticality, as evidenced by the following remarks from the study's high-school-aged subjects regarding how they decided whether a sentence fit the criteria. For grammaticality, they considered punctuation, making sense, whether the sentence was ``smooth,'' and ``what I learned in elementary school about correct grammar''; for meaningfulness, they considered ``pausing and  verbalization,'' ``if words could be  rearranged to make sense,'' whether the ``order of words seemed similar to reverse order in \isi{German},'' and whether it was ``true or something that could happen'';\is{truth of sentence, effect on grammaticality judgments} for ordinariness, they considered that ``word order inverted was ordinary, since it's natural in \isi{French},'' answered ``yes'' if the sentence ``didn't make sense but had normal subject and verb order,'' and factored in ``the way the words were typed.''\footnote{There were also a few responses that seemed to bear some resemblance to the desired interpretation of the terms.}
%\textsuperscript{23}
From these reports it is clear that the ratings could not represent anything approaching a unitary phenomenon, a fact that might invalidate all the other conclusions of the experiment anyway.

Let me  briefly review some other experiments on meaning and grammaticality.\is{meaning!effect on grammaticality judgments} \citet{DanksEtAl1970} looked at grammaticality, meaningfulness, and ordinariness, plus familiarity, in conjunction with data used by \citet{Coleman1965};
see \sectref{sec:3.3.3}. They asked subjects to rate sentences on one of these dimensions using a 10-point scale; none of the terms was defined for them. They found that \textit{familiar} and \textit{ordinary} were treated the same by subjects. By principal
components analysis, meaningfulness and familiarity were not independent, but meaningfulness and grammaticality were. \citet{Coleman1965} performed a statistical analysis on \citegen{Hill1961} data and found that 86.6\% of his meaningless sentences were judged grammatical (significantly more than chance), from which Coleman infers that Hill's subjects were able to distinguish these two dimensions. \citet{Moore1972} (see \sectref{sec:3.3.2}) reports a case where the existence of a metonymic or metaphoric reading\is{metaphoric and metonymic readings, effect on grammaticality judgments} of a literally ungrammatical sentence might have contributed to its being rated significantly higher than other structurally identical ones, which could be viewed as a meaning confound. The sentence in question was \textit{College students read many professors}, which supposedly violates selectional restrictions on the verb \textit{read}. But, as Moore correctly and humorously points out, ``A college professor may be read in the sense that Plato is read; alternatively, professors may have such transparent neuroses that they are easily `read' by their students'' (p.~558). It might also be true that meaning and meaningfulness affect the difficulty of performing grammaticality-related tasks. For instance, \citet{RyanEtAl1984} suggest that more cognitive control\is{cognitive control, as component of language skill} is required to correct a grammatical error\is{ungrammatical sentence, correction of} in a false sentence than in a true one,\is{truth of sentence, effect on grammaticality judgments} in order to ignore its falsity. \citet{Bialystok1986} claims that judging an ungrammatical meaningful sentence takes more analyzed knowledge,\is{analyzed knowledge, as component of language skill} whereas judging a grammatical anomalous one takes more cognitive control.\is{cognitive control, as component of language skill}  As evidence for the latter claim, she shows that bilingual children (who are claimed to have superior cognitive control skills) perform better than monolinguals on this kind of item.

\subsection{Parsability}\label{sec:5.3.3} 

\is{parsing!effect on grammaticality judgments}\is{parsing!versus grammar}To the extent that the human parsing mechanism does not accept precisely the same set of sentences as the grammar, we should expect that cases where the parser fails might be taken as unacceptable, even if upon further consideration we feel that they are 
grammatical \citep{ClarkEtAl1974}.\footnote{The reverse does not strike me as very likely, i.e., just because a string is easy to parse does not make us consider it grammatical; but see \sectref{sec:2.2} for some pathological cases.}
%\textsuperscript{24}
This is perhaps the most obvious case where \isi{speed of judgment} would be expected to make a large difference in judgments, since the parser might take a while to process a difficult sentence, e.g., the garden paths\is{garden path sentence} used by \citet{WarnerEtAl1987}; see \sectref{sec:5.3.1}.
Once we discover their intended structure, we agree that they must be grammatical, but due to parsing failure our initial judgments tend to be negative.\is{garden path sentence!effect on grammaticality judgments} \citet{VanKleeck1982}
suggests that sentence length and complexity will affect judgments. To this I would add any other factors that might make a sentence hard to parse, such as multiple center-embedding\is{center-embedding, multiple} or the serial position of an error;\is{position of violation in sentence, effect on grammaticality judgments} on the latter, see \sectref{sec:3.3.3} for a relevant experiment by \citet{Marks1967}. Finally, parsability is closely related to correctability,\is{correctability of ungrammatical sentence} also discussed in \sectref{sec:3.3.3}: the closer a bad sentence is to satisfying all the parser's constraints, the easier it will generally be to correct.

\subsection{Frequency}\label{sec:5.3.4} 

Another possible factor in judgments is the frequency\is{frequency, effect on grammaticality judgments} of occurrence of the stimulus materials. This could be taken in at least two ways, to refer to the frequency of the lexical items in the sentences, or of the sentence structures themselves. I am not aware of the former having been studied, but \citet{Greenbaum1976b,Greenbaum1977b} looked at the latter.\footnote{Note that his measure of frequency was subjective (i.e., people's judgments of it) rather than objective, as might be obtained by corpus analysis.
}
%\textsuperscript{25}
His experiments involved judgments on closely related sentence pairs such as active/passive and dative movement contrasts. In the first phase, subjects (who were linguistically naive) had to judge the sentences' ``overall frequency\is{frequency, effect on grammaticality judgments} in the English Language'' on a 5-tiered scale from ``very rare'' to ``very frequent.'' In the second phase, which occurred a week later, the same subjects were asked to rate the \textit{acceptability} of the same sentences, again on a 5-tiered scale, from ``completely unacceptable'' to ``perfectly OK.'' Greenbaum compared mean numeric scores across 87 subjects and found that, for each sentence, the acceptability rating was within one point of the frequency rating. (In most cases, acceptability was rated higher than frequency.) On the surface, this suggests that the two ratings are highly correlated, but no statistical tests were carried out and there is a potential confound in the experimental procedure. We do not know if subjects were aware that they were supposed to be judging something completely different the second time. They might have taken the instructions as merely a variation in wording of the original procedure. (This possibility could easily be tested using a between-subjects design.) To the extent that the aforementioned results of  \citet{VetterEtAl1979} have any validity, their finding that grammaticality was not independent of ordinariness points in the same direction. Greenbaum also examined the data on a subject-by-subject basis, finding that while identical ratings on the two scales were relatively rare, ratings
within one point of each other occurred for 88\% of the sentences among 65\% of the subjects. By this measure there was also reasonable consistency in the relationships between the ratings for the members of a related pair of sentences. Whichever of the two was rated more frequent\is{frequency, effect on grammaticality judgments} (e.g., the active version) would be rated more acceptable by half of the subjects in 64\% of the cases. If Greenbaum's interpretation is correct, we must be wary of grammaticality judgments on very obscure types of sentence constructions, which might reflect their infrequent nature despite their grammaticality. Following one of my earlier suggestions, a way to reduce this effect might be to allow subjects a separate frequency rating when judging acceptability, so that they can express this intuition and perhaps factor it out of the other judgment.\is{frequency, effect on grammaticality judgments} This is presumably what Maclay \& Sleator were trying to do with their ordinariness scale, although the meaning of the term was probably obscure to most subjects. We must also keep in mind, however, that Greenbaum has only shown a correlation between perceived frequency and acceptability, with no evidence about causality.

Some other interesting results were by-products of the fact that sentences were presented in related pairs such as active/passive. In general, across various other constructions, actives are judged more acceptable than passives (no analysis of significance was done by Greenbaum). Such a bias must be taken into account in other analyses. In \chapref{sec:2}, for example, I cited an instance where the fact that the active and passive versions of a sentence were equally marginal formed part of a theoretical argument (example \REF{ex:2:8}, \sectref{sec:2.3.3}). Of course, no experimental data had been used, but if they were, the general bias against passives would probably cause the result not to hold up, and yet this difference would have nothing to do with the particular theoretical issue involved. Other general biases were found as well, e.g., favoring present perfects over simple past tenses with both durative and iterative events, and subjunctives over indicatives and modals in subordinate clauses of demand or persuasion. The lesson for linguists is that whenever we rely on a nonminimal contrast, we should separately test each of the component minimal contrasts as well, to determine which one is responsible for the difference in acceptability.

\subsection{Lexical Content}\label{sec:5.3.5} 

\citet{LeveltEtAl1977} wanted to bring home the point that the particular lexical items chosen to make up an example sentence could affect grammaticality\is{lexical items, effect on grammaticality judgments}
%\originalpage{166} %  Chapter Five
ratings even when, from a normative point of view, the full range of words should all result in a grammatical utterance. The particular feature of lexical items they investigated was the imagery content\is{imagery content of words (concrete versus abstract)} of compound words in \isi{Dutch}, by which they meant the extent to which they were concrete as opposed to abstract, and hence more easily imaginable. (This idea was inspired by phenomenological reports of subjects performing judgment tasks by trying to imagine a situation in which the phrase in question could be said.) Reaction time was measured as grammaticality ratings and paraphrases of novel Dutch compounds (not complete sentences) were elicited. The purpose of avoiding lexicalized compounds was to encourage computation of a rating, rather than the use of lexical look-up. The basic prediction of Levelt et al.,\ia{Levelt, Willem J. M.} that the facilitation effect of imagery would show up in these judgments, was confirmed. More easily imaginable compounds were rated significantly more grammatical and judged and paraphrased faster than ones that were harder to imagine,\footnote{The imagery content of compounds was assessed in a pretest where other subjects reported how easily the expression lead to mental images of things or events.}
%\textsuperscript{26}
 supporting the notion of search for interpretation as (part of) the decision procedure. (The results for \isi{speed of judgment} are confirmed by results in \citet{GrantEtAl1977}.)
 The additional twist, however, was that imagery showed a much greater effect on reaction time for paraphrasing than for judging grammaticality. Levelt\ia{Levelt, Willem J. M.} et al. considered two explanations. First, perhaps imagery is involved in the task of generating a paraphrase, as well as in comprehending the original sentence. They consider this unlikely, for reasons not given. Second, perhaps it is the grammaticality judgments that do not require full imagistic search. That is, once a preliminary check (involving some imagistic component) succeeds, the compound does not need to be fully processed or understood before being judged as good (see the discussion in \sectref{sec:5.2.7}). As the authors suggest, this could be tested by timing a task that requires full interpretation but does not involve paraphrase, such as verification (truth judgment). Whichever explanation is correct, we have another case of a supposedly irrelevant variable influencing judgments of grammaticality. \citet{McCawley1985} views this as an instance of inaccurate \textit{reporting} of judgments,\is{grammaticality judgments!inaccurate reporting of} i.e., the subjects think they are reporting on grammaticality, but really they are reporting their (degree of) success in imagining\is{imagining situations, and grammaticality judgments} a context.

\largerpage
Another of \citegenp{Greenbaum1977b} experiments examined the effects of lexical substitution by comparing acceptability ratings between two instances of the
same sentence structure that differed only on certain lexical items. (He does not give a large range of examples, but the intent seems to have been that these substitutions could reasonably be expected to have no grammatical implications.) Again, judgments were on a 5-point scale. For 27 of 50 sentences at least half of the subjects gave identical ratings to the two variant sentences, and on 47 out of 50, 70\% of subjects were within one position on the scale of their initial judgment. Variants were presented in separate parts of the questionnaire so that memory for the previous rating would be extremely unlikely, and subjects were explicitly told not to try to remember their earlier ratings. Thus, this effect seems to be fairly small.

\subsection{Morphology and Spelling}\label{sec:5.3.6} 

\citet[407]{LangendoenEtAl1973} claim that there are acceptability differences that depend on the transparency of morphology\is{morphology, effect on grammaticality judgments} in cases where a pronoun later in the sentence refers to an implicit morphologically related word, e.g., in the contrast between \REF{ex:5:20} and \REF{ex:5:21}:
\begin{quote}

\ea[?]{\hspace*{-.7mm}Flutists are strange: \textit{it} doesn't sound shrill to them.}\label{ex:5:20}\z

\ea[*]{\hspace*{-.7mm}Flautists are strange: \textit{it} doesn't sound shrill to them.}\label{ex:5:21}\z
\end{quote}
 
 \noindent
They claim that \REF{ex:5:20} is more acceptable than \REF{ex:5:21} because \textit{flute}, the implicit antecedent of \textit{it}, is more obviously part of \textit{flutists} than of \textit{flautists}. Unfortunately, they do not cite actual data on this point; they might simply be expressing their own intuitions. To my ear, both sentences are equally (quite) bad, but if such a result should be found systematically, it would constitute another factor to be taken into consideration. (See \citealt{Smith1981} for the argument that the pragmatic principles that Langendoen\ia{Langendoen, D. Terence} \& Bever\ia{Bever, Thomas G.} propose should not be able to save truly ungrammatical sentences from unacceptability.) Some researchers (e.g., \citealt{Birdsong1989}) have cited this paper as showing that variant \textit{spellings} cause changes in acceptability ratings, but Langendoen\ia{Langendoen, D. Terence} \& Bever\ia{Bever, Thomas G.} make no mention of spelling, which is confounded with pronunciation in this case. Still, it would not be surprising to find acceptability differences between alternate spellings\is{spelling, effect on grammaticality judgments} of identically pronounced variants, e.g., \textit{night} versus \textit{nite}, triggered by relative frequency\is{frequency, effect on grammaticality judgments} in the dialect\is{dialects (idiolects)} of the subject. I am not aware of this issue ever having been studied. A
%\originalpage{168} %  Chapter Five
complementary point is made by \citet{Hill1961}: before people can judge a sentence, they must first identify all the morphemes in it, but the presence of a normal intonation contour can lead one to interpret apparently familiar morphemes as novel ones. For instance, the sentence \textit{I saw a fragile of}, read with declarative intonation, leads speakers to think that there is a novel noun \textit{of}, rather than identifying \textit{of} as the familiar preposition. This can lead them to judge bad sentences good unless they are informed that ``all the words will be familiar,'' or some equivalent statement.\is{intonation!effect on processing and grammaticality judgments}

\subsection{Rhetorical Structure}\label{sec:5.3.7} 

\citet{Langendoen1972} claims that some apparent cases of ungrammaticality may be explained by what he calls rhetorical factors, such as particular readings of elliptical sentences:\is{gapping construction}

\ea\label{ex:5:22}
\ea Mary takes Nancy seriously, but Ollie lightly.
\ex Mary takes Nancy seriously, but Ollie takes Nancy lightly.
\z
\z

\ea\label{ex:5:23}
\ea Mary takes life seriously, but Ollie lightly.
\ex Mary takes life seriously, but Ollie takes life lightly.
\z
\z

\noindent
According to Langendoen, people judge that (\ref{ex:5:22}a) cannot have the meaning of (\ref{ex:5:22}b), while (\ref{ex:5:23}a) can have the meaning of (\ref{ex:5:23}b). If this judgment reflects speakers' grammars, one would have to find a grammatical difference to account for the asymmetry between the two (b) examples. However, Langendoen argues that there is a rhetorical principle\is{rhetorical structure, effect on grammaticality judgments} at work that makes certain readings of grammatically ambiguous\is{ambiguous sentence!judging grammaticality of} sentences more salient than others, to the point where the less salient reading cannot even be forced. The specific factors behind salience in this case are not particularly important, but Langendoen speculates   that some parallelism    preference is at work. An object interpretation of \textit{Ollie} in (\ref{ex:5:23}a)  would
contrast him with \textit{life}, so we prefer the subject interpretation in which he is contrasted with the human \textit{Mary}, whereas in (\ref{ex:5:22}a) the object reading creates a comparison with \textit{Nancy} that is more strictly parallel in some sense. What is relevant to us is that a grammatical reading might be judged ungrammatical due to a competing reading. The lesson to be drawn is that if one must work with potentially ambiguous structures, one had better consider a wide range of exemplars in order to rule out such possible confounds.

\section{Conclusion} \label{sec:5.4}

In this chapter, we have seen at least suggestive evidence for effects on grammaticality judgments of just about every stimulus and procedure variable one can think of. Serial order, repeated presentation, deliberate judgment strategies, modality, register, preparation, and judgment speed are all features of the elicitation task that might contribute systematically to variation in judgments. So might stimulus features, including the various types of contextual material, the meaningfulness of the sentence, the perceived frequency of the sentence structure, and idiosyncratic properties of its lexical items. We have also seen some  unpredictable interactions between variables, such as context with repetition, and mental state with repetition. Interestingly, there has been relatively little work showing that these variables affect the overall \textit{pattern} of acceptability results, e.g., by reversing the relative status of two classes of sentences. It would be encouraging for the field if this turned out not to happen in general. But perhaps  the biggest lesson is the importance of the instructions we give to subjects. In the face of all the disparity in subject interpretations of the intended tasks, there is a strong temptation to propose that the first order of business should be to replicate all these studies with much more carefully designed instructional procedures. There can no longer be any doubt of the importance of this experimental design feature with regard to the elusive definitions of grammaticality and acceptability, and until this knowledge is acted upon we cannot say much about the other experimental factors with any certainty. Nevertheless, I attempt to derive some methodological recommendations from the findings of this and the preceding chapters. These are presented in \sectref{sec:6.3}, following a speculative discussion of the kind of model one might use to account for them.
