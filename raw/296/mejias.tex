\documentclass[output=paper]{langsci/langscibook}
\ChapterDOI{10.5281/zenodo.4450093}

\author{Laura Mejías-Climent\affiliation{Universitat Jaume I}}

\title[Between audiovisual translation and localization]{Between audiovisual translation and localization: The case of \textit{Detroit: Become Human}}

\abstract{The concept of audiovisual translation (AVT) is changing continuously in the current technological landscape, in which localization has emerged as a key process to adapt different types of modern multimedia products. Whether AVT encompasses localization, or vice versa, or they can be conceived as different fields instead, remains unclear. It is not my intention to find a unique solution to this unanswered question, but rather to shed some light on the convergences of AVT and localization from the specific perspective of dubbing, in a product that, in turn, raises some questions about the genre it belongs to: the graphic adventure \textit{Detroit: Become Human} (Quantic Dream, 2018). This chapter aims to highlight some of the differences and convergences between AVT and localization analyzing the dubbing synchronies applied in a video game belonging to a genre closer to traditional movies, compared to other adventure games, due to the strong presence of cinematic scenes and the lower level of interaction. The results will indicate that, even though clear differences can be found between the localization of a game and translation of non-interactive products, the convergences in terms of dubbing synchronies, particularly in the cinematographic scenes, are quite evident.}

\begin{document}

\maketitle

\section{The current landscape of audiovisual translation}

\subsection{Introduction}

Within the landscape of translation studies, and as a professional practice too, audiovisual translation (AVT) represents an umbrella term encompassing different translation modes. These modes depend on the nature of the original product and the translated one \parencite{hurtado11}, as well as the technical methods used to transfer the linguistic message from an original audiovisual text to the target one \parencite{chaume04}.

Traditionally, AVT is divided into two broad groups \parencite{chaume13}: revoicing and captioning. The former refers to those modes in which an additional soundtrack is included in the original product: dubbing, voice-overs, simultaneous interpreting of movies, free commentary, fandubs and audiodescription. The latter, captioning, encompasses those modes based on text inserted or next to the screen in which the original product is shown: subtitling, surtitling, respeaking, subtitling for the deaf and hard of hearing and fansubbing. Both lists keep broadening together with technological advancements, products and market preferences.

AVT has developed at a rapid pace in the last decades, not only as a professional practice, but also as a research field. \textcquote[41]{chaume18}{Technological developments have brought about new audiovisual transfer modes, or new combinations of the latter}. With the exponential increase in the audiovisual production during the last decade, the concept of AVT has faced the challenge of dealing with many different types of audiovisual products and translation modes, and with different passive and active forms of consumption. All of this has caused the emergence not only of additional AVT modes, but also of other terms that coexist with that of AVT, sometimes referring to the same concept, sometimes evidencing our technological changing reality more specifically. In all of them, translation is the underlying concept that accounts for the access to any audiovisual product to a different audience.

In the current and changing technological landscape of audiovisual production, some of the \enquote{characteristics of AVT that are expanding the borders of the concept of translation} are the following, as \textcite[88]{chaume18b} points out: not only interlingual and intralingual transfer of content takes place in AVT modes such as subtitling (interlingual) or subtitling for the deaf (intralingual), but also intersemiotic transfers, in the case of audio guides for museums, sign language, and audiodescription. Transadaptation \parencites{neves05}{gambier03} \textcquote[92]{chaume18b}{could encompass all AVT modes known to date} and, for \textcite{pruys09}, it consists of two variations of the same topic. Transcreation implies a high level of creativity to \textcquote[90]{bernal15}{tilt the balance towards the target audience} and can be understood as another form of semiotic adaptation dealing with many different types of audiovisual texts. Transmedia narratives, rewritings \parencite{bernal15} and media adaptations such as remakes are common practice nowadays. Finally, localization has emerged either as a synonym of a broader concept of AVT, or as a different professional field dealing with the adaptation of software, websites and video games to a target culture (see \sectref{lmc:avt}).

Regarding the concept of \textit{localization}, the borders between AVT and localization are no longer clear, if they ever were, and the use of different AVT modes can be found in any multimodal product nowadays. Whether AVT encompasses localization, or vice versa, or they can be conceived as different fields instead, remains unclear. It is not my intention to find a unique solution to this unanswered question, but rather to shed some light on the convergences of AVT and localization, from the specific perspective of dubbing, in a multimedia product that, in turn, raises some questions about the genre it belongs to: the graphic adventure \textit{Detroit: Become Human} (DBH), developed by Quantic Dream.

\subsection{The aim of the present chapter}

In order to trace some similarities, but also to point out some of the differences, that can be observed in the final localized version of a video game and that of any traditional movie, the results of a case study will be discussed in the following pages. The aim is to offer a concise analysis of the similarities between the dubbing of traditional movies and that of graphic adventures, focusing on the case of the video game \textit{Detroit: Become Human} and, more specifically, in the types of synchronies used in the cinematic scenes of this video game. A total of 20 hours of gameplay of this interactive audiovisual product was analyzed, focusing on the different game situations and dubbing synchronies used in each of them, especially, in the cinematic scenes.

To contextualize the analysis, first, the definitions of AVT and localization, and their convergence, will be discussed, as introduced above. Secondly, the characteristics of the AVT mode of dubbing in movies will be reviewed. Thirdly, the same will be done for the features of dubbing in video games, followed by a discussion of the game situations in which the analyzed video game is articulated. Finally, the results of the empirical and descriptive analysis will be presented to determine the convergences between the dubbing of a traditional movie, a fully-interactive video game \parencites{mejias17}{mejias19} and the case of the graphic adventure \textit{Detroit: Become Human}.

\section{Audiovisual translation within localization or vice versa?}\label{lmc:avt}

As introduced above, AVT encompasses nowadays a wide range of translation modes \parencites[31]{chaume04}[54]{hurtado11} that challenge the traditional concept of translation in the strictest sense of \enquote{linguistic transfer}. The ever-growing variety of multimodal products that keep breaking into the market require translation practices to adapt, in order to accommodate to these continuous changes in the technological configuration of the products and the way they are consumed. In fact, nowadays the term \textit{localization} itself can encompass \blockcquote[84]{chaume18b}{both consolidated as well as new groundbreaking interlingual, intralingual and intersemiotic \enquote{audiovisual translation} practices, namely dubbing, subtitling, surtitling, respeaking, audiosubtitling, voice-over and partial dubbing, simultaneous interpreting in film festivals, free-commentary, subtitling for the deaf and the hard of hearing, audio description for the blind and visually-impaired, fansubbing and fandubbing.}

Nonetheless, the term localization emerged in the 1980s when software developers identified the need to adapt their products to expand their markets to other cultures \parencite[87]{ohaman13}. With the rapid growth of the game industry, especially since the 1990s, the term localization has settled among professionals and it is generally understood as a more complex process of adaptation, beyond a mere linguistic translation \parencite{bernal06}. The author highlights the fact that, however, this term does not refer to anything new that the concept of translation did not include already. Since its use is widely spread among the industry, it seems necessary to accept it within translation studies but always preceded by \enquote{linguistic} to differentiate it from the whole adaptation and industrial process described by professionals such as \textcite{esselink00} or \textcite{maxwell05}.

Other scholars and professionals such as \textcite{munoz17}, \textcite{graetal15} or \textcite{manoha06} emphasize the idea that localization includes the adaptation of the interactive product on many different levels (including the linguistic one) to make it meet the needs of the target market completely. 

The debate is open about the link between the concept of localization and the field of AVT. As \textcite[9--23]{vazquez18} points out, a group of professionals defend the position of localization as a differentiated area, since they understand translation from a reductionist and linguistic perspective \parencite[cf.][]{cadess04}. In addition, some other professionals and scholars also prefer to separate the idea of localization from any other translation mode because of the broad range of adaptation processes it implies, the particularities in the professional practice and the type of product being translated \parencites{pym16}{mendez15}{jimenez13}{mata05}.

On the other hand, the term localization does not add anything new to the concept of translation defended by scholars such as \textcites{bernal06}{bernal15} and \textcite{ohaman13}. This is the same position that \textcite{vazquez18} takes himself, acknowledging that the term localization is widely used in professional spheres and, as such, it can be used in research as well, as a label for the translation practice that deals specifically with video games, software and websites. Localization and translation should not be separated, but rather, the first can be included in the latter as another translation mode with defining characteristics.

Having said that, is localization another mode within the field of AVT or is it a completely different area? In both cases, a multimodal product with very similar characteristics—except for the interactive dimension—is translated. Game localization might liken to AVT in the sense that it encompasses some other modalities itself, such as dubbing for cinematic scenes or subtitling dialogues, in addition to some other practices to modify legal, technical or external contents, or even accessibility practices.

However, it should be taken into account that AVT is a very broad field under which any multimodal text can find its particular translation practice. From my point of view, it all depends on the perspective from which both processes are considered. As a professional practice, game localization can be understood as the hypernym under which different translation modes can be gathered. Localization seems to seek for a clear differentiation within the industry, related to the concept of transcreation \parencite{ohaman13}. Although no clear definition has been established so far with empirical studies to validate the term transcreation \parencite{bernal15}. But that lies outside the scope of these pages. In academic circles, AVT is conceived as the process of adapting any kind of multimodal product, among which video games are included. As \textcite{ohaman13} rightly summarize, and as pointed out above, \blockcquote[106]{ohaman13}{The emergence of new media resulting from the convergence of technologies is seeing the previously separate domains of localization and AVT come together to cater for the new type of products needing to be prepared to go global. Whether AVT subsumes localization or vice versa remains to be seen, although it is now widely acknowledged that AVT is fast gaining a foothold within Translation Studies.}

Given the ambiguity in setting one field or practice within the other, I follow Vázquez Rodríguez’s \parencite*{vazquez18} approach, who proposes to adapt AVT research practices to include the interactive dimension and playability in an empirical study, in order to determine the repercussion that both might have in the translation of interactive audiovisual products. Thus, it is not necessary to establish a completely different paradigm for localization, but just to adapt the existing research approaches used in the AVT field.

When focusing on the analysis of video games, an additional semiotic channel needs to be taken into account in the configuration of the audiovisual product under study \parencite{mejias17}. Consequently, some differences in the translation of a movie and a video game can be identified with descriptive analysis. As the following case of study shows, there are clear differences in the product as a whole. But similarities in some specific areas are more prominent than differences, especially in the case of a graphic adventure, which is, ultimately, a movie offering choices to the viewer (thus, a type of narrative and audiovisual content including interaction).

\section{Dubbing as an audiovisual translation mode within the process of localization}

As is widely known, dubbing \textcquote[1]{chaume12}{consists of replacing the original track of a film’s (or any audiovisual text's) source language dialogues with another track on which translated dialogues have been recorded in the target language}. This translation mode is included in the localization of AAA video games, those with a large budget whose developer can afford a full localization including the adaptation of box and docs, in-game text and audio files and dialogues. 

There are certain differences in the dubbing of a video game compared to that of a movie. In particular, the following aspects can be mentioned \parencite{mejias19}: There is no linear script, but numerous dialogue strings that can be grouped, depending on the character, the setting or some other criteria. Thus, there is no division in takes or loops, as it happens in countries such as Spain or Italy (\textit{anelli}), where cinematographic scripts are traditionally divided to facilitate the dubbing actors’ task. No dubbing symbols are generally used, although they can be introduced later in the studio by the dubbing director; no TCRs are used, since there is no linear development of events in a video game. Finally, in most cases no images are used to perform the dubbing in the studio. Sound engineers use audio waves sometimes, but in the case of translators, they will never have access to images accompanying the dialogue strings.

Apart from these differences, the results in the dubbing of a modern video game and that of a movie seem to be very close—with some striking but rare exceptions, such as \textit{Arizona Sunshine} (Vertigo Games, Jaywalkers Interactive, 2016) or \textit{Age of Pirates} (Akella, 2006).

Dubbing is a historical and extended practice in countries such as Spain, France or Italy, among others, in which all dubbed products must meet a series of quality standards to be consumed successfully by what could be considered an ideal spectator \parencite{chaume07}. Among them, synchrony is one of the most prominent characteristics of dubbing.

\subsection{Characteristics of cinematographic dubbing: Synchronies}\label{lmc:syn}

Dubbing synchronies represent coherence between what is heard (in this case, a soundtrack containing dubbed dialogues) and seen on the screen. As \textcite[73]{chaume07} points out, \enquote{respect for mouth articulation (phonetic or lip-sync), body movements (kinetic synchrony) and the duration of the translation to match the lines spoken by the screen actors (isochrony), constitute one of the cornerstones of dubbing.}

As far as traditional audiovisual products are concerned (this is, those in which there is no interaction: movies, series, TV shows, etc.), the three types of synchronization above mentioned have been studied in depth: lip-sync, kinetic synchrony and isochrony \parencite[68]{chaume12}. In the case of dubbing into Spanish, the implementation of the three synchronies depends on the configuration and nature of the audiovisual product and the acoustic and visual codes involved, among other aspects (such as genres and historical conventions). Especially the paralinguistic code and on- and off-sound codes (acoustic channel), and the photographic and the kinetic codes, and the types of shots (visual channel) determine to a greater extent the level of precision with which each of these three types of synchronies needs to be applied \parencite{chaume04}.

For example, in an extreme close-up, the character’s lip movement is clearly visible onscreen. Thus, the translator and dialogue writer need to use a similar articulation in the translation with, at least, the same number of open vowels and bilabial and labio-dental consonants \parencite[73]{chaume12}. However, in a long shot, there is no need to use lip-sync, and even isochrony is irrelevant, since the characters’ faces and bodies might not be visible clearly.

This happens in a linear and pre-configured audiovisual product, in which the acoustic and visual codes are determined beforehand. In a video game, however, interaction opens the visual configuration of the audiovisual product to a wider number of options; hence, synchronization does not necessarily work in the same way.

\subsection{Characteristics of dubbing in video games: Restrictions}

Dubbing synchronies play an important role in the dubbing of a video game as well. Video games are the most complex example of a modern audiovisual product. As such, they are very close to traditional movies in some aspects, especially when it comes to cinematic scenes. However, the materials available for translation are not the same as in a movie: neither a traditional script nor a final video is facilitated \parencite{mejias19}. Consequently, the process takes place differently and synchronies are rather understood as a series of restrictions \parencite[197]{pujol15}.

These restrictions can be transmitted to translators in a maximum number of characters or words per string. They can also be indicated depending on the type of string, being dialogues and sound content more restrictive (thus, the translation needs to resemble the original length as much as possible), and in-game dialogues more flexible.

Nevertheless, many other factors come into play when determining restrictions in the dubbing of a video game: different localization vendors work differently, as shown in \textcite{mejias19}. In addition, the different agents taking part in the whole process of dubbing play different roles when applying restrictions (thus, synchronies) to the translated text.

It is in the dubbing studio when up to five types of synchronies can be identified and applied to the translated text for the dubbing of a video game, in contrast with the three synchronies described for traditional audiovisual products (see \sectref{lmc:syn}). Dubbing actors and directors would typically apply the three types of synchronies described for traditional movies if videos were available. However, this is not usually the case, and only sound waves are available in some AAA projects, so they tend to imitate the original sound waves as much as possible, in order to assure a well synchronized dubbed dialogue. Here, up to five levels of restriction can be set, depending on the type of string they dub. It is the role of sound engineers to make the dubbed audio files resemble the original ones as much as possible, according to five levels of restriction that can be understood as the five types of synchrony used in the dubbing of a video game \parencite[105]{mejias17}.

\begin{description}
  \item[Wild:] No time restriction applies. 
  \item[Time constraint (TC):] The translated utterances must be the same length as the originals, with a 10\% or 20\% margin.
  \item[Strict time constraint (STC):] The translated utterances must be exactly the same length as the original ones, ignoring any internal pauses or specific intonation.
  \item[Sound-sync (SS):] The translated utterances must be exactly the same length as the original ones, including internal pauses and intonation.
  \item[Lip-sync:] The translated text must be exactly the same length as the original, including pauses, and must resemble the lip articulation.
\end{description}

These five synchronies can be associated with game situations \parencite[90]{mejias19}. Game situations alternate continuously in any video game \parencite[150]{pujol15}. They are a direct consequence of the interactive dimension (interactive channel) and imply different conditions for interaction, depending not only on the genre, but also on the nature of every single video game.

Typically, in action-adventure video games, cinematic scenes stop interaction completely, since they are closed video clips based on a cinematographic configuration. Game action implies full interaction, the dynamic moment in which the player makes the game develop fully. Dialogues are dialectical exchanges and can be considered a situation in between cinematics and action: they can stop interaction partially, restricting the player’s action to a few camera movements, for example, or not interfering with interaction at all. Finally, tasks are instructions transmitted to the player that can also take place during full interaction or stopping it completely. In the following section, the relationship between game situations and game synchronies will be described, as well as the methodology used to analyze dubbing as one of the AVT modes included in the process of localizing a graphic adventure.

\section{Methodology}\label{lmc:meth}

In a previous project \parencite{mejias19}, a relationship between game situations and dubbing synchronies in action-adventure video games was established. The empirical analysis showed that in the three action-adventure video games that were analyzed,

\begin{itemize}
  \item tasks are always dubbed applying no restriction (wild sync), since they are transmitted through off-screen voices;
  \item game action is a relatively flexible situation, since full interaction does not always permit the highest level of visibility of the characters onscreen. Thus, TC usually applies, with a few cases of wild sync for off-screen voices;
  \item dialogues are a hybrid situation in terms of interaction (they vary greatly from one video game to another). The result is that the five types of synchrony can be found in dialogues, being TC the most frequent;
  \item cinematics tend to resemble movies as much as possible. This is also evident in the type of synchrony most commonly used in them: lip-sync. In addition, wild sync is always used for off-screen voices.
\end{itemize}

In this case, a different video game has been analyzed to determine if this relationship between game situations and types of synchrony is also present in a game subgenre closer to traditional movies: the graphic adventure \textit{Detroit: Become Human}. More specifically, the dubbing of the cinematic scenes in this game will be discussed in terms of lip-synching, in order to determine if there is a clear distinction between the dubbing of a movie and the dubbing of the cinematic scenes in a graphic adventure.

To do so, an empirical analysis was carried out within the framework of descriptive translation studies, following the methodology used in \textcites{mejias17}{mejias19}. This can be labeled as an exploratory study requiring further research, since, to the best of our knowledge, no previous empirical studies on the particularities of dubbing in video games have been conducted. To reduce the scope of the study, the specific phenomenon of dubbing synchronies was analyzed in each game situation identified in said video game. More specifically, the game was played classifying in an Excel sheet every game situation that alternated throughout the story and annotating the type of synchrony identified in each situation. The game was played first in Spanish until the main goal was achieved. The same path was reproduced again in English, looking for the types of synchrony used in both the translated segments and the original ones \parencite{toury95}. The game was played for ten hours both in Spanish and in English. A total of 20 hours of gameplay was analyzed.

This methodology reveals some limitations that were already acknowledged in \textcite[315--317]{mejias19}. First of all, the validity of the game situations taxonomy could be questioned, as dialogues represent a completely heterogeneous situation in terms of interactive options. Nonetheless, while game action, cinematics and tasks have been analyzed, the characteristics of dialogues have been redefined in the particular case of the video game presented here to suit the features of a graphic adventure. Indeed, dialogues have been considered as \emph{dialogic quick-time events} (see \sectref{detroit}), which creates a more adapted taxonomy of game situations to conduct this empirical analysis.

Secondly, an interactive product will always entail a certain level of arbitrariness when displaying its components, which might make slight differences arise if the study was replicated. However, in terms of percentages, the impact of these changes on the results obtained would mean unrepresentative variations, so the general conclusions should not be affected.

Finally, a strong limitation imposed by empirical analyses of video games is the difficult access to the linguistic components (such as written scripts of the plot used for translation purposes), as strong non-disclosure agreements prevent the video game assets from being freely accessible or distributed. To overcome this, the corpus was analyzed while playing, since this is the only way to access the full game, and only some transcriptions of representative examples were made. The gameplay, nonetheless, was recorded and the time codes of the recording were annotated in the Excel sheet to track down all the game situations easily. Closer collaboration between the industry and academia could enrich empirical analysis like this in the future.

\section{The case of \textit{Detroit: Become Human}}\label{detroit}

The video game \textit{Detroit: Become Human} was released in 2018 for Play Station 4, and in 2019 for PC. Its director, David Cage, is also the founder of Quantic Dream, a studio specializing in interactive storytelling and in which this game was developed.

The work by David Cage has always created controversy among the most purist players because of the high level of narrative all his games contain, at the expense of a fully interactive and ludic experience. The storytelling seems to be more important than mechanics based on a rapid response and quick reflexes from the (active) player \parencite{altozano17}. With his games, Cage exhorts the player to \enquote{play the story} combining continuous cinematic scenes with interactive dialogues and quick time events. Nevertheless, despite what some players claim, Cage states that he aims to achieve a full and realistic immersion rather than the narrative display \parencite{altozano17}.

Quick-time events (QTEs) are one of the most defining features in David Cage’s work. A QTE represents an action that is completed automatically after pressing a certain button in a limited time. They typically occur during cinematics and, if the specific button is pressed as indicated by the game, the scene continues developing successfully \parencite[131]{altozano17}. QTEs are a useful tool to make the story develop combining action and cinematics (thus, interaction and movies). On the one hand, a QTE is like watching a movie, except for certain buttons that the spectator is required to press if he/she wants the story to continue. On the other hand, the most purist players also see it as an interruption of pure playability \parencite[132]{altozano17}. 

Be it as it may, the truth is that QTEs are a recurrent tool included by Cage in all of his games to make the story develop making the player participate in an unpredictable but limited way. In this analysis, QTEs are considered as dialogues: they usually introduce a question or an answer that the player has to choose in a limited time as part of a longer dialogue. Pure QTE are not very common in \textit{Detroit: Become Human}, neither are they considered a game situation to be analyzed, because they do not imply any sort of dubbing -- in the middle of a fight, the player needs to press ${\times}$, ${\bigtriangleup}$ or ${\bigcirc}$ to hit the opponent or to cover him/herself, but no linguistic content is related to the QTE in such cases (thus no dubbing sync applies).

This video game, as any other by David Cage and Quantic Dream, is intended to make the player become part of the story through very simple mechanics based on basic movements, constant dialogues and numerous cinematic scenes and dialogical QTEs (as opposed to \enquote{action} QTEs, which are not analyzed here, as mentioned). The story revolves around a dystopian Detroit City in which androids start feeling and behaving beyond what machines are expected to do, causing some divergent androids to rebel against humans and fight for their rights. The player controls three characters alternatively. The story is divided into sequences. After each one, a blank tree diagram shows the different possibilities that the player could have considered with his/her choices. The 10 hours played in each language add up a total of 35 sequences.

\subsection{Game situations in Detroit}\label{lmc:gamsit}

As stated in \sectref{lmc:meth}, the game was played for 10 hours in each language, obtaining 696 registers distributed in 35 sequences (See Table \ref{lmc:game-tab}). The most frequent game situation, as the numbers show, are cinematic scenes, followed by QTE-dialogues, game action, and finally, tasks. This represents a clear illustration of the nature of the game: a graphic adventure focuses on the narrative content. The story is the core of the game and those game situations that carry the narrative weight are more frequent than fully interactive moments (game action). This contrasts with the number of game situations obtained in the aforementioned studies \parencites{mejias17}{mejias19}, in which action-adventure games were analyzed. In all of them, game action was the most frequent situation throughout the interactive audiovisual product. We consider it \emph{frequent} instead of \emph{long} because the time span has not been measured. While in a movie time codes and the duration of particular phenomena can be traced, in a video game, interactivity make some situations last as much as the player whishes (game action), while other do have a pre-established length (cinematics). This is why alternation and repetition have been analyzed instead of time span.

\begin{table}\caption{Game situations identified in 10 hours gameplay of \textit{Detroit: Become Human}}\label{lmc:game-tab}
  \begin{tabularx}{.8\textwidth}{Xrr}
    \lsptoprule
    \textbf{Game situation} & \multicolumn{2}{c}{\bfseries Num. of registers}\\
    \midrule
    Tasks             & 58  & 8.33\%\\
    Game action       & 180 & 25.86\%\\
    QTE-Dialogues     & 212 & 30.46\%\\
    Cinematic scenes  & 246 & 35.34\%\\
    \lspbottomrule
  \end{tabularx}
\end{table}

Regarding the types of synchrony found in each group of game situations, the following data was obtained in \emph{DTB}:

\begin{itemize}
  \item Tasks are transmitted through in-game (written) text exclusively. Therefore, their translation is never dubbed but always written onscreen, with a single exception: an introductory sequence in the main menu, during which a woman in a close-up shot talks directly to the player to guide him\slash her through the main settings of the game, before the actual story begins. This single task is dubbed lip-synching.
  \item Game action: most of the game action is dubbed using wild sync (42 cases both in Spanish and in English). STC and TC are also frequent (31 and 22 cases respectively for the Spanish version, and 31 and 21 in English). Lip-sync is only used in 2 cases in Spanish, but in 6 cases in English. There are 80 moments in which no dialogues are heard during game action. 
  \item QTE-Dialogues: with a few exceptions, most dialogical QTEs are dubbed using lip-sync, thus resembling the dubbing used in traditional movies. Only 1 example of TC, 4 of STC and 2 examples of SS have been found both in Spanish and English. There are 5 moments using off-voices (wild sync).
  \item Cinematics: as well as dialogical QTEs, cinematic scenes are dubbed using lip-sync almost exclusively (221 cases in Spanish; 222 in English), with only 1 example of wild, TC, STC and 5 of SS in Spanish; and 1 example of wild, TC, STC and only 4 of SS in English.
\end{itemize}

These results illustrate the nature of the subgenre of a graphic adventure, at least in the case of \textit{DBH}: dialogues using QTEs and cinematic scenes are the most frequent game situations in a video game aimed at recreating the atmosphere of a movie, but always reminding the player that he/she is the main character in charge of taking all the decisions to make the story develop. Additionally, the use of lip-sync as the most frequent type of synchrony in the dubbing of such a game -- 424 cases in Spanish and 429 in English out of 696 registers -- shows the closeness of the final configuration of dubbing in a graphic adventure and in a traditional movie, in terms of the types of synchrony applied. As in any non-interactive audiovisual material, wild sync is also frequent—54 registers both in Spanish and English, because off-voices are used repeatedly to make the story develop.

A significant difference with non-interactive movies, however, is the constant use of text written on the screen, especially, to give instructions to the player, replacing dubbing. A total of 148 out of 696 cases, both in Spanish and English, have been registered as containing no dialogues; 80 took place during game action, 11 represented silent cinematic scenes and 58 were tasks in which the instructions were transmitted through in-game text. This in-game instructional text will never be used in a non-interactive movie, as no action is required from the viewer.

\subsection{The dubbing of cinematic scenes}

As described in \sectref{lmc:gamsit}, the highest level of restriction, lip-sync, is the most frequently applied in the dubbing of the graphic adventure \textit{DBH}. This is the most complex type of synchrony, since the reproduction of the articulatory movements in the translated text is not always compatible with an accurate translation. In movies, it is reserved almost exclusively for close-ups and extreme close-ups \parencite{chaume12}.

In the case of \textit{DBH}, the most restrictive type of synchrony is noticeable in almost all the cinematics and the dialogical QTEs. Here, a strong similarity with the dubbing of any non-interactive movie that should be noted is that the characters’ lips in \textit{DBH }are animated in English using the articulatory lip movements of the actors dubbing the original version. In a movie, we can see real actors speaking onscreen, whose utterances are replaced later by the translated utterances performed by the dubbing actors in the target language. In a video game, it has been argued \parencite[106]{mendez15} that the \enquote{original version} might not be strictly the first one, since all video game characters need a human actor\slash actress to provide them with his/her voice. Nonetheless, in AAA modern video games such as \textit{DBH}, characters’ movements and even speech articulation are recreated with the motion capture technique \parencite{turnes20}, using sensors on a human actor’s body to capture his/her movements and recreate them in a digital model to animate a virtual character \parencite{kines00}. In such a way, the characters’ lips in \textit{DBH} accurately reproduce the articulatory movements of the words they utter in English, as real actors in a non-interactive movie do. In this case, the slight differences between the exact lip movements of the original version in English and the lip-synched Spanish sentences are visible in \textit{DBH} as it happens in any movie.

Regarding the level of accuracy in lip-synching, it should be noted that, as explained above, in most cases dubbing actors do not have images to support their performances. This might result in a slightly less accurate lip-synching than in a traditional movie that, nonetheless, remains unnoticed by most spectators, although further reception studies in the field of video game dubbing would be quite revealing. In the case of \textit{DBH}, lip-synchrony appears quite accurate, even though some open vowels, and bilabial and labio-dental consonants do not coincide exactly in some cases.

To determine how accurate lip-sync is achieved in \emph{DTB}, the following examples reproduce the dubbed and original dialogues in a cinematic scene, a dialogical QTE and a second cinematic scene dubbed using lip-sync. Those paralinguistic features included in the acting (coughing, onomatopoeic expressions, etc.) have been reproduced with the dubbing symbol (G) used in Spanish dubbing scripts. Pauses are represented with \enquote{/} and whenever a non-dialogical QTE is required to make the action continue, the symbol (QTE) has been introduced.

\begin{exe}
  \ex Cinematic scene 298\label{lmc:ex298}

\meijastriple{Connor:}{¿Teni\redvow{e}nt\redvow{e}? / [QTE] }{Lieut\redvow{e}n\redvow{a}nt? / [QTE]}
\meijastriple{Anderson:}{(G) }{(G)}
\meijastriple{Connor:}{D\redvow{e}spiert\redvow{e}, teni\redvow{e}nt\redvow{e}. }{W\redvow{a}ke \redvow{u}p, lieut\redvow{e}n\redvow{a}nt!}
\meijastriple{Anderson:}{(G) }{(G)}
\meijastriple{~}{[QTE] }{[QTE]}
\meijastriple{Connor:}{¡Soy yo, \textbf{Connor}! }{It's me, \textbf{Connor}!}
\meijastriple{Anderson:}{(G) }{(G)}
\meijastriple{Connor:}{Por su \bluecon{b}ien, haré que \bluecon{v}uelva \redvow{a} estar so\bluecon{b}rio. Se lo ad\bluecon{v}ierto: será \bluecon{p}oco agr\redvow{a}d\redvow{a}ble. }{I'\bluecon{m} going to so\bluecon{be}r you \redvow{u}p, for your own sa\bluecon{f}ety. I ha\bluecon{v}e to warn y\redvow{o}u, this \bluecon{m}ay be unpl\redvow{e}as\redvow{a}nt.}
\meijastriple{Anderson:}{(A LA VEZ) (G) ¡Déja\bluecon{m}e en \bluecon{p}az, \bluecon{p}uto \textbf{android}e! ¡Sal de \bluecon{m}i casa, j\redvow{o}der! }{(SIMULTANEOUSLY) Hey! Lea\bluecon{v}e \bluecon{m}e alone, you \bluecon{f}uckin' \textbf{android}! Get the fuck outta \bluecon{m}y h\redvow{o}use!}
\meijastriple{Connor:}{Lo siento, teni\redvow{e}nt\redvow{e}, \bluecon{p}ero lo n\redvow{e}cesit\redvow{o}. [QTE] Le agradezc\redvow{o} de \redvow{a}nt\redvow{e}m\redvow{a}no su cola\bluecon{b}oración. }{I'm sorry, lieut\redvow{e}n\redvow{a}nt, \bluecon{b}ut I n\redvow{e}ed y\redvow{o}u. [QTE] Thank y\redvow{o}u in \redvow{a}dv\redvow{a}nce for your coo\bluecon{p}eration.}
\meijastriple{Anderson:}{(P) Eh, ¡lárgate de aquí, jod\redvow{e}r! [QTE] }{(P) Hey! Get the fuck outta h\redvow{e}re! [QTE]}
\end{exe}

\begin{exe}
\ex QTE-Dialogue 302\label{lmc:ex302}

\meijastriple{Connor:}{Lo en\bluecon{t}i\redvow{e}ndo\dots\ Ta\bluecon{mp}oco creo que tuvi\redvow{e}ra mucho int\redvow{e}r\redvow{é}s\dots\ H\redvow{a}n \redvow{e}ncontrado el cadá\bluecon{v}er de un hombre en un \bluecon{b}urdel d\redvow{e}l \bluecon{c}entro\dots\ Ya r\redvow{e}solv\redvow{e}rán el c\redvow{a}so sin nosotros\dots }{I un\bluecon{d}erst\redvow{a}nd\dots\ It \bluecon{p}ro\bluecon{b}ably wasn't inter\redvow{e}sting \redvow{a}nyw\redvow{a}y\dots\ \redvow{A} m\redvow{a}n \bluecon{f}ound dead in a sex clu\bluecon{b} d\redvow{o}wnt\redvow{o}wn\dots\ Gu\redvow{e}ss th\redvow{e}y'll h\redvow{a}ve to solve the c\redvow{a}se without us\dots
}
\meijastriple{Anderson:}{\redvow{O}ye, no \bluecon{m}e \bluecon{v}endrá \bluecon{m}al to\bluecon{ma}r un \bluecon{p}oco el \redvow{ai}re. \redvow{E}n \redvow{e}l \redvow{a}rmari\redvow{o} de la ha\bluecon{b}itación hay ropa. }{Y\redvow{o}u know, \bluecon{p}ro\bluecon{b}ably wouldn't do \bluecon{m}e any h\redvow{a}r\bluecon{m} to get so\bluecon{m}e \redvow{ai}r\dots\ Th\redvow{e}re'r\redvow{e} s\redvow{o}me clothes in the \bluecon{b}edroom there.}
\meijastriple{Connor:}{Ir\redvow{é a} \bluecon{p}or ella. }{\redvow{I'}ll go get the\bluecon{m}.}
\end{exe}

\begin{exe}
\ex Cinematic scene 305\label{lmc:ex305}

\meijastriple{Connor:}{¿Qu\redvow{é} se qui\redvow{e}re pon\redvow{e}r? }{Wh\redvow{a}t do you w\redvow{a}nt to w\redvow{ea}r?}
\meijastriple{Anderson:}{(G) (Tose) }{(G) (Coughing)}
\meijastriple{Connor:}{¿S\redvow{e e}ncuentr\redvow{a} bien, t\redvow{e}ni\redvow{e}nte? }{\redvow{A}re you \redvow{a}lright, lieut\redvow{e}n\redvow{a}nt?}
\meijastriple{Anderson:}{(G) Sí\dots\ sí\dots\ (G) De mara\bluecon{v}illa\dots\ s\redvow{o}lo\dots\ da\bluecon{m}e cinco \bluecon{m}inutos, ¿vale? }{(G) Yeah\dots\ yeah\dots\ (G) Wonder\bluecon{f}ul\dots\ J\redvow{u}st a\dots\ Gi\bluecon{v}e me five \bluecon{m}inutes, okay?}
\meijastriple{Connor:}{Claro. }{Sure.}
\meijastriple{Anderson:}{(G)}{(G)}
\end{exe}

In the three examples above, all the elements included in video game lip-syn\-ching are reproduced precisely, as in the case of a non-interactive movie: the length of the translated utterances is the same as the original ones; intonation and paralinguistic features are reproduced exactly too. Also open vowels (\textit{a}, \textit{e}, \textit{o}, marked in red) and most labial and bi-labial consonants (marked in blue) are reproduced as much as possible. This makes this level of restriction quite close to how it is done in a non-interactive movie, even though translators and most probably dubbing actors did not have access to the final videos. Most times, videos have not been produced yet when dubbing takes place, although this could not be confirmed in the particular case of \textit{DBH}.

The use of the highest level of restriction in the translated text of a video game implies that all previous levels have been taken into account as well: length of the utterances (TC, STC) and intonation and pauses within utterances (SS). Thus, isochrony is applied, as it is always the case in a non-interactive movie, being this the most valued quality standard among Spanish spectators \parencite{chaume07}.

Some cases of cinematographic kinetic synchrony are also found in the dubbing of \textit{DBH}. This is most probably not done intentionally in the dubbing studio, since videos are not available. Some deictic expressions have been either omitted, as in (\ref{lmc:ex302}), or reproduced literally, in the same position within the sentence, to assure the correspondence with the image.

In (\ref{lmc:ex302}), \textit{There're some clothes in the bedroom }\textbf{\textit{there}} has been translated as `\textit{En el armario de la habitación hay ropa}'. The second occurrence of \textit{there} has been omitted, but the reference to the bedroom should be enough to make the possible body movements of the character coherent with a reference to it, wherever it is located in the house.

Another example was found in the game situation 23 (see example (\ref{lmc:ex23})), a limited game action during which the player’s actions were restricted to camera movements. The seller refers to the android in front of him with the following utterance:

\begin{exe}
  \ex Game action 23\label{lmc:ex23}

  \begin{tabular}{lp{0.38\linewidth}p{0.38\linewidth}}
    Seller: &
    \foreignlanguage{spanish}{En este momento tenemos una oferta especial para \textbf{esta} gama de 7999 dólares, con financiación sin intereses a 48 meses.} &
    At the moment we’re doing a special promotion on \textbf{this} entire range at \$7999, with a 48-months interest free credit.
    \\
  \end{tabular}
\end{exe}

The deictic \textit{this} coincides with the character onscreen pointing at the android in front of him. Since it has been translated reproducing the same length and structure of the sentence, kinetic synchrony has been applied here as well.

These are just a few examples that illustrate the accuracy with which lip-sync has been applied in the analyzed video game, similar to what \textcite{chaume16} did in a descriptive and \enquote{qualitative analysis according to the episode’s adherence to a checklist of dubbing standards} in the TV series \textit{The West Wing} (1999) \parencite{chaume16}. His work, focusing on quality standards in dubbing \parencite{chaume07}, as well as some other studies on the language of dubbing such as those by \textcites{banos09}{marti13}{frepav09} and \textcite{martinez08}, among many others, could serve as useful models for further research in the field of video game dubbing, compared to dubbing in non-interactive material.

Empirical and reception studies would especially benefit greatly from this pilot analysis on the characteristics of dubbing synchronies in video games, which represents a revealing starting point to trace considerable similarities in the dubbing of interactive and non-interactive material, in spite of the different materials available when translating, and the differences in the translation and localization processes.

\section{Final remarks}

The main aim of this chapter was to review the most prominent similarities and differences between cinematographic dubbing and that of a video game belonging to the subgenre of graphic adventures, within the main genre of adventure video games.

Video games represent the most complex example of a multimodal text and, as such, they share many of the characteristics of a non-interactive audiovisual product. The particularity of the added interactive dimension in video games makes them a specific case, which undergoes a process of localization when exported to other cultures, beyond a mere linguistic transfer.

Within the industry, professionals support the idea of localization being an independent field, different from AVT, since it implies some other adaptation processes including a more creative approach for translators and the modification of linguistic and non-linguistic contents of the localized product. Within academia, however, there is no clear evidence that justifies the need to separate localization from AVT. Both fields deal with the translation of multimedia and multimodal products, and both encompass a series of translation modes such as dubbing or subtitling, among many others, required for the different types of audiovisual products and their particularities.

Further research is needed on the convergences and differences of the process of dubbing a movie and a video game, and on localization and AVT modes in general. Notwithstanding this, the aim of these pages was to point out that the result in the dubbing of a graphic adventure and a traditional move is very similar in terms of dubbing synchronies.

Three types of synchronies have been described in the dubbing of non-inter\-ac\-tive audiovisual products \parencites{chaume04}{chaume07}{chaume12}. A new taxonomy of five dubbing synchronies is also necessary in video games \parencites{mejias17}{mejias19}, given the idiosyncrasy of the interactive audiovisual text. However, in the specific case of cinematic scenes and dialogical QTEs of a graphic adventure such as \textit{Detroit: Become Human}, the most restrictive dubbing synchrony in video games, lip-sync, is the one used most frequently and encompasses all the three dubbing synchronies described for non-interactive products.

It should be acknowledged that a case study will never be enough to identify translation tendencies \parencite{toury95}, neither to close the debate of the link between AVT and localization. Nonetheless, this study can be understood as no more than a starting point after which further research is needed, first, enlarging the corpus of adventure video games. Other game genres would need to be explored as well, to look for translation tendencies in the use of dubbing synchronies, and to determine the most characteristic game situations for each genre. Audiovisual translation and localization are two convergent fields and professional practices, which seem to share more similarities than differences, although much is yet to be done with further research.

\section*{Abbreviations}

\begin{tabularx}{.45\textwidth}{lQ}
AVT & audiovisual translation \\
DBH & \textit{Detroit: Become Human}\\
QTE & Quick-Time Event\\
\end{tabularx}
\begin{tabularx}{.45\textwidth}{lQ}
TC & Time constraint\\
STC & Strict time constraint\\
SS & Sound-sync\\
\end{tabularx}
%\begin{tabularx}{.45\textwidth}{lQ}
%... & \\
%... & \\
%\end{tabularx}

{\sloppy\printbibliography[heading=subbibliography,notkeyword=this]}

\end{document}
